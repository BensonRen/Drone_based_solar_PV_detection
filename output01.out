Device being used: cuda:0
Finetuning model from /scratch/wh145/models/solarmapper_final/ct/epoch-80.pth.tar
Warning: The following parameters in the pretrained model does not exist in the current model
	 decoder.uc.0.up_conv.weight
	 decoder.uc.0.up_conv.bias
	 decoder.uc.0.conv_1.weight
	 decoder.uc.0.conv_1.bias
	 decoder.uc.0.conv_2.weight
	 decoder.uc.0.conv_2.bias
	 decoder.uc.0.bn_1.weight
	 decoder.uc.0.bn_1.bias
	 decoder.uc.0.bn_1.running_mean
	 decoder.uc.0.bn_1.running_var
	 decoder.uc.0.bn_1.num_batches_tracked
	 decoder.uc.0.bn_2.weight
	 decoder.uc.0.bn_2.bias
	 decoder.uc.0.bn_2.running_mean
	 decoder.uc.0.bn_2.running_var
	 decoder.uc.0.bn_2.num_batches_tracked
	 decoder.uc.0.act.weight
	 decoder.uc.1.up_conv.weight
	 decoder.uc.1.up_conv.bias
	 decoder.uc.1.conv_1.weight
	 decoder.uc.1.conv_1.bias
	 decoder.uc.1.conv_2.weight
	 decoder.uc.1.conv_2.bias
	 decoder.uc.1.bn_1.weight
	 decoder.uc.1.bn_1.bias
	 decoder.uc.1.bn_1.running_mean
	 decoder.uc.1.bn_1.running_var
	 decoder.uc.1.bn_1.num_batches_tracked
	 decoder.uc.1.bn_2.weight
	 decoder.uc.1.bn_2.bias
	 decoder.uc.1.bn_2.running_mean
	 decoder.uc.1.bn_2.running_var
	 decoder.uc.1.bn_2.num_batches_tracked
	 decoder.uc.1.act.weight
	 decoder.uc.2.up_conv.weight
	 decoder.uc.2.up_conv.bias
	 decoder.uc.2.conv_1.weight
	 decoder.uc.2.conv_1.bias
	 decoder.uc.2.conv_2.weight
	 decoder.uc.2.conv_2.bias
	 decoder.uc.2.bn_1.weight
	 decoder.uc.2.bn_1.bias
	 decoder.uc.2.bn_1.running_mean
	 decoder.uc.2.bn_1.running_var
	 decoder.uc.2.bn_1.num_batches_tracked
	 decoder.uc.2.bn_2.weight
	 decoder.uc.2.bn_2.bias
	 decoder.uc.2.bn_2.running_mean
	 decoder.uc.2.bn_2.running_var
	 decoder.uc.2.bn_2.num_batches_tracked
	 decoder.uc.2.act.weight
	 decoder.uc.3.up_conv.weight
	 decoder.uc.3.up_conv.bias
	 decoder.uc.3.conv_1.weight
	 decoder.uc.3.conv_1.bias
	 decoder.uc.3.conv_2.weight
	 decoder.uc.3.conv_2.bias
	 decoder.uc.3.bn_1.weight
	 decoder.uc.3.bn_1.bias
	 decoder.uc.3.bn_1.running_mean
	 decoder.uc.3.bn_1.running_var
	 decoder.uc.3.bn_1.num_batches_tracked
	 decoder.uc.3.bn_2.weight
	 decoder.uc.3.bn_2.bias
	 decoder.uc.3.bn_2.running_mean
	 decoder.uc.3.bn_2.running_var
	 decoder.uc.3.bn_2.num_batches_tracked
	 decoder.uc.3.act.weight
Warning: The following parameters in the current model does not exist in the pretrained model
	 decoder.center_dilation.dconv_1.weight
	 decoder.center_dilation.dconv_1.bias
	 decoder.center_dilation.dconv_2.weight
	 decoder.center_dilation.dconv_2.bias
	 decoder.center_dilation.dconv_3.weight
	 decoder.center_dilation.dconv_3.bias
	 decoder.center_dilation.dconv_4.weight
	 decoder.center_dilation.dconv_4.bias
	 decoder.upsample_1.conv1.weight
	 decoder.upsample_1.conv1.bias
	 decoder.upsample_1.tconv.weight
	 decoder.upsample_1.tconv.bias
	 decoder.upsample_1.conv2.weight
	 decoder.upsample_1.conv2.bias
	 decoder.upsample_2.conv1.weight
	 decoder.upsample_2.conv1.bias
	 decoder.upsample_2.tconv.weight
	 decoder.upsample_2.tconv.bias
	 decoder.upsample_2.conv2.weight
	 decoder.upsample_2.conv2.bias
	 decoder.upsample_3.conv1.weight
	 decoder.upsample_3.conv1.bias
	 decoder.upsample_3.tconv.weight
	 decoder.upsample_3.tconv.bias
	 decoder.upsample_3.conv2.weight
	 decoder.upsample_3.conv2.bias
	 decoder.upsample_4.conv1.weight
	 decoder.upsample_4.conv1.bias
	 decoder.upsample_4.tconv.weight
	 decoder.upsample_4.tconv.bias
	 decoder.upsample_4.conv2.weight
	 decoder.upsample_4.conv2.bias
	 decoder.tconv.weight
	 decoder.tconv.bias
Warning: The size of the following parameters in the current model does not match the ones in the pretrained model
	 decoder.classify.weight
Try loading with relaxed naming rule:
Prefix in pretrained model 
	pretrained param: encoder.conv1.weight -> current param: encoder.conv1.weight
	pretrained param: encoder.bn1.weight -> current param: encoder.bn1.weight
	pretrained param: encoder.bn1.bias -> current param: encoder.bn1.bias
	pretrained param: encoder.bn1.running_mean -> current param: encoder.bn1.running_mean
	pretrained param: encoder.bn1.running_var -> current param: encoder.bn1.running_var
	pretrained param: encoder.bn1.num_batches_tracked -> current param: encoder.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv1.weight -> current param: encoder.layer1.0.conv1.weight
	pretrained param: encoder.layer1.0.bn1.weight -> current param: encoder.layer1.0.bn1.weight
	pretrained param: encoder.layer1.0.bn1.bias -> current param: encoder.layer1.0.bn1.bias
	pretrained param: encoder.layer1.0.bn1.running_mean -> current param: encoder.layer1.0.bn1.running_mean
	pretrained param: encoder.layer1.0.bn1.running_var -> current param: encoder.layer1.0.bn1.running_var
	pretrained param: encoder.layer1.0.bn1.num_batches_tracked -> current param: encoder.layer1.0.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv2.weight -> current param: encoder.layer1.0.conv2.weight
	pretrained param: encoder.layer1.0.bn2.weight -> current param: encoder.layer1.0.bn2.weight
	pretrained param: encoder.layer1.0.bn2.bias -> current param: encoder.layer1.0.bn2.bias
	pretrained param: encoder.layer1.0.bn2.running_mean -> current param: encoder.layer1.0.bn2.running_mean
	pretrained param: encoder.layer1.0.bn2.running_var -> current param: encoder.layer1.0.bn2.running_var
	pretrained param: encoder.layer1.0.bn2.num_batches_tracked -> current param: encoder.layer1.0.bn2.num_batches_tracked
	pretrained param: encoder.layer1.0.conv3.weight -> current param: encoder.layer1.0.conv3.weight
	pretrained param: encoder.layer1.0.bn3.weight -> current param: encoder.layer1.0.bn3.weight
	pretrained param: encoder.layer1.0.bn3.bias -> current param: encoder.layer1.0.bn3.bias
	pretrained param: encoder.layer1.0.bn3.running_mean -> current param: encoder.layer1.0.bn3.running_mean
	pretrained param: encoder.layer1.0.bn3.running_var -> current param: encoder.layer1.0.bn3.running_var
	pretrained param: encoder.layer1.0.bn3.num_batches_tracked -> current param: encoder.layer1.0.bn3.num_batches_tracked
	pretrained param: encoder.layer1.0.downsample.0.weight -> current param: encoder.layer1.0.downsample.0.weight
	pretrained param: encoder.layer1.0.downsample.1.weight -> current param: encoder.layer1.0.downsample.1.weight
	pretrained param: encoder.layer1.0.downsample.1.bias -> current param: encoder.layer1.0.downsample.1.bias
	pretrained param: encoder.layer1.0.downsample.1.running_mean -> current param: encoder.layer1.0.downsample.1.running_mean
	pretrained param: encoder.layer1.0.downsample.1.running_var -> current param: encoder.layer1.0.downsample.1.running_var
	pretrained param: encoder.layer1.0.downsample.1.num_batches_tracked -> current param: encoder.layer1.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv1.weight -> current param: encoder.layer1.1.conv1.weight
	pretrained param: encoder.layer1.1.bn1.weight -> current param: encoder.layer1.1.bn1.weight
	pretrained param: encoder.layer1.1.bn1.bias -> current param: encoder.layer1.1.bn1.bias
	pretrained param: encoder.layer1.1.bn1.running_mean -> current param: encoder.layer1.1.bn1.running_mean
	pretrained param: encoder.layer1.1.bn1.running_var -> current param: encoder.layer1.1.bn1.running_var
	pretrained param: encoder.layer1.1.bn1.num_batches_tracked -> current param: encoder.layer1.1.bn1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv2.weight -> current param: encoder.layer1.1.conv2.weight
	pretrained param: encoder.layer1.1.bn2.weight -> current param: encoder.layer1.1.bn2.weight
	pretrained param: encoder.layer1.1.bn2.bias -> current param: encoder.layer1.1.bn2.bias
	pretrained param: encoder.layer1.1.bn2.running_mean -> current param: encoder.layer1.1.bn2.running_mean
	pretrained param: encoder.layer1.1.bn2.running_var -> current param: encoder.layer1.1.bn2.running_var
	pretrained param: encoder.layer1.1.bn2.num_batches_tracked -> current param: encoder.layer1.1.bn2.num_batches_tracked
	pretrained param: encoder.layer1.1.conv3.weight -> current param: encoder.layer1.1.conv3.weight
	pretrained param: encoder.layer1.1.bn3.weight -> current param: encoder.layer1.1.bn3.weight
	pretrained param: encoder.layer1.1.bn3.bias -> current param: encoder.layer1.1.bn3.bias
	pretrained param: encoder.layer1.1.bn3.running_mean -> current param: encoder.layer1.1.bn3.running_mean
	pretrained param: encoder.layer1.1.bn3.running_var -> current param: encoder.layer1.1.bn3.running_var
	pretrained param: encoder.layer1.1.bn3.num_batches_tracked -> current param: encoder.layer1.1.bn3.num_batches_tracked
	pretrained param: encoder.layer1.2.conv1.weight -> current param: encoder.layer1.2.conv1.weight
	pretrained param: encoder.layer1.2.bn1.weight -> current param: encoder.layer1.2.bn1.weight
	pretrained param: encoder.layer1.2.bn1.bias -> current param: encoder.layer1.2.bn1.bias
	pretrained param: encoder.layer1.2.bn1.running_mean -> current param: encoder.layer1.2.bn1.running_mean
	pretrained param: encoder.layer1.2.bn1.running_var -> current param: encoder.layer1.2.bn1.running_var
	pretrained param: encoder.layer1.2.bn1.num_batches_tracked -> current param: encoder.layer1.2.bn1.num_batches_tracked
	pretrained param: encoder.layer1.2.conv2.weight -> current param: encoder.layer1.2.conv2.weight
	pretrained param: encoder.layer1.2.bn2.weight -> current param: encoder.layer1.2.bn2.weight
	pretrained param: encoder.layer1.2.bn2.bias -> current param: encoder.layer1.2.bn2.bias
	pretrained param: encoder.layer1.2.bn2.running_mean -> current param: encoder.layer1.2.bn2.running_mean
	pretrained param: encoder.layer1.2.bn2.running_var -> current param: encoder.layer1.2.bn2.running_var
	pretrained param: encoder.layer1.2.bn2.num_batches_tracked -> current param: encoder.layer1.2.bn2.num_batches_tracked
	pretrained param: encoder.layer1.2.conv3.weight -> current param: encoder.layer1.2.conv3.weight
	pretrained param: encoder.layer1.2.bn3.weight -> current param: encoder.layer1.2.bn3.weight
	pretrained param: encoder.layer1.2.bn3.bias -> current param: encoder.layer1.2.bn3.bias
	pretrained param: encoder.layer1.2.bn3.running_mean -> current param: encoder.layer1.2.bn3.running_mean
	pretrained param: encoder.layer1.2.bn3.running_var -> current param: encoder.layer1.2.bn3.running_var
	pretrained param: encoder.layer1.2.bn3.num_batches_tracked -> current param: encoder.layer1.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.conv1.weight -> current param: encoder.layer2.0.conv1.weight
	pretrained param: encoder.layer2.0.bn1.weight -> current param: encoder.layer2.0.bn1.weight
	pretrained param: encoder.layer2.0.bn1.bias -> current param: encoder.layer2.0.bn1.bias
	pretrained param: encoder.layer2.0.bn1.running_mean -> current param: encoder.layer2.0.bn1.running_mean
	pretrained param: encoder.layer2.0.bn1.running_var -> current param: encoder.layer2.0.bn1.running_var
	pretrained param: encoder.layer2.0.bn1.num_batches_tracked -> current param: encoder.layer2.0.bn1.num_batches_tracked
	pretrained param: encoder.layer2.0.conv2.weight -> current param: encoder.layer2.0.conv2.weight
	pretrained param: encoder.layer2.0.bn2.weight -> current param: encoder.layer2.0.bn2.weight
	pretrained param: encoder.layer2.0.bn2.bias -> current param: encoder.layer2.0.bn2.bias
	pretrained param: encoder.layer2.0.bn2.running_mean -> current param: encoder.layer2.0.bn2.running_mean
	pretrained param: encoder.layer2.0.bn2.running_var -> current param: encoder.layer2.0.bn2.running_var
	pretrained param: encoder.layer2.0.bn2.num_batches_tracked -> current param: encoder.layer2.0.bn2.num_batches_tracked
	pretrained param: encoder.layer2.0.conv3.weight -> current param: encoder.layer2.0.conv3.weight
	pretrained param: encoder.layer2.0.bn3.weight -> current param: encoder.layer2.0.bn3.weight
	pretrained param: encoder.layer2.0.bn3.bias -> current param: encoder.layer2.0.bn3.bias
	pretrained param: encoder.layer2.0.bn3.running_mean -> current param: encoder.layer2.0.bn3.running_mean
	pretrained param: encoder.layer2.0.bn3.running_var -> current param: encoder.layer2.0.bn3.running_var
	pretrained param: encoder.layer2.0.bn3.num_batches_tracked -> current param: encoder.layer2.0.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.downsample.0.weight -> current param: encoder.layer2.0.downsample.0.weight
	pretrained param: encoder.layer2.0.downsample.1.weight -> current param: encoder.layer2.0.downsample.1.weight
	pretrained param: encoder.layer2.0.downsample.1.bias -> current param: encoder.layer2.0.downsample.1.bias
	pretrained param: encoder.layer2.0.downsample.1.running_mean -> current param: encoder.layer2.0.downsample.1.running_mean
	pretrained param: encoder.layer2.0.downsample.1.running_var -> current param: encoder.layer2.0.downsample.1.running_var
	pretrained param: encoder.layer2.0.downsample.1.num_batches_tracked -> current param: encoder.layer2.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv1.weight -> current param: encoder.layer2.1.conv1.weight
	pretrained param: encoder.layer2.1.bn1.weight -> current param: encoder.layer2.1.bn1.weight
	pretrained param: encoder.layer2.1.bn1.bias -> current param: encoder.layer2.1.bn1.bias
	pretrained param: encoder.layer2.1.bn1.running_mean -> current param: encoder.layer2.1.bn1.running_mean
	pretrained param: encoder.layer2.1.bn1.running_var -> current param: encoder.layer2.1.bn1.running_var
	pretrained param: encoder.layer2.1.bn1.num_batches_tracked -> current param: encoder.layer2.1.bn1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv2.weight -> current param: encoder.layer2.1.conv2.weight
	pretrained param: encoder.layer2.1.bn2.weight -> current param: encoder.layer2.1.bn2.weight
	pretrained param: encoder.layer2.1.bn2.bias -> current param: encoder.layer2.1.bn2.bias
	pretrained param: encoder.layer2.1.bn2.running_mean -> current param: encoder.layer2.1.bn2.running_mean
	pretrained param: encoder.layer2.1.bn2.running_var -> current param: encoder.layer2.1.bn2.running_var
	pretrained param: encoder.layer2.1.bn2.num_batches_tracked -> current param: encoder.layer2.1.bn2.num_batches_tracked
	pretrained param: encoder.layer2.1.conv3.weight -> current param: encoder.layer2.1.conv3.weight
	pretrained param: encoder.layer2.1.bn3.weight -> current param: encoder.layer2.1.bn3.weight
	pretrained param: encoder.layer2.1.bn3.bias -> current param: encoder.layer2.1.bn3.bias
	pretrained param: encoder.layer2.1.bn3.running_mean -> current param: encoder.layer2.1.bn3.running_mean
	pretrained param: encoder.layer2.1.bn3.running_var -> current param: encoder.layer2.1.bn3.running_var
	pretrained param: encoder.layer2.1.bn3.num_batches_tracked -> current param: encoder.layer2.1.bn3.num_batches_tracked
	pretrained param: encoder.layer2.2.conv1.weight -> current param: encoder.layer2.2.conv1.weight
	pretrained param: encoder.layer2.2.bn1.weight -> current param: encoder.layer2.2.bn1.weight
	pretrained param: encoder.layer2.2.bn1.bias -> current param: encoder.layer2.2.bn1.bias
	pretrained param: encoder.layer2.2.bn1.running_mean -> current param: encoder.layer2.2.bn1.running_mean
	pretrained param: encoder.layer2.2.bn1.running_var -> current param: encoder.layer2.2.bn1.running_var
	pretrained param: encoder.layer2.2.bn1.num_batches_tracked -> current param: encoder.layer2.2.bn1.num_batches_tracked
	pretrained param: encoder.layer2.2.conv2.weight -> current param: encoder.layer2.2.conv2.weight
	pretrained param: encoder.layer2.2.bn2.weight -> current param: encoder.layer2.2.bn2.weight
	pretrained param: encoder.layer2.2.bn2.bias -> current param: encoder.layer2.2.bn2.bias
	pretrained param: encoder.layer2.2.bn2.running_mean -> current param: encoder.layer2.2.bn2.running_mean
	pretrained param: encoder.layer2.2.bn2.running_var -> current param: encoder.layer2.2.bn2.running_var
	pretrained param: encoder.layer2.2.bn2.num_batches_tracked -> current param: encoder.layer2.2.bn2.num_batches_tracked
	pretrained param: encoder.layer2.2.conv3.weight -> current param: encoder.layer2.2.conv3.weight
	pretrained param: encoder.layer2.2.bn3.weight -> current param: encoder.layer2.2.bn3.weight
	pretrained param: encoder.layer2.2.bn3.bias -> current param: encoder.layer2.2.bn3.bias
	pretrained param: encoder.layer2.2.bn3.running_mean -> current param: encoder.layer2.2.bn3.running_mean
	pretrained param: encoder.layer2.2.bn3.running_var -> current param: encoder.layer2.2.bn3.running_var
	pretrained param: encoder.layer2.2.bn3.num_batches_tracked -> current param: encoder.layer2.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.3.conv1.weight -> current param: encoder.layer2.3.conv1.weight
	pretrained param: encoder.layer2.3.bn1.weight -> current param: encoder.layer2.3.bn1.weight
	pretrained param: encoder.layer2.3.bn1.bias -> current param: encoder.layer2.3.bn1.bias
	pretrained param: encoder.layer2.3.bn1.running_mean -> current param: encoder.layer2.3.bn1.running_mean
	pretrained param: encoder.layer2.3.bn1.running_var -> current param: encoder.layer2.3.bn1.running_var
	pretrained param: encoder.layer2.3.bn1.num_batches_tracked -> current param: encoder.layer2.3.bn1.num_batches_tracked
	pretrained param: encoder.layer2.3.conv2.weight -> current param: encoder.layer2.3.conv2.weight
	pretrained param: encoder.layer2.3.bn2.weight -> current param: encoder.layer2.3.bn2.weight
	pretrained param: encoder.layer2.3.bn2.bias -> current param: encoder.layer2.3.bn2.bias
	pretrained param: encoder.layer2.3.bn2.running_mean -> current param: encoder.layer2.3.bn2.running_mean
	pretrained param: encoder.layer2.3.bn2.running_var -> current param: encoder.layer2.3.bn2.running_var
	pretrained param: encoder.layer2.3.bn2.num_batches_tracked -> current param: encoder.layer2.3.bn2.num_batches_tracked
	pretrained param: encoder.layer2.3.conv3.weight -> current param: encoder.layer2.3.conv3.weight
	pretrained param: encoder.layer2.3.bn3.weight -> current param: encoder.layer2.3.bn3.weight
	pretrained param: encoder.layer2.3.bn3.bias -> current param: encoder.layer2.3.bn3.bias
	pretrained param: encoder.layer2.3.bn3.running_mean -> current param: encoder.layer2.3.bn3.running_mean
	pretrained param: encoder.layer2.3.bn3.running_var -> current param: encoder.layer2.3.bn3.running_var
	pretrained param: encoder.layer2.3.bn3.num_batches_tracked -> current param: encoder.layer2.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.conv1.weight -> current param: encoder.layer3.0.conv1.weight
	pretrained param: encoder.layer3.0.bn1.weight -> current param: encoder.layer3.0.bn1.weight
	pretrained param: encoder.layer3.0.bn1.bias -> current param: encoder.layer3.0.bn1.bias
	pretrained param: encoder.layer3.0.bn1.running_mean -> current param: encoder.layer3.0.bn1.running_mean
	pretrained param: encoder.layer3.0.bn1.running_var -> current param: encoder.layer3.0.bn1.running_var
	pretrained param: encoder.layer3.0.bn1.num_batches_tracked -> current param: encoder.layer3.0.bn1.num_batches_tracked
	pretrained param: encoder.layer3.0.conv2.weight -> current param: encoder.layer3.0.conv2.weight
	pretrained param: encoder.layer3.0.bn2.weight -> current param: encoder.layer3.0.bn2.weight
	pretrained param: encoder.layer3.0.bn2.bias -> current param: encoder.layer3.0.bn2.bias
	pretrained param: encoder.layer3.0.bn2.running_mean -> current param: encoder.layer3.0.bn2.running_mean
	pretrained param: encoder.layer3.0.bn2.running_var -> current param: encoder.layer3.0.bn2.running_var
	pretrained param: encoder.layer3.0.bn2.num_batches_tracked -> current param: encoder.layer3.0.bn2.num_batches_tracked
	pretrained param: encoder.layer3.0.conv3.weight -> current param: encoder.layer3.0.conv3.weight
	pretrained param: encoder.layer3.0.bn3.weight -> current param: encoder.layer3.0.bn3.weight
	pretrained param: encoder.layer3.0.bn3.bias -> current param: encoder.layer3.0.bn3.bias
	pretrained param: encoder.layer3.0.bn3.running_mean -> current param: encoder.layer3.0.bn3.running_mean
	pretrained param: encoder.layer3.0.bn3.running_var -> current param: encoder.layer3.0.bn3.running_var
	pretrained param: encoder.layer3.0.bn3.num_batches_tracked -> current param: encoder.layer3.0.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.downsample.0.weight -> current param: encoder.layer3.0.downsample.0.weight
	pretrained param: encoder.layer3.0.downsample.1.weight -> current param: encoder.layer3.0.downsample.1.weight
	pretrained param: encoder.layer3.0.downsample.1.bias -> current param: encoder.layer3.0.downsample.1.bias
	pretrained param: encoder.layer3.0.downsample.1.running_mean -> current param: encoder.layer3.0.downsample.1.running_mean
	pretrained param: encoder.layer3.0.downsample.1.running_var -> current param: encoder.layer3.0.downsample.1.running_var
	pretrained param: encoder.layer3.0.downsample.1.num_batches_tracked -> current param: encoder.layer3.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv1.weight -> current param: encoder.layer3.1.conv1.weight
	pretrained param: encoder.layer3.1.bn1.weight -> current param: encoder.layer3.1.bn1.weight
	pretrained param: encoder.layer3.1.bn1.bias -> current param: encoder.layer3.1.bn1.bias
	pretrained param: encoder.layer3.1.bn1.running_mean -> current param: encoder.layer3.1.bn1.running_mean
	pretrained param: encoder.layer3.1.bn1.running_var -> current param: encoder.layer3.1.bn1.running_var
	pretrained param: encoder.layer3.1.bn1.num_batches_tracked -> current param: encoder.layer3.1.bn1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv2.weight -> current param: encoder.layer3.1.conv2.weight
	pretrained param: encoder.layer3.1.bn2.weight -> current param: encoder.layer3.1.bn2.weight
	pretrained param: encoder.layer3.1.bn2.bias -> current param: encoder.layer3.1.bn2.bias
	pretrained param: encoder.layer3.1.bn2.running_mean -> current param: encoder.layer3.1.bn2.running_mean
	pretrained param: encoder.layer3.1.bn2.running_var -> current param: encoder.layer3.1.bn2.running_var
	pretrained param: encoder.layer3.1.bn2.num_batches_tracked -> current param: encoder.layer3.1.bn2.num_batches_tracked
	pretrained param: encoder.layer3.1.conv3.weight -> current param: encoder.layer3.1.conv3.weight
	pretrained param: encoder.layer3.1.bn3.weight -> current param: encoder.layer3.1.bn3.weight
	pretrained param: encoder.layer3.1.bn3.bias -> current param: encoder.layer3.1.bn3.bias
	pretrained param: encoder.layer3.1.bn3.running_mean -> current param: encoder.layer3.1.bn3.running_mean
	pretrained param: encoder.layer3.1.bn3.running_var -> current param: encoder.layer3.1.bn3.running_var
	pretrained param: encoder.layer3.1.bn3.num_batches_tracked -> current param: encoder.layer3.1.bn3.num_batches_tracked
	pretrained param: encoder.layer3.2.conv1.weight -> current param: encoder.layer3.2.conv1.weight
	pretrained param: encoder.layer3.2.bn1.weight -> current param: encoder.layer3.2.bn1.weight
	pretrained param: encoder.layer3.2.bn1.bias -> current param: encoder.layer3.2.bn1.bias
	pretrained param: encoder.layer3.2.bn1.running_mean -> current param: encoder.layer3.2.bn1.running_mean
	pretrained param: encoder.layer3.2.bn1.running_var -> current param: encoder.layer3.2.bn1.running_var
	pretrained param: encoder.layer3.2.bn1.num_batches_tracked -> current param: encoder.layer3.2.bn1.num_batches_tracked
	pretrained param: encoder.layer3.2.conv2.weight -> current param: encoder.layer3.2.conv2.weight
	pretrained param: encoder.layer3.2.bn2.weight -> current param: encoder.layer3.2.bn2.weight
	pretrained param: encoder.layer3.2.bn2.bias -> current param: encoder.layer3.2.bn2.bias
	pretrained param: encoder.layer3.2.bn2.running_mean -> current param: encoder.layer3.2.bn2.running_mean
	pretrained param: encoder.layer3.2.bn2.running_var -> current param: encoder.layer3.2.bn2.running_var
	pretrained param: encoder.layer3.2.bn2.num_batches_tracked -> current param: encoder.layer3.2.bn2.num_batches_tracked
	pretrained param: encoder.layer3.2.conv3.weight -> current param: encoder.layer3.2.conv3.weight
	pretrained param: encoder.layer3.2.bn3.weight -> current param: encoder.layer3.2.bn3.weight
	pretrained param: encoder.layer3.2.bn3.bias -> current param: encoder.layer3.2.bn3.bias
	pretrained param: encoder.layer3.2.bn3.running_mean -> current param: encoder.layer3.2.bn3.running_mean
	pretrained param: encoder.layer3.2.bn3.running_var -> current param: encoder.layer3.2.bn3.running_var
	pretrained param: encoder.layer3.2.bn3.num_batches_tracked -> current param: encoder.layer3.2.bn3.num_batches_tracked
	pretrained param: encoder.layer3.3.conv1.weight -> current param: encoder.layer3.3.conv1.weight
	pretrained param: encoder.layer3.3.bn1.weight -> current param: encoder.layer3.3.bn1.weight
	pretrained param: encoder.layer3.3.bn1.bias -> current param: encoder.layer3.3.bn1.bias
	pretrained param: encoder.layer3.3.bn1.running_mean -> current param: encoder.layer3.3.bn1.running_mean
	pretrained param: encoder.layer3.3.bn1.running_var -> current param: encoder.layer3.3.bn1.running_var
	pretrained param: encoder.layer3.3.bn1.num_batches_tracked -> current param: encoder.layer3.3.bn1.num_batches_tracked
	pretrained param: encoder.layer3.3.conv2.weight -> current param: encoder.layer3.3.conv2.weight
	pretrained param: encoder.layer3.3.bn2.weight -> current param: encoder.layer3.3.bn2.weight
	pretrained param: encoder.layer3.3.bn2.bias -> current param: encoder.layer3.3.bn2.bias
	pretrained param: encoder.layer3.3.bn2.running_mean -> current param: encoder.layer3.3.bn2.running_mean
	pretrained param: encoder.layer3.3.bn2.running_var -> current param: encoder.layer3.3.bn2.running_var
	pretrained param: encoder.layer3.3.bn2.num_batches_tracked -> current param: encoder.layer3.3.bn2.num_batches_tracked
	pretrained param: encoder.layer3.3.conv3.weight -> current param: encoder.layer3.3.conv3.weight
	pretrained param: encoder.layer3.3.bn3.weight -> current param: encoder.layer3.3.bn3.weight
	pretrained param: encoder.layer3.3.bn3.bias -> current param: encoder.layer3.3.bn3.bias
	pretrained param: encoder.layer3.3.bn3.running_mean -> current param: encoder.layer3.3.bn3.running_mean
	pretrained param: encoder.layer3.3.bn3.running_var -> current param: encoder.layer3.3.bn3.running_var
	pretrained param: encoder.layer3.3.bn3.num_batches_tracked -> current param: encoder.layer3.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.4.conv1.weight -> current param: encoder.layer3.4.conv1.weight
	pretrained param: encoder.layer3.4.bn1.weight -> current param: encoder.layer3.4.bn1.weight
	pretrained param: encoder.layer3.4.bn1.bias -> current param: encoder.layer3.4.bn1.bias
	pretrained param: encoder.layer3.4.bn1.running_mean -> current param: encoder.layer3.4.bn1.running_mean
	pretrained param: encoder.layer3.4.bn1.running_var -> current param: encoder.layer3.4.bn1.running_var
	pretrained param: encoder.layer3.4.bn1.num_batches_tracked -> current param: encoder.layer3.4.bn1.num_batches_tracked
	pretrained param: encoder.layer3.4.conv2.weight -> current param: encoder.layer3.4.conv2.weight
	pretrained param: encoder.layer3.4.bn2.weight -> current param: encoder.layer3.4.bn2.weight
	pretrained param: encoder.layer3.4.bn2.bias -> current param: encoder.layer3.4.bn2.bias
	pretrained param: encoder.layer3.4.bn2.running_mean -> current param: encoder.layer3.4.bn2.running_mean
	pretrained param: encoder.layer3.4.bn2.running_var -> current param: encoder.layer3.4.bn2.running_var
	pretrained param: encoder.layer3.4.bn2.num_batches_tracked -> current param: encoder.layer3.4.bn2.num_batches_tracked
	pretrained param: encoder.layer3.4.conv3.weight -> current param: encoder.layer3.4.conv3.weight
	pretrained param: encoder.layer3.4.bn3.weight -> current param: encoder.layer3.4.bn3.weight
	pretrained param: encoder.layer3.4.bn3.bias -> current param: encoder.layer3.4.bn3.bias
	pretrained param: encoder.layer3.4.bn3.running_mean -> current param: encoder.layer3.4.bn3.running_mean
	pretrained param: encoder.layer3.4.bn3.running_var -> current param: encoder.layer3.4.bn3.running_var
	pretrained param: encoder.layer3.4.bn3.num_batches_tracked -> current param: encoder.layer3.4.bn3.num_batches_tracked
	pretrained param: encoder.layer3.5.conv1.weight -> current param: encoder.layer3.5.conv1.weight
	pretrained param: encoder.layer3.5.bn1.weight -> current param: encoder.layer3.5.bn1.weight
	pretrained param: encoder.layer3.5.bn1.bias -> current param: encoder.layer3.5.bn1.bias
	pretrained param: encoder.layer3.5.bn1.running_mean -> current param: encoder.layer3.5.bn1.running_mean
	pretrained param: encoder.layer3.5.bn1.running_var -> current param: encoder.layer3.5.bn1.running_var
	pretrained param: encoder.layer3.5.bn1.num_batches_tracked -> current param: encoder.layer3.5.bn1.num_batches_tracked
	pretrained param: encoder.layer3.5.conv2.weight -> current param: encoder.layer3.5.conv2.weight
	pretrained param: encoder.layer3.5.bn2.weight -> current param: encoder.layer3.5.bn2.weight
	pretrained param: encoder.layer3.5.bn2.bias -> current param: encoder.layer3.5.bn2.bias
	pretrained param: encoder.layer3.5.bn2.running_mean -> current param: encoder.layer3.5.bn2.running_mean
	pretrained param: encoder.layer3.5.bn2.running_var -> current param: encoder.layer3.5.bn2.running_var
	pretrained param: encoder.layer3.5.bn2.num_batches_tracked -> current param: encoder.layer3.5.bn2.num_batches_tracked
	pretrained param: encoder.layer3.5.conv3.weight -> current param: encoder.layer3.5.conv3.weight
	pretrained param: encoder.layer3.5.bn3.weight -> current param: encoder.layer3.5.bn3.weight
	pretrained param: encoder.layer3.5.bn3.bias -> current param: encoder.layer3.5.bn3.bias
	pretrained param: encoder.layer3.5.bn3.running_mean -> current param: encoder.layer3.5.bn3.running_mean
	pretrained param: encoder.layer3.5.bn3.running_var -> current param: encoder.layer3.5.bn3.running_var
	pretrained param: encoder.layer3.5.bn3.num_batches_tracked -> current param: encoder.layer3.5.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.conv1.weight -> current param: encoder.layer4.0.conv1.weight
	pretrained param: encoder.layer4.0.bn1.weight -> current param: encoder.layer4.0.bn1.weight
	pretrained param: encoder.layer4.0.bn1.bias -> current param: encoder.layer4.0.bn1.bias
	pretrained param: encoder.layer4.0.bn1.running_mean -> current param: encoder.layer4.0.bn1.running_mean
	pretrained param: encoder.layer4.0.bn1.running_var -> current param: encoder.layer4.0.bn1.running_var
	pretrained param: encoder.layer4.0.bn1.num_batches_tracked -> current param: encoder.layer4.0.bn1.num_batches_tracked
	pretrained param: encoder.layer4.0.conv2.weight -> current param: encoder.layer4.0.conv2.weight
	pretrained param: encoder.layer4.0.bn2.weight -> current param: encoder.layer4.0.bn2.weight
	pretrained param: encoder.layer4.0.bn2.bias -> current param: encoder.layer4.0.bn2.bias
	pretrained param: encoder.layer4.0.bn2.running_mean -> current param: encoder.layer4.0.bn2.running_mean
	pretrained param: encoder.layer4.0.bn2.running_var -> current param: encoder.layer4.0.bn2.running_var
	pretrained param: encoder.layer4.0.bn2.num_batches_tracked -> current param: encoder.layer4.0.bn2.num_batches_tracked
	pretrained param: encoder.layer4.0.conv3.weight -> current param: encoder.layer4.0.conv3.weight
	pretrained param: encoder.layer4.0.bn3.weight -> current param: encoder.layer4.0.bn3.weight
	pretrained param: encoder.layer4.0.bn3.bias -> current param: encoder.layer4.0.bn3.bias
	pretrained param: encoder.layer4.0.bn3.running_mean -> current param: encoder.layer4.0.bn3.running_mean
	pretrained param: encoder.layer4.0.bn3.running_var -> current param: encoder.layer4.0.bn3.running_var
	pretrained param: encoder.layer4.0.bn3.num_batches_tracked -> current param: encoder.layer4.0.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.downsample.0.weight -> current param: encoder.layer4.0.downsample.0.weight
	pretrained param: encoder.layer4.0.downsample.1.weight -> current param: encoder.layer4.0.downsample.1.weight
	pretrained param: encoder.layer4.0.downsample.1.bias -> current param: encoder.layer4.0.downsample.1.bias
	pretrained param: encoder.layer4.0.downsample.1.running_mean -> current param: encoder.layer4.0.downsample.1.running_mean
	pretrained param: encoder.layer4.0.downsample.1.running_var -> current param: encoder.layer4.0.downsample.1.running_var
	pretrained param: encoder.layer4.0.downsample.1.num_batches_tracked -> current param: encoder.layer4.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv1.weight -> current param: encoder.layer4.1.conv1.weight
	pretrained param: encoder.layer4.1.bn1.weight -> current param: encoder.layer4.1.bn1.weight
	pretrained param: encoder.layer4.1.bn1.bias -> current param: encoder.layer4.1.bn1.bias
	pretrained param: encoder.layer4.1.bn1.running_mean -> current param: encoder.layer4.1.bn1.running_mean
	pretrained param: encoder.layer4.1.bn1.running_var -> current param: encoder.layer4.1.bn1.running_var
	pretrained param: encoder.layer4.1.bn1.num_batches_tracked -> current param: encoder.layer4.1.bn1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv2.weight -> current param: encoder.layer4.1.conv2.weight
	pretrained param: encoder.layer4.1.bn2.weight -> current param: encoder.layer4.1.bn2.weight
	pretrained param: encoder.layer4.1.bn2.bias -> current param: encoder.layer4.1.bn2.bias
	pretrained param: encoder.layer4.1.bn2.running_mean -> current param: encoder.layer4.1.bn2.running_mean
	pretrained param: encoder.layer4.1.bn2.running_var -> current param: encoder.layer4.1.bn2.running_var
	pretrained param: encoder.layer4.1.bn2.num_batches_tracked -> current param: encoder.layer4.1.bn2.num_batches_tracked
	pretrained param: encoder.layer4.1.conv3.weight -> current param: encoder.layer4.1.conv3.weight
	pretrained param: encoder.layer4.1.bn3.weight -> current param: encoder.layer4.1.bn3.weight
	pretrained param: encoder.layer4.1.bn3.bias -> current param: encoder.layer4.1.bn3.bias
	pretrained param: encoder.layer4.1.bn3.running_mean -> current param: encoder.layer4.1.bn3.running_mean
	pretrained param: encoder.layer4.1.bn3.running_var -> current param: encoder.layer4.1.bn3.running_var
	pretrained param: encoder.layer4.1.bn3.num_batches_tracked -> current param: encoder.layer4.1.bn3.num_batches_tracked
	pretrained param: encoder.layer4.2.conv1.weight -> current param: encoder.layer4.2.conv1.weight
	pretrained param: encoder.layer4.2.bn1.weight -> current param: encoder.layer4.2.bn1.weight
	pretrained param: encoder.layer4.2.bn1.bias -> current param: encoder.layer4.2.bn1.bias
	pretrained param: encoder.layer4.2.bn1.running_mean -> current param: encoder.layer4.2.bn1.running_mean
	pretrained param: encoder.layer4.2.bn1.running_var -> current param: encoder.layer4.2.bn1.running_var
	pretrained param: encoder.layer4.2.bn1.num_batches_tracked -> current param: encoder.layer4.2.bn1.num_batches_tracked
	pretrained param: encoder.layer4.2.conv2.weight -> current param: encoder.layer4.2.conv2.weight
	pretrained param: encoder.layer4.2.bn2.weight -> current param: encoder.layer4.2.bn2.weight
	pretrained param: encoder.layer4.2.bn2.bias -> current param: encoder.layer4.2.bn2.bias
	pretrained param: encoder.layer4.2.bn2.running_mean -> current param: encoder.layer4.2.bn2.running_mean
	pretrained param: encoder.layer4.2.bn2.running_var -> current param: encoder.layer4.2.bn2.running_var
	pretrained param: encoder.layer4.2.bn2.num_batches_tracked -> current param: encoder.layer4.2.bn2.num_batches_tracked
	pretrained param: encoder.layer4.2.conv3.weight -> current param: encoder.layer4.2.conv3.weight
	pretrained param: encoder.layer4.2.bn3.weight -> current param: encoder.layer4.2.bn3.weight
	pretrained param: encoder.layer4.2.bn3.bias -> current param: encoder.layer4.2.bn3.bias
	pretrained param: encoder.layer4.2.bn3.running_mean -> current param: encoder.layer4.2.bn3.running_mean
	pretrained param: encoder.layer4.2.bn3.running_var -> current param: encoder.layer4.2.bn3.running_var
	pretrained param: encoder.layer4.2.bn3.num_batches_tracked -> current param: encoder.layer4.2.bn3.num_batches_tracked
	pretrained param: decoder.classify.weight -> current param: decoder.classify.weight
		Ignoring: decoder.classify.weight->decoder.classify.weight (size mismatch)
	pretrained param: decoder.classify.bias -> current param: decoder.classify.bias
90.11% of the model loaded from the pretrained
Total params: 179.77M
Dataset catalyst_h3 is not supported, use default mean stats instead
Training model on the catalyst_h3 dataset
Dataset catalyst_h3 is not supported, use default mean stats instead
[train] Epoch: 0/80 xent: 1.512 softIoU: 8.303 IoU: 0.000 
Execution time: 312.4946221471764

[valid] Epoch: 0/80 xent: 0.513 softIoU: 8.017 IoU: 0.000 
Execution time: 39.231760035734624

[train] Epoch: 1/80 xent: 0.501 softIoU: 8.017 IoU: 0.000 
Execution time: 313.62933349981904

[valid] Epoch: 1/80 xent: 0.511 softIoU: 8.018 IoU: 0.000 
Execution time: 39.56654245080426

[train] Epoch: 2/80 xent: 0.500 softIoU: 8.019 IoU: 0.000 
Execution time: 285.673943717964

[valid] Epoch: 2/80 xent: 0.511 softIoU: 8.018 IoU: 0.000 
Execution time: 39.13011088501662

[train] Epoch: 3/80 xent: 0.500 softIoU: 8.018 IoU: 0.000 
Execution time: 285.29455022793263

[valid] Epoch: 3/80 xent: 0.511 softIoU: 8.017 IoU: 0.000 
Execution time: 38.94809889094904

[train] Epoch: 4/80 xent: 0.499 softIoU: 8.017 IoU: 0.000 
Execution time: 304.1968146250583

[valid] Epoch: 4/80 xent: 0.509 softIoU: 8.019 IoU: 0.000 
Execution time: 39.188039732165635

[train] Epoch: 5/80 xent: 0.498 softIoU: 8.018 IoU: 0.000 
Execution time: 294.45909574907273

[valid] Epoch: 5/80 xent: 0.508 softIoU: 8.018 IoU: 0.000 
Execution time: 44.07132996805012

[train] Epoch: 6/80 xent: 0.495 softIoU: 8.019 IoU: 0.000 
Execution time: 296.2884744652547

[valid] Epoch: 6/80 xent: 0.508 softIoU: 8.017 IoU: 0.000 
Execution time: 39.10476397629827

[train] Epoch: 7/80 xent: 0.496 softIoU: 8.018 IoU: 0.000 
Execution time: 284.7620301791467

[valid] Epoch: 7/80 xent: 0.507 softIoU: 8.017 IoU: 0.000 
Execution time: 39.30851269420236

[train] Epoch: 8/80 xent: 0.496 softIoU: 8.017 IoU: 0.000 
Execution time: 284.96058411803097

[valid] Epoch: 8/80 xent: 0.506 softIoU: 8.017 IoU: 0.000 
Execution time: 38.9041785239242

[train] Epoch: 9/80 xent: 0.494 softIoU: 8.018 IoU: 0.000 
Execution time: 285.45153276994824

[valid] Epoch: 9/80 xent: 0.505 softIoU: 8.017 IoU: 0.000 
Execution time: 43.30063403118402

[train] Epoch: 10/80 xent: 0.493 softIoU: 8.018 IoU: 0.000 
Execution time: 284.38076588790864

[valid] Epoch: 10/80 xent: 0.503 softIoU: 8.017 IoU: 0.000 
Execution time: 43.107481081970036

[train] Epoch: 11/80 xent: 0.493 softIoU: 8.016 IoU: 0.000 
Execution time: 285.463514925912

[valid] Epoch: 11/80 xent: 0.501 softIoU: 8.018 IoU: 0.000 
Execution time: 43.487655207980424

[train] Epoch: 12/80 xent: 0.489 softIoU: 8.018 IoU: 0.000 
Execution time: 284.57503512874246

[valid] Epoch: 12/80 xent: 0.500 softIoU: 8.017 IoU: 0.000 
Execution time: 38.743305335287005

[train] Epoch: 13/80 xent: 0.488 softIoU: 8.017 IoU: 0.000 
Execution time: 317.94263393618166

[valid] Epoch: 13/80 xent: 0.497 softIoU: 8.017 IoU: 0.000 
Execution time: 38.504840910900384

[train] Epoch: 14/80 xent: 0.485 softIoU: 8.017 IoU: 0.000 
Execution time: 313.71843826025724

[valid] Epoch: 14/80 xent: 0.494 softIoU: 8.018 IoU: 0.000 
Execution time: 42.34490113100037

[train] Epoch: 15/80 xent: 0.480 softIoU: 8.016 IoU: 0.000 
Execution time: 285.1319918814115

[valid] Epoch: 15/80 xent: 0.489 softIoU: 8.017 IoU: 0.000 
Execution time: 42.87131294794381

[train] Epoch: 16/80 xent: 0.475 softIoU: 8.018 IoU: 0.000 
Execution time: 285.2181870560162

[valid] Epoch: 16/80 xent: 0.484 softIoU: 8.016 IoU: 0.000 
Execution time: 39.34911788627505

[train] Epoch: 17/80 xent: 0.467 softIoU: 8.016 IoU: 0.000 
Execution time: 284.86278190277517

[valid] Epoch: 17/80 xent: 0.474 softIoU: 8.016 IoU: 0.000 
Execution time: 39.53032677900046

[train] Epoch: 18/80 xent: 0.456 softIoU: 8.017 IoU: 0.000 
Execution time: 316.5256397067569

[valid] Epoch: 18/80 xent: 0.460 softIoU: 8.015 IoU: 0.000 
Execution time: 39.43705694936216

[train] Epoch: 19/80 xent: 0.439 softIoU: 8.014 IoU: 0.000 
Execution time: 316.7534532742575

[valid] Epoch: 19/80 xent: 0.436 softIoU: 8.016 IoU: 0.000 
Execution time: 39.32542827213183

[train] Epoch: 20/80 xent: 0.403 softIoU: 8.014 IoU: 0.000 
Execution time: 285.45493745803833

[valid] Epoch: 20/80 xent: 0.390 softIoU: 8.012 IoU: 0.000 
Execution time: 38.98864251514897

Saved model at /scratch/sr365/models/catalysth3_mb_2/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-20.pth.tar
[train] Epoch: 21/80 xent: 0.329 softIoU: 8.004 IoU: 0.001 
Execution time: 285.5099423038773

[valid] Epoch: 21/80 xent: 0.258 softIoU: 7.991 IoU: 0.006 
Execution time: 39.143700615968555

[train] Epoch: 22/80 xent: 0.158 softIoU: 7.918 IoU: 0.240 
Execution time: 314.9203044846654

[valid] Epoch: 22/80 xent: 0.090 softIoU: 7.850 IoU: 0.370 
Execution time: 39.168973786756396

[train] Epoch: 23/80 xent: 0.066 softIoU: 7.782 IoU: 0.317 
Execution time: 316.0064287628047

[valid] Epoch: 23/80 xent: 0.054 softIoU: 7.770 IoU: 0.390 
Execution time: 39.16637300839648

[train] Epoch: 24/80 xent: 0.040 softIoU: 7.711 IoU: 0.288 
Execution time: 290.93938051722944

[valid] Epoch: 24/80 xent: 0.037 softIoU: 7.740 IoU: 0.294 
Execution time: 38.99281675508246

[train] Epoch: 25/80 xent: 0.039 softIoU: 7.701 IoU: 0.283 
Execution time: 302.3071740199812

[valid] Epoch: 25/80 xent: 0.059 softIoU: 7.770 IoU: 0.140 
Execution time: 39.43477341718972

[train] Epoch: 26/80 xent: 0.035 softIoU: 7.697 IoU: 0.282 
Execution time: 285.5529221701436

[valid] Epoch: 26/80 xent: 0.044 softIoU: 7.719 IoU: 0.478 
Execution time: 39.539284862112254

[train] Epoch: 27/80 xent: 0.035 softIoU: 7.688 IoU: 0.299 
Execution time: 296.43047792930156

[valid] Epoch: 27/80 xent: 0.052 softIoU: 7.756 IoU: 0.171 
Execution time: 43.47748819133267

[train] Epoch: 28/80 xent: 0.032 softIoU: 7.689 IoU: 0.301 
Execution time: 308.8119923709892

[valid] Epoch: 28/80 xent: 0.034 softIoU: 7.716 IoU: 0.372 
Execution time: 44.307652357034385

[train] Epoch: 29/80 xent: 0.028 softIoU: 7.682 IoU: 0.336 
Execution time: 286.49563076579943

[valid] Epoch: 29/80 xent: 0.033 softIoU: 7.710 IoU: 0.401 
Execution time: 39.422230758704245

[train] Epoch: 30/80 xent: 0.031 softIoU: 7.685 IoU: 0.335 
Execution time: 290.2731824000366

[valid] Epoch: 30/80 xent: 0.039 softIoU: 7.734 IoU: 0.260 
Execution time: 39.00979136116803

[train] Epoch: 31/80 xent: 0.029 softIoU: 7.666 IoU: 0.343 
Execution time: 314.51478000124916

[valid] Epoch: 31/80 xent: 0.031 softIoU: 7.725 IoU: 0.281 
Execution time: 42.919530127663165

[train] Epoch: 32/80 xent: 0.025 softIoU: 7.661 IoU: 0.362 
Execution time: 285.6206629308872

[valid] Epoch: 32/80 xent: 0.034 softIoU: 7.703 IoU: 0.503 
Execution time: 39.29277636669576

[train] Epoch: 33/80 xent: 0.027 softIoU: 7.665 IoU: 0.378 
Execution time: 312.5067048300989

[valid] Epoch: 33/80 xent: 0.028 softIoU: 7.706 IoU: 0.440 
Execution time: 39.19179489603266

[train] Epoch: 34/80 xent: 0.026 softIoU: 7.658 IoU: 0.378 
Execution time: 285.52738393098116

[valid] Epoch: 34/80 xent: 0.031 softIoU: 7.725 IoU: 0.278 
Execution time: 39.23255251906812

[train] Epoch: 35/80 xent: 0.024 softIoU: 7.671 IoU: 0.375 
Execution time: 316.3262581289746

[valid] Epoch: 35/80 xent: 0.029 softIoU: 7.703 IoU: 0.451 
Execution time: 38.852789513766766

[train] Epoch: 36/80 xent: 0.024 softIoU: 7.647 IoU: 0.407 
Execution time: 285.45201157359406

[valid] Epoch: 36/80 xent: 0.029 softIoU: 7.705 IoU: 0.415 
Execution time: 43.36409277608618

[train] Epoch: 37/80 xent: 0.024 softIoU: 7.655 IoU: 0.398 
Execution time: 285.5259918621741

[valid] Epoch: 37/80 xent: 0.031 softIoU: 7.712 IoU: 0.381 
Execution time: 39.093267288058996

[train] Epoch: 38/80 xent: 0.026 softIoU: 7.670 IoU: 0.369 
Execution time: 284.9642340289429

[valid] Epoch: 38/80 xent: 0.030 softIoU: 7.699 IoU: 0.490 
Execution time: 38.73206056281924

[train] Epoch: 39/80 xent: 0.024 softIoU: 7.648 IoU: 0.398 
Execution time: 285.3606490320526

[valid] Epoch: 39/80 xent: 0.036 softIoU: 7.729 IoU: 0.235 
Execution time: 44.95594574930146

[train] Epoch: 40/80 xent: 0.024 softIoU: 7.665 IoU: 0.399 
Execution time: 300.0110643962398

[valid] Epoch: 40/80 xent: 0.027 softIoU: 7.698 IoU: 0.475 
Execution time: 52.01925727305934

Saved model at /scratch/sr365/models/catalysth3_mb_2/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-40.pth.tar
[train] Epoch: 41/80 xent: 0.023 softIoU: 7.673 IoU: 0.429 
Execution time: 291.6899118698202

[valid] Epoch: 41/80 xent: 0.027 softIoU: 7.700 IoU: 0.451 
Execution time: 39.46687027905136

[train] Epoch: 42/80 xent: 0.023 softIoU: 7.656 IoU: 0.438 
Execution time: 297.0290439687669

[valid] Epoch: 42/80 xent: 0.029 softIoU: 7.712 IoU: 0.357 
Execution time: 39.39341504406184

[train] Epoch: 43/80 xent: 0.021 softIoU: 7.664 IoU: 0.411 
Execution time: 285.9584768731147

[valid] Epoch: 43/80 xent: 0.025 softIoU: 7.705 IoU: 0.411 
Execution time: 39.40102404076606

[train] Epoch: 44/80 xent: 0.022 softIoU: 7.655 IoU: 0.447 
Execution time: 285.19511315319687

[valid] Epoch: 44/80 xent: 0.028 softIoU: 7.699 IoU: 0.454 
Execution time: 43.2395806577988

[train] Epoch: 45/80 xent: 0.021 softIoU: 7.662 IoU: 0.448 
Execution time: 285.0681388420053

[valid] Epoch: 45/80 xent: 0.028 softIoU: 7.715 IoU: 0.320 
Execution time: 39.08773995283991

[train] Epoch: 46/80 xent: 0.021 softIoU: 7.655 IoU: 0.413 
Execution time: 310.93555669812486

[valid] Epoch: 46/80 xent: 0.027 softIoU: 7.691 IoU: 0.531 
Execution time: 38.432189454790205

[train] Epoch: 47/80 xent: 0.020 softIoU: 7.650 IoU: 0.462 
Execution time: 284.8938525109552

[valid] Epoch: 47/80 xent: 0.026 softIoU: 7.695 IoU: 0.483 
Execution time: 38.59762690914795

[train] Epoch: 48/80 xent: 0.020 softIoU: 7.654 IoU: 0.458 
Execution time: 285.0051213479601

[valid] Epoch: 48/80 xent: 0.030 softIoU: 7.690 IoU: 0.545 
Execution time: 39.35808203369379

[train] Epoch: 49/80 xent: 0.022 softIoU: 7.649 IoU: 0.435 
Execution time: 284.6327294688672

[valid] Epoch: 49/80 xent: 0.026 softIoU: 7.702 IoU: 0.407 
Execution time: 38.53328842809424

[train] Epoch: 50/80 xent: 0.020 softIoU: 7.653 IoU: 0.447 
Execution time: 287.1829288317822

[valid] Epoch: 50/80 xent: 0.025 softIoU: 7.695 IoU: 0.470 
Execution time: 38.94743186002597

[train] Epoch: 51/80 xent: 0.020 softIoU: 7.658 IoU: 0.457 
Execution time: 285.08700455585495

[valid] Epoch: 51/80 xent: 0.026 softIoU: 7.694 IoU: 0.486 
Execution time: 39.32700088014826

[train] Epoch: 52/80 xent: 0.018 softIoU: 7.638 IoU: 0.469 
Execution time: 285.38990921201184

[valid] Epoch: 52/80 xent: 0.025 softIoU: 7.690 IoU: 0.503 
Execution time: 39.10556231997907

[train] Epoch: 53/80 xent: 0.021 softIoU: 7.657 IoU: 0.461 
Execution time: 285.75676965294406

[valid] Epoch: 53/80 xent: 0.024 softIoU: 7.694 IoU: 0.470 
Execution time: 38.54360863287002

[train] Epoch: 54/80 xent: 0.020 softIoU: 7.644 IoU: 0.457 
Execution time: 316.55353369982913

[valid] Epoch: 54/80 xent: 0.024 softIoU: 7.690 IoU: 0.499 
Execution time: 39.177199294790626

[train] Epoch: 55/80 xent: 0.018 softIoU: 7.634 IoU: 0.457 
Execution time: 306.0772953890264

[valid] Epoch: 55/80 xent: 0.024 softIoU: 7.693 IoU: 0.480 
Execution time: 42.924392519984394

[train] Epoch: 56/80 xent: 0.020 softIoU: 7.665 IoU: 0.453 
Execution time: 284.2705774009228

[valid] Epoch: 56/80 xent: 0.023 softIoU: 7.693 IoU: 0.475 
Execution time: 41.5031835869886

[train] Epoch: 57/80 xent: 0.020 softIoU: 7.656 IoU: 0.461 
Execution time: 284.41616621799767

[valid] Epoch: 57/80 xent: 0.023 softIoU: 7.691 IoU: 0.490 
Execution time: 39.37279111659154

[train] Epoch: 58/80 xent: 0.019 softIoU: 7.662 IoU: 0.449 
Execution time: 287.67369017284364

[valid] Epoch: 58/80 xent: 0.024 softIoU: 7.691 IoU: 0.489 
Execution time: 39.18111405475065

[train] Epoch: 59/80 xent: 0.021 softIoU: 7.653 IoU: 0.470 
Execution time: 285.8561224900186

[valid] Epoch: 59/80 xent: 0.025 softIoU: 7.691 IoU: 0.510 
Execution time: 39.885147073771805

[train] Epoch: 60/80 xent: 0.020 softIoU: 7.652 IoU: 0.466 
Execution time: 304.9560424420051

[valid] Epoch: 60/80 xent: 0.023 softIoU: 7.690 IoU: 0.492 
Execution time: 39.61426144139841

Saved model at /scratch/sr365/models/catalysth3_mb_2/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-60.pth.tar
[train] Epoch: 61/80 xent: 0.020 softIoU: 7.641 IoU: 0.455 
Execution time: 296.57092924416065

[valid] Epoch: 61/80 xent: 0.023 softIoU: 7.690 IoU: 0.501 
Execution time: 43.29015242308378

[train] Epoch: 62/80 xent: 0.020 softIoU: 7.645 IoU: 0.467 
Execution time: 284.51280447421595

[valid] Epoch: 62/80 xent: 0.023 softIoU: 7.690 IoU: 0.490 
Execution time: 43.48660146212205

[train] Epoch: 63/80 xent: 0.019 softIoU: 7.645 IoU: 0.468 
Execution time: 284.6471605747938

[valid] Epoch: 63/80 xent: 0.022 softIoU: 7.688 IoU: 0.503 
Execution time: 42.80102160014212

[train] Epoch: 64/80 xent: 0.019 softIoU: 7.658 IoU: 0.471 
Execution time: 284.97517956094816

[valid] Epoch: 64/80 xent: 0.022 softIoU: 7.689 IoU: 0.491 
Execution time: 44.01386790256947

[train] Epoch: 65/80 xent: 0.021 softIoU: 7.642 IoU: 0.471 
Execution time: 284.8793574706651

[valid] Epoch: 65/80 xent: 0.022 softIoU: 7.693 IoU: 0.468 
Execution time: 38.91134488489479

[train] Epoch: 66/80 xent: 0.019 softIoU: 7.639 IoU: 0.469 
Execution time: 284.4581170543097

[valid] Epoch: 66/80 xent: 0.024 softIoU: 7.687 IoU: 0.517 
Execution time: 42.85035098902881

[train] Epoch: 67/80 xent: 0.018 softIoU: 7.656 IoU: 0.469 
Execution time: 294.95720538077876

[valid] Epoch: 67/80 xent: 0.023 softIoU: 7.688 IoU: 0.506 
Execution time: 38.53968362789601

[train] Epoch: 68/80 xent: 0.021 softIoU: 7.655 IoU: 0.470 
Execution time: 287.6107255979441

[valid] Epoch: 68/80 xent: 0.021 softIoU: 7.696 IoU: 0.443 
Execution time: 42.73380294488743

[train] Epoch: 69/80 xent: 0.018 softIoU: 7.649 IoU: 0.477 
Execution time: 284.2584581496194

[valid] Epoch: 69/80 xent: 0.022 softIoU: 7.691 IoU: 0.482 
Execution time: 39.81177462590858

[train] Epoch: 70/80 xent: 0.020 softIoU: 7.662 IoU: 0.466 
Execution time: 284.29500564187765

[valid] Epoch: 70/80 xent: 0.022 softIoU: 7.689 IoU: 0.487 
Execution time: 38.97615618305281

[train] Epoch: 71/80 xent: 0.019 softIoU: 7.645 IoU: 0.475 
Execution time: 285.8484396156855

[valid] Epoch: 71/80 xent: 0.022 softIoU: 7.689 IoU: 0.499 
Execution time: 43.62301586009562

[train] Epoch: 72/80 xent: 0.021 softIoU: 7.647 IoU: 0.468 
Execution time: 285.0290021612309

[valid] Epoch: 72/80 xent: 0.023 softIoU: 7.688 IoU: 0.508 
Execution time: 39.02560322266072

[train] Epoch: 73/80 xent: 0.018 softIoU: 7.653 IoU: 0.467 
Execution time: 285.0059541640803

[valid] Epoch: 73/80 xent: 0.023 softIoU: 7.690 IoU: 0.498 
Execution time: 39.03079064982012

[train] Epoch: 74/80 xent: 0.020 softIoU: 7.643 IoU: 0.468 
Execution time: 285.64294735202566

[valid] Epoch: 74/80 xent: 0.022 softIoU: 7.692 IoU: 0.471 
Execution time: 43.41952581796795

[train] Epoch: 75/80 xent: 0.020 softIoU: 7.656 IoU: 0.456 
Execution time: 284.8214551266283

[valid] Epoch: 75/80 xent: 0.021 softIoU: 7.693 IoU: 0.470 
Execution time: 39.043062918353826

[train] Epoch: 76/80 xent: 0.018 softIoU: 7.647 IoU: 0.467 
Execution time: 284.19263875391334

[valid] Epoch: 76/80 xent: 0.022 softIoU: 7.690 IoU: 0.489 
Execution time: 39.15656723175198

[train] Epoch: 77/80 xent: 0.021 softIoU: 7.643 IoU: 0.485 
Execution time: 310.58458391577005

[valid] Epoch: 77/80 xent: 0.021 softIoU: 7.689 IoU: 0.487 
Execution time: 39.30611869227141

[train] Epoch: 78/80 xent: 0.018 softIoU: 7.646 IoU: 0.485 
Execution time: 288.6972012971528

[valid] Epoch: 78/80 xent: 0.019 softIoU: 7.693 IoU: 0.458 
Execution time: 39.12222878821194

[train] Epoch: 79/80 xent: 0.019 softIoU: 7.654 IoU: 0.487 
Execution time: 284.4920599120669

[valid] Epoch: 79/80 xent: 0.021 softIoU: 7.690 IoU: 0.485 
Execution time: 43.62531293975189

Saved model at /scratch/sr365/models/catalysth3_mb_2/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-80.pth.tar
Device being used: cuda:0
Finetuning model from /scratch/wh145/models/solarmapper_final/ct/epoch-80.pth.tar
Warning: The following parameters in the pretrained model does not exist in the current model
	 decoder.uc.0.up_conv.weight
	 decoder.uc.0.up_conv.bias
	 decoder.uc.0.conv_1.weight
	 decoder.uc.0.conv_1.bias
	 decoder.uc.0.conv_2.weight
	 decoder.uc.0.conv_2.bias
	 decoder.uc.0.bn_1.weight
	 decoder.uc.0.bn_1.bias
	 decoder.uc.0.bn_1.running_mean
	 decoder.uc.0.bn_1.running_var
	 decoder.uc.0.bn_1.num_batches_tracked
	 decoder.uc.0.bn_2.weight
	 decoder.uc.0.bn_2.bias
	 decoder.uc.0.bn_2.running_mean
	 decoder.uc.0.bn_2.running_var
	 decoder.uc.0.bn_2.num_batches_tracked
	 decoder.uc.0.act.weight
	 decoder.uc.1.up_conv.weight
	 decoder.uc.1.up_conv.bias
	 decoder.uc.1.conv_1.weight
	 decoder.uc.1.conv_1.bias
	 decoder.uc.1.conv_2.weight
	 decoder.uc.1.conv_2.bias
	 decoder.uc.1.bn_1.weight
	 decoder.uc.1.bn_1.bias
	 decoder.uc.1.bn_1.running_mean
	 decoder.uc.1.bn_1.running_var
	 decoder.uc.1.bn_1.num_batches_tracked
	 decoder.uc.1.bn_2.weight
	 decoder.uc.1.bn_2.bias
	 decoder.uc.1.bn_2.running_mean
	 decoder.uc.1.bn_2.running_var
	 decoder.uc.1.bn_2.num_batches_tracked
	 decoder.uc.1.act.weight
	 decoder.uc.2.up_conv.weight
	 decoder.uc.2.up_conv.bias
	 decoder.uc.2.conv_1.weight
	 decoder.uc.2.conv_1.bias
	 decoder.uc.2.conv_2.weight
	 decoder.uc.2.conv_2.bias
	 decoder.uc.2.bn_1.weight
	 decoder.uc.2.bn_1.bias
	 decoder.uc.2.bn_1.running_mean
	 decoder.uc.2.bn_1.running_var
	 decoder.uc.2.bn_1.num_batches_tracked
	 decoder.uc.2.bn_2.weight
	 decoder.uc.2.bn_2.bias
	 decoder.uc.2.bn_2.running_mean
	 decoder.uc.2.bn_2.running_var
	 decoder.uc.2.bn_2.num_batches_tracked
	 decoder.uc.2.act.weight
	 decoder.uc.3.up_conv.weight
	 decoder.uc.3.up_conv.bias
	 decoder.uc.3.conv_1.weight
	 decoder.uc.3.conv_1.bias
	 decoder.uc.3.conv_2.weight
	 decoder.uc.3.conv_2.bias
	 decoder.uc.3.bn_1.weight
	 decoder.uc.3.bn_1.bias
	 decoder.uc.3.bn_1.running_mean
	 decoder.uc.3.bn_1.running_var
	 decoder.uc.3.bn_1.num_batches_tracked
	 decoder.uc.3.bn_2.weight
	 decoder.uc.3.bn_2.bias
	 decoder.uc.3.bn_2.running_mean
	 decoder.uc.3.bn_2.running_var
	 decoder.uc.3.bn_2.num_batches_tracked
	 decoder.uc.3.act.weight
Warning: The following parameters in the current model does not exist in the pretrained model
	 decoder.center_dilation.dconv_1.weight
	 decoder.center_dilation.dconv_1.bias
	 decoder.center_dilation.dconv_2.weight
	 decoder.center_dilation.dconv_2.bias
	 decoder.center_dilation.dconv_3.weight
	 decoder.center_dilation.dconv_3.bias
	 decoder.center_dilation.dconv_4.weight
	 decoder.center_dilation.dconv_4.bias
	 decoder.upsample_1.conv1.weight
	 decoder.upsample_1.conv1.bias
	 decoder.upsample_1.tconv.weight
	 decoder.upsample_1.tconv.bias
	 decoder.upsample_1.conv2.weight
	 decoder.upsample_1.conv2.bias
	 decoder.upsample_2.conv1.weight
	 decoder.upsample_2.conv1.bias
	 decoder.upsample_2.tconv.weight
	 decoder.upsample_2.tconv.bias
	 decoder.upsample_2.conv2.weight
	 decoder.upsample_2.conv2.bias
	 decoder.upsample_3.conv1.weight
	 decoder.upsample_3.conv1.bias
	 decoder.upsample_3.tconv.weight
	 decoder.upsample_3.tconv.bias
	 decoder.upsample_3.conv2.weight
	 decoder.upsample_3.conv2.bias
	 decoder.upsample_4.conv1.weight
	 decoder.upsample_4.conv1.bias
	 decoder.upsample_4.tconv.weight
	 decoder.upsample_4.tconv.bias
	 decoder.upsample_4.conv2.weight
	 decoder.upsample_4.conv2.bias
	 decoder.tconv.weight
	 decoder.tconv.bias
Warning: The size of the following parameters in the current model does not match the ones in the pretrained model
	 decoder.classify.weight
Try loading with relaxed naming rule:
Prefix in pretrained model 
	pretrained param: encoder.conv1.weight -> current param: encoder.conv1.weight
	pretrained param: encoder.bn1.weight -> current param: encoder.bn1.weight
	pretrained param: encoder.bn1.bias -> current param: encoder.bn1.bias
	pretrained param: encoder.bn1.running_mean -> current param: encoder.bn1.running_mean
	pretrained param: encoder.bn1.running_var -> current param: encoder.bn1.running_var
	pretrained param: encoder.bn1.num_batches_tracked -> current param: encoder.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv1.weight -> current param: encoder.layer1.0.conv1.weight
	pretrained param: encoder.layer1.0.bn1.weight -> current param: encoder.layer1.0.bn1.weight
	pretrained param: encoder.layer1.0.bn1.bias -> current param: encoder.layer1.0.bn1.bias
	pretrained param: encoder.layer1.0.bn1.running_mean -> current param: encoder.layer1.0.bn1.running_mean
	pretrained param: encoder.layer1.0.bn1.running_var -> current param: encoder.layer1.0.bn1.running_var
	pretrained param: encoder.layer1.0.bn1.num_batches_tracked -> current param: encoder.layer1.0.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv2.weight -> current param: encoder.layer1.0.conv2.weight
	pretrained param: encoder.layer1.0.bn2.weight -> current param: encoder.layer1.0.bn2.weight
	pretrained param: encoder.layer1.0.bn2.bias -> current param: encoder.layer1.0.bn2.bias
	pretrained param: encoder.layer1.0.bn2.running_mean -> current param: encoder.layer1.0.bn2.running_mean
	pretrained param: encoder.layer1.0.bn2.running_var -> current param: encoder.layer1.0.bn2.running_var
	pretrained param: encoder.layer1.0.bn2.num_batches_tracked -> current param: encoder.layer1.0.bn2.num_batches_tracked
	pretrained param: encoder.layer1.0.conv3.weight -> current param: encoder.layer1.0.conv3.weight
	pretrained param: encoder.layer1.0.bn3.weight -> current param: encoder.layer1.0.bn3.weight
	pretrained param: encoder.layer1.0.bn3.bias -> current param: encoder.layer1.0.bn3.bias
	pretrained param: encoder.layer1.0.bn3.running_mean -> current param: encoder.layer1.0.bn3.running_mean
	pretrained param: encoder.layer1.0.bn3.running_var -> current param: encoder.layer1.0.bn3.running_var
	pretrained param: encoder.layer1.0.bn3.num_batches_tracked -> current param: encoder.layer1.0.bn3.num_batches_tracked
	pretrained param: encoder.layer1.0.downsample.0.weight -> current param: encoder.layer1.0.downsample.0.weight
	pretrained param: encoder.layer1.0.downsample.1.weight -> current param: encoder.layer1.0.downsample.1.weight
	pretrained param: encoder.layer1.0.downsample.1.bias -> current param: encoder.layer1.0.downsample.1.bias
	pretrained param: encoder.layer1.0.downsample.1.running_mean -> current param: encoder.layer1.0.downsample.1.running_mean
	pretrained param: encoder.layer1.0.downsample.1.running_var -> current param: encoder.layer1.0.downsample.1.running_var
	pretrained param: encoder.layer1.0.downsample.1.num_batches_tracked -> current param: encoder.layer1.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv1.weight -> current param: encoder.layer1.1.conv1.weight
	pretrained param: encoder.layer1.1.bn1.weight -> current param: encoder.layer1.1.bn1.weight
	pretrained param: encoder.layer1.1.bn1.bias -> current param: encoder.layer1.1.bn1.bias
	pretrained param: encoder.layer1.1.bn1.running_mean -> current param: encoder.layer1.1.bn1.running_mean
	pretrained param: encoder.layer1.1.bn1.running_var -> current param: encoder.layer1.1.bn1.running_var
	pretrained param: encoder.layer1.1.bn1.num_batches_tracked -> current param: encoder.layer1.1.bn1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv2.weight -> current param: encoder.layer1.1.conv2.weight
	pretrained param: encoder.layer1.1.bn2.weight -> current param: encoder.layer1.1.bn2.weight
	pretrained param: encoder.layer1.1.bn2.bias -> current param: encoder.layer1.1.bn2.bias
	pretrained param: encoder.layer1.1.bn2.running_mean -> current param: encoder.layer1.1.bn2.running_mean
	pretrained param: encoder.layer1.1.bn2.running_var -> current param: encoder.layer1.1.bn2.running_var
	pretrained param: encoder.layer1.1.bn2.num_batches_tracked -> current param: encoder.layer1.1.bn2.num_batches_tracked
	pretrained param: encoder.layer1.1.conv3.weight -> current param: encoder.layer1.1.conv3.weight
	pretrained param: encoder.layer1.1.bn3.weight -> current param: encoder.layer1.1.bn3.weight
	pretrained param: encoder.layer1.1.bn3.bias -> current param: encoder.layer1.1.bn3.bias
	pretrained param: encoder.layer1.1.bn3.running_mean -> current param: encoder.layer1.1.bn3.running_mean
	pretrained param: encoder.layer1.1.bn3.running_var -> current param: encoder.layer1.1.bn3.running_var
	pretrained param: encoder.layer1.1.bn3.num_batches_tracked -> current param: encoder.layer1.1.bn3.num_batches_tracked
	pretrained param: encoder.layer1.2.conv1.weight -> current param: encoder.layer1.2.conv1.weight
	pretrained param: encoder.layer1.2.bn1.weight -> current param: encoder.layer1.2.bn1.weight
	pretrained param: encoder.layer1.2.bn1.bias -> current param: encoder.layer1.2.bn1.bias
	pretrained param: encoder.layer1.2.bn1.running_mean -> current param: encoder.layer1.2.bn1.running_mean
	pretrained param: encoder.layer1.2.bn1.running_var -> current param: encoder.layer1.2.bn1.running_var
	pretrained param: encoder.layer1.2.bn1.num_batches_tracked -> current param: encoder.layer1.2.bn1.num_batches_tracked
	pretrained param: encoder.layer1.2.conv2.weight -> current param: encoder.layer1.2.conv2.weight
	pretrained param: encoder.layer1.2.bn2.weight -> current param: encoder.layer1.2.bn2.weight
	pretrained param: encoder.layer1.2.bn2.bias -> current param: encoder.layer1.2.bn2.bias
	pretrained param: encoder.layer1.2.bn2.running_mean -> current param: encoder.layer1.2.bn2.running_mean
	pretrained param: encoder.layer1.2.bn2.running_var -> current param: encoder.layer1.2.bn2.running_var
	pretrained param: encoder.layer1.2.bn2.num_batches_tracked -> current param: encoder.layer1.2.bn2.num_batches_tracked
	pretrained param: encoder.layer1.2.conv3.weight -> current param: encoder.layer1.2.conv3.weight
	pretrained param: encoder.layer1.2.bn3.weight -> current param: encoder.layer1.2.bn3.weight
	pretrained param: encoder.layer1.2.bn3.bias -> current param: encoder.layer1.2.bn3.bias
	pretrained param: encoder.layer1.2.bn3.running_mean -> current param: encoder.layer1.2.bn3.running_mean
	pretrained param: encoder.layer1.2.bn3.running_var -> current param: encoder.layer1.2.bn3.running_var
	pretrained param: encoder.layer1.2.bn3.num_batches_tracked -> current param: encoder.layer1.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.conv1.weight -> current param: encoder.layer2.0.conv1.weight
	pretrained param: encoder.layer2.0.bn1.weight -> current param: encoder.layer2.0.bn1.weight
	pretrained param: encoder.layer2.0.bn1.bias -> current param: encoder.layer2.0.bn1.bias
	pretrained param: encoder.layer2.0.bn1.running_mean -> current param: encoder.layer2.0.bn1.running_mean
	pretrained param: encoder.layer2.0.bn1.running_var -> current param: encoder.layer2.0.bn1.running_var
	pretrained param: encoder.layer2.0.bn1.num_batches_tracked -> current param: encoder.layer2.0.bn1.num_batches_tracked
	pretrained param: encoder.layer2.0.conv2.weight -> current param: encoder.layer2.0.conv2.weight
	pretrained param: encoder.layer2.0.bn2.weight -> current param: encoder.layer2.0.bn2.weight
	pretrained param: encoder.layer2.0.bn2.bias -> current param: encoder.layer2.0.bn2.bias
	pretrained param: encoder.layer2.0.bn2.running_mean -> current param: encoder.layer2.0.bn2.running_mean
	pretrained param: encoder.layer2.0.bn2.running_var -> current param: encoder.layer2.0.bn2.running_var
	pretrained param: encoder.layer2.0.bn2.num_batches_tracked -> current param: encoder.layer2.0.bn2.num_batches_tracked
	pretrained param: encoder.layer2.0.conv3.weight -> current param: encoder.layer2.0.conv3.weight
	pretrained param: encoder.layer2.0.bn3.weight -> current param: encoder.layer2.0.bn3.weight
	pretrained param: encoder.layer2.0.bn3.bias -> current param: encoder.layer2.0.bn3.bias
	pretrained param: encoder.layer2.0.bn3.running_mean -> current param: encoder.layer2.0.bn3.running_mean
	pretrained param: encoder.layer2.0.bn3.running_var -> current param: encoder.layer2.0.bn3.running_var
	pretrained param: encoder.layer2.0.bn3.num_batches_tracked -> current param: encoder.layer2.0.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.downsample.0.weight -> current param: encoder.layer2.0.downsample.0.weight
	pretrained param: encoder.layer2.0.downsample.1.weight -> current param: encoder.layer2.0.downsample.1.weight
	pretrained param: encoder.layer2.0.downsample.1.bias -> current param: encoder.layer2.0.downsample.1.bias
	pretrained param: encoder.layer2.0.downsample.1.running_mean -> current param: encoder.layer2.0.downsample.1.running_mean
	pretrained param: encoder.layer2.0.downsample.1.running_var -> current param: encoder.layer2.0.downsample.1.running_var
	pretrained param: encoder.layer2.0.downsample.1.num_batches_tracked -> current param: encoder.layer2.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv1.weight -> current param: encoder.layer2.1.conv1.weight
	pretrained param: encoder.layer2.1.bn1.weight -> current param: encoder.layer2.1.bn1.weight
	pretrained param: encoder.layer2.1.bn1.bias -> current param: encoder.layer2.1.bn1.bias
	pretrained param: encoder.layer2.1.bn1.running_mean -> current param: encoder.layer2.1.bn1.running_mean
	pretrained param: encoder.layer2.1.bn1.running_var -> current param: encoder.layer2.1.bn1.running_var
	pretrained param: encoder.layer2.1.bn1.num_batches_tracked -> current param: encoder.layer2.1.bn1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv2.weight -> current param: encoder.layer2.1.conv2.weight
	pretrained param: encoder.layer2.1.bn2.weight -> current param: encoder.layer2.1.bn2.weight
	pretrained param: encoder.layer2.1.bn2.bias -> current param: encoder.layer2.1.bn2.bias
	pretrained param: encoder.layer2.1.bn2.running_mean -> current param: encoder.layer2.1.bn2.running_mean
	pretrained param: encoder.layer2.1.bn2.running_var -> current param: encoder.layer2.1.bn2.running_var
	pretrained param: encoder.layer2.1.bn2.num_batches_tracked -> current param: encoder.layer2.1.bn2.num_batches_tracked
	pretrained param: encoder.layer2.1.conv3.weight -> current param: encoder.layer2.1.conv3.weight
	pretrained param: encoder.layer2.1.bn3.weight -> current param: encoder.layer2.1.bn3.weight
	pretrained param: encoder.layer2.1.bn3.bias -> current param: encoder.layer2.1.bn3.bias
	pretrained param: encoder.layer2.1.bn3.running_mean -> current param: encoder.layer2.1.bn3.running_mean
	pretrained param: encoder.layer2.1.bn3.running_var -> current param: encoder.layer2.1.bn3.running_var
	pretrained param: encoder.layer2.1.bn3.num_batches_tracked -> current param: encoder.layer2.1.bn3.num_batches_tracked
	pretrained param: encoder.layer2.2.conv1.weight -> current param: encoder.layer2.2.conv1.weight
	pretrained param: encoder.layer2.2.bn1.weight -> current param: encoder.layer2.2.bn1.weight
	pretrained param: encoder.layer2.2.bn1.bias -> current param: encoder.layer2.2.bn1.bias
	pretrained param: encoder.layer2.2.bn1.running_mean -> current param: encoder.layer2.2.bn1.running_mean
	pretrained param: encoder.layer2.2.bn1.running_var -> current param: encoder.layer2.2.bn1.running_var
	pretrained param: encoder.layer2.2.bn1.num_batches_tracked -> current param: encoder.layer2.2.bn1.num_batches_tracked
	pretrained param: encoder.layer2.2.conv2.weight -> current param: encoder.layer2.2.conv2.weight
	pretrained param: encoder.layer2.2.bn2.weight -> current param: encoder.layer2.2.bn2.weight
	pretrained param: encoder.layer2.2.bn2.bias -> current param: encoder.layer2.2.bn2.bias
	pretrained param: encoder.layer2.2.bn2.running_mean -> current param: encoder.layer2.2.bn2.running_mean
	pretrained param: encoder.layer2.2.bn2.running_var -> current param: encoder.layer2.2.bn2.running_var
	pretrained param: encoder.layer2.2.bn2.num_batches_tracked -> current param: encoder.layer2.2.bn2.num_batches_tracked
	pretrained param: encoder.layer2.2.conv3.weight -> current param: encoder.layer2.2.conv3.weight
	pretrained param: encoder.layer2.2.bn3.weight -> current param: encoder.layer2.2.bn3.weight
	pretrained param: encoder.layer2.2.bn3.bias -> current param: encoder.layer2.2.bn3.bias
	pretrained param: encoder.layer2.2.bn3.running_mean -> current param: encoder.layer2.2.bn3.running_mean
	pretrained param: encoder.layer2.2.bn3.running_var -> current param: encoder.layer2.2.bn3.running_var
	pretrained param: encoder.layer2.2.bn3.num_batches_tracked -> current param: encoder.layer2.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.3.conv1.weight -> current param: encoder.layer2.3.conv1.weight
	pretrained param: encoder.layer2.3.bn1.weight -> current param: encoder.layer2.3.bn1.weight
	pretrained param: encoder.layer2.3.bn1.bias -> current param: encoder.layer2.3.bn1.bias
	pretrained param: encoder.layer2.3.bn1.running_mean -> current param: encoder.layer2.3.bn1.running_mean
	pretrained param: encoder.layer2.3.bn1.running_var -> current param: encoder.layer2.3.bn1.running_var
	pretrained param: encoder.layer2.3.bn1.num_batches_tracked -> current param: encoder.layer2.3.bn1.num_batches_tracked
	pretrained param: encoder.layer2.3.conv2.weight -> current param: encoder.layer2.3.conv2.weight
	pretrained param: encoder.layer2.3.bn2.weight -> current param: encoder.layer2.3.bn2.weight
	pretrained param: encoder.layer2.3.bn2.bias -> current param: encoder.layer2.3.bn2.bias
	pretrained param: encoder.layer2.3.bn2.running_mean -> current param: encoder.layer2.3.bn2.running_mean
	pretrained param: encoder.layer2.3.bn2.running_var -> current param: encoder.layer2.3.bn2.running_var
	pretrained param: encoder.layer2.3.bn2.num_batches_tracked -> current param: encoder.layer2.3.bn2.num_batches_tracked
	pretrained param: encoder.layer2.3.conv3.weight -> current param: encoder.layer2.3.conv3.weight
	pretrained param: encoder.layer2.3.bn3.weight -> current param: encoder.layer2.3.bn3.weight
	pretrained param: encoder.layer2.3.bn3.bias -> current param: encoder.layer2.3.bn3.bias
	pretrained param: encoder.layer2.3.bn3.running_mean -> current param: encoder.layer2.3.bn3.running_mean
	pretrained param: encoder.layer2.3.bn3.running_var -> current param: encoder.layer2.3.bn3.running_var
	pretrained param: encoder.layer2.3.bn3.num_batches_tracked -> current param: encoder.layer2.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.conv1.weight -> current param: encoder.layer3.0.conv1.weight
	pretrained param: encoder.layer3.0.bn1.weight -> current param: encoder.layer3.0.bn1.weight
	pretrained param: encoder.layer3.0.bn1.bias -> current param: encoder.layer3.0.bn1.bias
	pretrained param: encoder.layer3.0.bn1.running_mean -> current param: encoder.layer3.0.bn1.running_mean
	pretrained param: encoder.layer3.0.bn1.running_var -> current param: encoder.layer3.0.bn1.running_var
	pretrained param: encoder.layer3.0.bn1.num_batches_tracked -> current param: encoder.layer3.0.bn1.num_batches_tracked
	pretrained param: encoder.layer3.0.conv2.weight -> current param: encoder.layer3.0.conv2.weight
	pretrained param: encoder.layer3.0.bn2.weight -> current param: encoder.layer3.0.bn2.weight
	pretrained param: encoder.layer3.0.bn2.bias -> current param: encoder.layer3.0.bn2.bias
	pretrained param: encoder.layer3.0.bn2.running_mean -> current param: encoder.layer3.0.bn2.running_mean
	pretrained param: encoder.layer3.0.bn2.running_var -> current param: encoder.layer3.0.bn2.running_var
	pretrained param: encoder.layer3.0.bn2.num_batches_tracked -> current param: encoder.layer3.0.bn2.num_batches_tracked
	pretrained param: encoder.layer3.0.conv3.weight -> current param: encoder.layer3.0.conv3.weight
	pretrained param: encoder.layer3.0.bn3.weight -> current param: encoder.layer3.0.bn3.weight
	pretrained param: encoder.layer3.0.bn3.bias -> current param: encoder.layer3.0.bn3.bias
	pretrained param: encoder.layer3.0.bn3.running_mean -> current param: encoder.layer3.0.bn3.running_mean
	pretrained param: encoder.layer3.0.bn3.running_var -> current param: encoder.layer3.0.bn3.running_var
	pretrained param: encoder.layer3.0.bn3.num_batches_tracked -> current param: encoder.layer3.0.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.downsample.0.weight -> current param: encoder.layer3.0.downsample.0.weight
	pretrained param: encoder.layer3.0.downsample.1.weight -> current param: encoder.layer3.0.downsample.1.weight
	pretrained param: encoder.layer3.0.downsample.1.bias -> current param: encoder.layer3.0.downsample.1.bias
	pretrained param: encoder.layer3.0.downsample.1.running_mean -> current param: encoder.layer3.0.downsample.1.running_mean
	pretrained param: encoder.layer3.0.downsample.1.running_var -> current param: encoder.layer3.0.downsample.1.running_var
	pretrained param: encoder.layer3.0.downsample.1.num_batches_tracked -> current param: encoder.layer3.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv1.weight -> current param: encoder.layer3.1.conv1.weight
	pretrained param: encoder.layer3.1.bn1.weight -> current param: encoder.layer3.1.bn1.weight
	pretrained param: encoder.layer3.1.bn1.bias -> current param: encoder.layer3.1.bn1.bias
	pretrained param: encoder.layer3.1.bn1.running_mean -> current param: encoder.layer3.1.bn1.running_mean
	pretrained param: encoder.layer3.1.bn1.running_var -> current param: encoder.layer3.1.bn1.running_var
	pretrained param: encoder.layer3.1.bn1.num_batches_tracked -> current param: encoder.layer3.1.bn1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv2.weight -> current param: encoder.layer3.1.conv2.weight
	pretrained param: encoder.layer3.1.bn2.weight -> current param: encoder.layer3.1.bn2.weight
	pretrained param: encoder.layer3.1.bn2.bias -> current param: encoder.layer3.1.bn2.bias
	pretrained param: encoder.layer3.1.bn2.running_mean -> current param: encoder.layer3.1.bn2.running_mean
	pretrained param: encoder.layer3.1.bn2.running_var -> current param: encoder.layer3.1.bn2.running_var
	pretrained param: encoder.layer3.1.bn2.num_batches_tracked -> current param: encoder.layer3.1.bn2.num_batches_tracked
	pretrained param: encoder.layer3.1.conv3.weight -> current param: encoder.layer3.1.conv3.weight
	pretrained param: encoder.layer3.1.bn3.weight -> current param: encoder.layer3.1.bn3.weight
	pretrained param: encoder.layer3.1.bn3.bias -> current param: encoder.layer3.1.bn3.bias
	pretrained param: encoder.layer3.1.bn3.running_mean -> current param: encoder.layer3.1.bn3.running_mean
	pretrained param: encoder.layer3.1.bn3.running_var -> current param: encoder.layer3.1.bn3.running_var
	pretrained param: encoder.layer3.1.bn3.num_batches_tracked -> current param: encoder.layer3.1.bn3.num_batches_tracked
	pretrained param: encoder.layer3.2.conv1.weight -> current param: encoder.layer3.2.conv1.weight
	pretrained param: encoder.layer3.2.bn1.weight -> current param: encoder.layer3.2.bn1.weight
	pretrained param: encoder.layer3.2.bn1.bias -> current param: encoder.layer3.2.bn1.bias
	pretrained param: encoder.layer3.2.bn1.running_mean -> current param: encoder.layer3.2.bn1.running_mean
	pretrained param: encoder.layer3.2.bn1.running_var -> current param: encoder.layer3.2.bn1.running_var
	pretrained param: encoder.layer3.2.bn1.num_batches_tracked -> current param: encoder.layer3.2.bn1.num_batches_tracked
	pretrained param: encoder.layer3.2.conv2.weight -> current param: encoder.layer3.2.conv2.weight
	pretrained param: encoder.layer3.2.bn2.weight -> current param: encoder.layer3.2.bn2.weight
	pretrained param: encoder.layer3.2.bn2.bias -> current param: encoder.layer3.2.bn2.bias
	pretrained param: encoder.layer3.2.bn2.running_mean -> current param: encoder.layer3.2.bn2.running_mean
	pretrained param: encoder.layer3.2.bn2.running_var -> current param: encoder.layer3.2.bn2.running_var
	pretrained param: encoder.layer3.2.bn2.num_batches_tracked -> current param: encoder.layer3.2.bn2.num_batches_tracked
	pretrained param: encoder.layer3.2.conv3.weight -> current param: encoder.layer3.2.conv3.weight
	pretrained param: encoder.layer3.2.bn3.weight -> current param: encoder.layer3.2.bn3.weight
	pretrained param: encoder.layer3.2.bn3.bias -> current param: encoder.layer3.2.bn3.bias
	pretrained param: encoder.layer3.2.bn3.running_mean -> current param: encoder.layer3.2.bn3.running_mean
	pretrained param: encoder.layer3.2.bn3.running_var -> current param: encoder.layer3.2.bn3.running_var
	pretrained param: encoder.layer3.2.bn3.num_batches_tracked -> current param: encoder.layer3.2.bn3.num_batches_tracked
	pretrained param: encoder.layer3.3.conv1.weight -> current param: encoder.layer3.3.conv1.weight
	pretrained param: encoder.layer3.3.bn1.weight -> current param: encoder.layer3.3.bn1.weight
	pretrained param: encoder.layer3.3.bn1.bias -> current param: encoder.layer3.3.bn1.bias
	pretrained param: encoder.layer3.3.bn1.running_mean -> current param: encoder.layer3.3.bn1.running_mean
	pretrained param: encoder.layer3.3.bn1.running_var -> current param: encoder.layer3.3.bn1.running_var
	pretrained param: encoder.layer3.3.bn1.num_batches_tracked -> current param: encoder.layer3.3.bn1.num_batches_tracked
	pretrained param: encoder.layer3.3.conv2.weight -> current param: encoder.layer3.3.conv2.weight
	pretrained param: encoder.layer3.3.bn2.weight -> current param: encoder.layer3.3.bn2.weight
	pretrained param: encoder.layer3.3.bn2.bias -> current param: encoder.layer3.3.bn2.bias
	pretrained param: encoder.layer3.3.bn2.running_mean -> current param: encoder.layer3.3.bn2.running_mean
	pretrained param: encoder.layer3.3.bn2.running_var -> current param: encoder.layer3.3.bn2.running_var
	pretrained param: encoder.layer3.3.bn2.num_batches_tracked -> current param: encoder.layer3.3.bn2.num_batches_tracked
	pretrained param: encoder.layer3.3.conv3.weight -> current param: encoder.layer3.3.conv3.weight
	pretrained param: encoder.layer3.3.bn3.weight -> current param: encoder.layer3.3.bn3.weight
	pretrained param: encoder.layer3.3.bn3.bias -> current param: encoder.layer3.3.bn3.bias
	pretrained param: encoder.layer3.3.bn3.running_mean -> current param: encoder.layer3.3.bn3.running_mean
	pretrained param: encoder.layer3.3.bn3.running_var -> current param: encoder.layer3.3.bn3.running_var
	pretrained param: encoder.layer3.3.bn3.num_batches_tracked -> current param: encoder.layer3.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.4.conv1.weight -> current param: encoder.layer3.4.conv1.weight
	pretrained param: encoder.layer3.4.bn1.weight -> current param: encoder.layer3.4.bn1.weight
	pretrained param: encoder.layer3.4.bn1.bias -> current param: encoder.layer3.4.bn1.bias
	pretrained param: encoder.layer3.4.bn1.running_mean -> current param: encoder.layer3.4.bn1.running_mean
	pretrained param: encoder.layer3.4.bn1.running_var -> current param: encoder.layer3.4.bn1.running_var
	pretrained param: encoder.layer3.4.bn1.num_batches_tracked -> current param: encoder.layer3.4.bn1.num_batches_tracked
	pretrained param: encoder.layer3.4.conv2.weight -> current param: encoder.layer3.4.conv2.weight
	pretrained param: encoder.layer3.4.bn2.weight -> current param: encoder.layer3.4.bn2.weight
	pretrained param: encoder.layer3.4.bn2.bias -> current param: encoder.layer3.4.bn2.bias
	pretrained param: encoder.layer3.4.bn2.running_mean -> current param: encoder.layer3.4.bn2.running_mean
	pretrained param: encoder.layer3.4.bn2.running_var -> current param: encoder.layer3.4.bn2.running_var
	pretrained param: encoder.layer3.4.bn2.num_batches_tracked -> current param: encoder.layer3.4.bn2.num_batches_tracked
	pretrained param: encoder.layer3.4.conv3.weight -> current param: encoder.layer3.4.conv3.weight
	pretrained param: encoder.layer3.4.bn3.weight -> current param: encoder.layer3.4.bn3.weight
	pretrained param: encoder.layer3.4.bn3.bias -> current param: encoder.layer3.4.bn3.bias
	pretrained param: encoder.layer3.4.bn3.running_mean -> current param: encoder.layer3.4.bn3.running_mean
	pretrained param: encoder.layer3.4.bn3.running_var -> current param: encoder.layer3.4.bn3.running_var
	pretrained param: encoder.layer3.4.bn3.num_batches_tracked -> current param: encoder.layer3.4.bn3.num_batches_tracked
	pretrained param: encoder.layer3.5.conv1.weight -> current param: encoder.layer3.5.conv1.weight
	pretrained param: encoder.layer3.5.bn1.weight -> current param: encoder.layer3.5.bn1.weight
	pretrained param: encoder.layer3.5.bn1.bias -> current param: encoder.layer3.5.bn1.bias
	pretrained param: encoder.layer3.5.bn1.running_mean -> current param: encoder.layer3.5.bn1.running_mean
	pretrained param: encoder.layer3.5.bn1.running_var -> current param: encoder.layer3.5.bn1.running_var
	pretrained param: encoder.layer3.5.bn1.num_batches_tracked -> current param: encoder.layer3.5.bn1.num_batches_tracked
	pretrained param: encoder.layer3.5.conv2.weight -> current param: encoder.layer3.5.conv2.weight
	pretrained param: encoder.layer3.5.bn2.weight -> current param: encoder.layer3.5.bn2.weight
	pretrained param: encoder.layer3.5.bn2.bias -> current param: encoder.layer3.5.bn2.bias
	pretrained param: encoder.layer3.5.bn2.running_mean -> current param: encoder.layer3.5.bn2.running_mean
	pretrained param: encoder.layer3.5.bn2.running_var -> current param: encoder.layer3.5.bn2.running_var
	pretrained param: encoder.layer3.5.bn2.num_batches_tracked -> current param: encoder.layer3.5.bn2.num_batches_tracked
	pretrained param: encoder.layer3.5.conv3.weight -> current param: encoder.layer3.5.conv3.weight
	pretrained param: encoder.layer3.5.bn3.weight -> current param: encoder.layer3.5.bn3.weight
	pretrained param: encoder.layer3.5.bn3.bias -> current param: encoder.layer3.5.bn3.bias
	pretrained param: encoder.layer3.5.bn3.running_mean -> current param: encoder.layer3.5.bn3.running_mean
	pretrained param: encoder.layer3.5.bn3.running_var -> current param: encoder.layer3.5.bn3.running_var
	pretrained param: encoder.layer3.5.bn3.num_batches_tracked -> current param: encoder.layer3.5.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.conv1.weight -> current param: encoder.layer4.0.conv1.weight
	pretrained param: encoder.layer4.0.bn1.weight -> current param: encoder.layer4.0.bn1.weight
	pretrained param: encoder.layer4.0.bn1.bias -> current param: encoder.layer4.0.bn1.bias
	pretrained param: encoder.layer4.0.bn1.running_mean -> current param: encoder.layer4.0.bn1.running_mean
	pretrained param: encoder.layer4.0.bn1.running_var -> current param: encoder.layer4.0.bn1.running_var
	pretrained param: encoder.layer4.0.bn1.num_batches_tracked -> current param: encoder.layer4.0.bn1.num_batches_tracked
	pretrained param: encoder.layer4.0.conv2.weight -> current param: encoder.layer4.0.conv2.weight
	pretrained param: encoder.layer4.0.bn2.weight -> current param: encoder.layer4.0.bn2.weight
	pretrained param: encoder.layer4.0.bn2.bias -> current param: encoder.layer4.0.bn2.bias
	pretrained param: encoder.layer4.0.bn2.running_mean -> current param: encoder.layer4.0.bn2.running_mean
	pretrained param: encoder.layer4.0.bn2.running_var -> current param: encoder.layer4.0.bn2.running_var
	pretrained param: encoder.layer4.0.bn2.num_batches_tracked -> current param: encoder.layer4.0.bn2.num_batches_tracked
	pretrained param: encoder.layer4.0.conv3.weight -> current param: encoder.layer4.0.conv3.weight
	pretrained param: encoder.layer4.0.bn3.weight -> current param: encoder.layer4.0.bn3.weight
	pretrained param: encoder.layer4.0.bn3.bias -> current param: encoder.layer4.0.bn3.bias
	pretrained param: encoder.layer4.0.bn3.running_mean -> current param: encoder.layer4.0.bn3.running_mean
	pretrained param: encoder.layer4.0.bn3.running_var -> current param: encoder.layer4.0.bn3.running_var
	pretrained param: encoder.layer4.0.bn3.num_batches_tracked -> current param: encoder.layer4.0.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.downsample.0.weight -> current param: encoder.layer4.0.downsample.0.weight
	pretrained param: encoder.layer4.0.downsample.1.weight -> current param: encoder.layer4.0.downsample.1.weight
	pretrained param: encoder.layer4.0.downsample.1.bias -> current param: encoder.layer4.0.downsample.1.bias
	pretrained param: encoder.layer4.0.downsample.1.running_mean -> current param: encoder.layer4.0.downsample.1.running_mean
	pretrained param: encoder.layer4.0.downsample.1.running_var -> current param: encoder.layer4.0.downsample.1.running_var
	pretrained param: encoder.layer4.0.downsample.1.num_batches_tracked -> current param: encoder.layer4.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv1.weight -> current param: encoder.layer4.1.conv1.weight
	pretrained param: encoder.layer4.1.bn1.weight -> current param: encoder.layer4.1.bn1.weight
	pretrained param: encoder.layer4.1.bn1.bias -> current param: encoder.layer4.1.bn1.bias
	pretrained param: encoder.layer4.1.bn1.running_mean -> current param: encoder.layer4.1.bn1.running_mean
	pretrained param: encoder.layer4.1.bn1.running_var -> current param: encoder.layer4.1.bn1.running_var
	pretrained param: encoder.layer4.1.bn1.num_batches_tracked -> current param: encoder.layer4.1.bn1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv2.weight -> current param: encoder.layer4.1.conv2.weight
	pretrained param: encoder.layer4.1.bn2.weight -> current param: encoder.layer4.1.bn2.weight
	pretrained param: encoder.layer4.1.bn2.bias -> current param: encoder.layer4.1.bn2.bias
	pretrained param: encoder.layer4.1.bn2.running_mean -> current param: encoder.layer4.1.bn2.running_mean
	pretrained param: encoder.layer4.1.bn2.running_var -> current param: encoder.layer4.1.bn2.running_var
	pretrained param: encoder.layer4.1.bn2.num_batches_tracked -> current param: encoder.layer4.1.bn2.num_batches_tracked
	pretrained param: encoder.layer4.1.conv3.weight -> current param: encoder.layer4.1.conv3.weight
	pretrained param: encoder.layer4.1.bn3.weight -> current param: encoder.layer4.1.bn3.weight
	pretrained param: encoder.layer4.1.bn3.bias -> current param: encoder.layer4.1.bn3.bias
	pretrained param: encoder.layer4.1.bn3.running_mean -> current param: encoder.layer4.1.bn3.running_mean
	pretrained param: encoder.layer4.1.bn3.running_var -> current param: encoder.layer4.1.bn3.running_var
	pretrained param: encoder.layer4.1.bn3.num_batches_tracked -> current param: encoder.layer4.1.bn3.num_batches_tracked
	pretrained param: encoder.layer4.2.conv1.weight -> current param: encoder.layer4.2.conv1.weight
	pretrained param: encoder.layer4.2.bn1.weight -> current param: encoder.layer4.2.bn1.weight
	pretrained param: encoder.layer4.2.bn1.bias -> current param: encoder.layer4.2.bn1.bias
	pretrained param: encoder.layer4.2.bn1.running_mean -> current param: encoder.layer4.2.bn1.running_mean
	pretrained param: encoder.layer4.2.bn1.running_var -> current param: encoder.layer4.2.bn1.running_var
	pretrained param: encoder.layer4.2.bn1.num_batches_tracked -> current param: encoder.layer4.2.bn1.num_batches_tracked
	pretrained param: encoder.layer4.2.conv2.weight -> current param: encoder.layer4.2.conv2.weight
	pretrained param: encoder.layer4.2.bn2.weight -> current param: encoder.layer4.2.bn2.weight
	pretrained param: encoder.layer4.2.bn2.bias -> current param: encoder.layer4.2.bn2.bias
	pretrained param: encoder.layer4.2.bn2.running_mean -> current param: encoder.layer4.2.bn2.running_mean
	pretrained param: encoder.layer4.2.bn2.running_var -> current param: encoder.layer4.2.bn2.running_var
	pretrained param: encoder.layer4.2.bn2.num_batches_tracked -> current param: encoder.layer4.2.bn2.num_batches_tracked
	pretrained param: encoder.layer4.2.conv3.weight -> current param: encoder.layer4.2.conv3.weight
	pretrained param: encoder.layer4.2.bn3.weight -> current param: encoder.layer4.2.bn3.weight
	pretrained param: encoder.layer4.2.bn3.bias -> current param: encoder.layer4.2.bn3.bias
	pretrained param: encoder.layer4.2.bn3.running_mean -> current param: encoder.layer4.2.bn3.running_mean
	pretrained param: encoder.layer4.2.bn3.running_var -> current param: encoder.layer4.2.bn3.running_var
	pretrained param: encoder.layer4.2.bn3.num_batches_tracked -> current param: encoder.layer4.2.bn3.num_batches_tracked
	pretrained param: decoder.classify.weight -> current param: decoder.classify.weight
		Ignoring: decoder.classify.weight->decoder.classify.weight (size mismatch)
	pretrained param: decoder.classify.bias -> current param: decoder.classify.bias
90.11% of the model loaded from the pretrained
Total params: 179.77M
Dataset catalyst_h3 is not supported, use default mean stats instead
Training model on the catalyst_h3 dataset
Dataset catalyst_h3 is not supported, use default mean stats instead
[train] Epoch: 0/80 xent: 1.529 softIoU: 8.303 IoU: 0.000 
Execution time: 304.69298503687605

[valid] Epoch: 0/80 xent: 0.465 softIoU: 7.750 IoU: 0.000 
Execution time: 44.08500457415357

[train] Epoch: 1/80 xent: 0.503 softIoU: 8.018 IoU: 0.000 
Execution time: 282.97919180803

[valid] Epoch: 1/80 xent: 0.464 softIoU: 7.750 IoU: 0.000 
Execution time: 40.14292147569358

[train] Epoch: 2/80 xent: 0.503 softIoU: 8.017 IoU: 0.000 
Execution time: 282.8845258723013

[valid] Epoch: 2/80 xent: 0.464 softIoU: 7.750 IoU: 0.000 
Execution time: 44.5131747382693

[train] Epoch: 3/80 xent: 0.502 softIoU: 8.018 IoU: 0.000 
Execution time: 283.6587293311022

[valid] Epoch: 3/80 xent: 0.463 softIoU: 7.752 IoU: 0.000 
Execution time: 40.214606061112136

[train] Epoch: 4/80 xent: 0.500 softIoU: 8.019 IoU: 0.000 
Execution time: 283.0174271641299

[valid] Epoch: 4/80 xent: 0.462 softIoU: 7.750 IoU: 0.000 
Execution time: 40.18045085994527

[train] Epoch: 5/80 xent: 0.501 softIoU: 8.018 IoU: 0.000 
Execution time: 282.46514802007005

[valid] Epoch: 5/80 xent: 0.461 softIoU: 7.751 IoU: 0.000 
Execution time: 43.7188407080248

[train] Epoch: 6/80 xent: 0.499 softIoU: 8.018 IoU: 0.000 
Execution time: 292.4242071104236

[valid] Epoch: 6/80 xent: 0.461 softIoU: 7.751 IoU: 0.000 
Execution time: 40.163233598228544

[train] Epoch: 7/80 xent: 0.498 softIoU: 8.018 IoU: 0.000 
Execution time: 282.5340278618969

[valid] Epoch: 7/80 xent: 0.460 softIoU: 7.750 IoU: 0.000 
Execution time: 40.274635998066515

[train] Epoch: 8/80 xent: 0.497 softIoU: 8.016 IoU: 0.000 
Execution time: 283.06920355791226

[valid] Epoch: 8/80 xent: 0.459 softIoU: 7.752 IoU: 0.000 
Execution time: 39.73424937808886

[train] Epoch: 9/80 xent: 0.496 softIoU: 8.019 IoU: 0.000 
Execution time: 294.906160896644

[valid] Epoch: 9/80 xent: 0.458 softIoU: 7.751 IoU: 0.000 
Execution time: 44.789714514277875

[train] Epoch: 10/80 xent: 0.495 softIoU: 8.017 IoU: 0.000 
Execution time: 282.71911758184433

[valid] Epoch: 10/80 xent: 0.456 softIoU: 7.751 IoU: 0.000 
Execution time: 40.01052492624149

[train] Epoch: 11/80 xent: 0.493 softIoU: 8.018 IoU: 0.000 
Execution time: 283.8263988690451

[valid] Epoch: 11/80 xent: 0.455 softIoU: 7.751 IoU: 0.000 
Execution time: 43.909813980106264

[train] Epoch: 12/80 xent: 0.492 softIoU: 8.018 IoU: 0.000 
Execution time: 309.6872759810649

[valid] Epoch: 12/80 xent: 0.453 softIoU: 7.752 IoU: 0.000 
Execution time: 43.938437442760915

[train] Epoch: 13/80 xent: 0.490 softIoU: 8.018 IoU: 0.000 
Execution time: 283.1238574432209

[valid] Epoch: 13/80 xent: 0.451 softIoU: 7.752 IoU: 0.000 
Execution time: 39.54876052774489

[train] Epoch: 14/80 xent: 0.486 softIoU: 8.017 IoU: 0.000 
Execution time: 315.77204030100256

[valid] Epoch: 14/80 xent: 0.448 softIoU: 7.750 IoU: 0.000 
Execution time: 44.20662338798866

[train] Epoch: 15/80 xent: 0.482 softIoU: 8.017 IoU: 0.000 
Execution time: 283.0567190060392

[valid] Epoch: 15/80 xent: 0.444 softIoU: 7.750 IoU: 0.000 
Execution time: 39.61927690496668

[train] Epoch: 16/80 xent: 0.476 softIoU: 8.017 IoU: 0.000 
Execution time: 314.72272402700037

[valid] Epoch: 16/80 xent: 0.437 softIoU: 7.751 IoU: 0.000 
Execution time: 44.20706116128713

[train] Epoch: 17/80 xent: 0.468 softIoU: 8.017 IoU: 0.000 
Execution time: 307.12816398683935

[valid] Epoch: 17/80 xent: 0.429 softIoU: 7.749 IoU: 0.000 
Execution time: 40.01919744396582

[train] Epoch: 18/80 xent: 0.457 softIoU: 8.016 IoU: 0.000 
Execution time: 283.0554503388703

[valid] Epoch: 18/80 xent: 0.415 softIoU: 7.749 IoU: 0.000 
Execution time: 40.1664861459285

[train] Epoch: 19/80 xent: 0.435 softIoU: 8.015 IoU: 0.000 
Execution time: 284.50598485115916

[valid] Epoch: 19/80 xent: 0.390 softIoU: 7.748 IoU: 0.000 
Execution time: 41.507522765081376

[train] Epoch: 20/80 xent: 0.396 softIoU: 8.013 IoU: 0.000 
Execution time: 291.22708752797917

[valid] Epoch: 20/80 xent: 0.337 softIoU: 7.743 IoU: 0.000 
Execution time: 40.04318369179964

Saved model at /scratch/sr365/models/catalysth3_mb_3/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-20.pth.tar
[train] Epoch: 21/80 xent: 0.300 softIoU: 7.998 IoU: 0.004 
Execution time: 282.96233596419916

[valid] Epoch: 21/80 xent: 0.216 softIoU: 7.708 IoU: 0.013 
Execution time: 43.8975294129923

[train] Epoch: 22/80 xent: 0.126 softIoU: 7.887 IoU: 0.255 
Execution time: 300.12873712787405

[valid] Epoch: 22/80 xent: 0.080 softIoU: 7.550 IoU: 0.393 
Execution time: 40.2662349822931

[train] Epoch: 23/80 xent: 0.053 softIoU: 7.754 IoU: 0.311 
Execution time: 294.44897474208847

[valid] Epoch: 23/80 xent: 0.041 softIoU: 7.472 IoU: 0.318 
Execution time: 43.624751144088805

[train] Epoch: 24/80 xent: 0.040 softIoU: 7.703 IoU: 0.276 
Execution time: 297.9335963013582

[valid] Epoch: 24/80 xent: 0.036 softIoU: 7.459 IoU: 0.395 
Execution time: 44.76587856980041

[train] Epoch: 25/80 xent: 0.035 softIoU: 7.691 IoU: 0.315 
Execution time: 294.8940672678873

[valid] Epoch: 25/80 xent: 0.029 softIoU: 7.449 IoU: 0.344 
Execution time: 42.650130197871476

[train] Epoch: 26/80 xent: 0.030 softIoU: 7.685 IoU: 0.325 
Execution time: 297.8532452150248

[valid] Epoch: 26/80 xent: 0.031 softIoU: 7.446 IoU: 0.307 
Execution time: 43.81150162406266

[train] Epoch: 27/80 xent: 0.032 softIoU: 7.680 IoU: 0.328 
Execution time: 300.51630481285974

[valid] Epoch: 27/80 xent: 0.030 softIoU: 7.442 IoU: 0.368 
Execution time: 43.5292868828401

[train] Epoch: 28/80 xent: 0.028 softIoU: 7.680 IoU: 0.337 
Execution time: 296.8570477985777

[valid] Epoch: 28/80 xent: 0.028 softIoU: 7.443 IoU: 0.381 
Execution time: 43.5112638277933

[train] Epoch: 29/80 xent: 0.031 softIoU: 7.690 IoU: 0.328 
Execution time: 297.76922223111615

[valid] Epoch: 29/80 xent: 0.029 softIoU: 7.440 IoU: 0.409 
Execution time: 43.303797472734004

[train] Epoch: 30/80 xent: 0.029 softIoU: 7.676 IoU: 0.332 
Execution time: 298.2451182901859

[valid] Epoch: 30/80 xent: 0.025 softIoU: 7.443 IoU: 0.365 
Execution time: 42.007837411016226

[train] Epoch: 31/80 xent: 0.027 softIoU: 7.659 IoU: 0.385 
Execution time: 291.23800136707723

[valid] Epoch: 31/80 xent: 0.027 softIoU: 7.440 IoU: 0.353 
Execution time: 42.45314268581569

[train] Epoch: 32/80 xent: 0.027 softIoU: 7.662 IoU: 0.350 
Execution time: 293.3628609199077

[valid] Epoch: 32/80 xent: 0.029 softIoU: 7.435 IoU: 0.453 
Execution time: 42.109602654818445

[train] Epoch: 33/80 xent: 0.028 softIoU: 7.668 IoU: 0.378 
Execution time: 293.45172251807526

[valid] Epoch: 33/80 xent: 0.029 softIoU: 7.440 IoU: 0.359 
Execution time: 41.45150652201846

[train] Epoch: 34/80 xent: 0.023 softIoU: 7.663 IoU: 0.395 
Execution time: 291.53418166423216

[valid] Epoch: 34/80 xent: 0.030 softIoU: 7.441 IoU: 0.335 
Execution time: 41.11467396002263

[train] Epoch: 35/80 xent: 0.024 softIoU: 7.666 IoU: 0.390 
Execution time: 294.0700611900538

[valid] Epoch: 35/80 xent: 0.026 softIoU: 7.436 IoU: 0.447 
Execution time: 42.44949400331825

[train] Epoch: 36/80 xent: 0.024 softIoU: 7.669 IoU: 0.393 
Execution time: 293.41516216285527

[valid] Epoch: 36/80 xent: 0.024 softIoU: 7.439 IoU: 0.408 
Execution time: 42.337306858971715

[train] Epoch: 37/80 xent: 0.022 softIoU: 7.645 IoU: 0.401 
Execution time: 291.6538548041135

[valid] Epoch: 37/80 xent: 0.026 softIoU: 7.442 IoU: 0.344 
Execution time: 41.205435974989086

[train] Epoch: 38/80 xent: 0.025 softIoU: 7.662 IoU: 0.406 
Execution time: 290.17867440730333

[valid] Epoch: 38/80 xent: 0.034 softIoU: 7.440 IoU: 0.495 
Execution time: 42.84349728608504

[train] Epoch: 39/80 xent: 0.026 softIoU: 7.660 IoU: 0.397 
Execution time: 292.76031745783985

[valid] Epoch: 39/80 xent: 0.026 softIoU: 7.434 IoU: 0.403 
Execution time: 42.32190306484699

[train] Epoch: 40/80 xent: 0.023 softIoU: 7.653 IoU: 0.403 
Execution time: 288.8465467626229

[valid] Epoch: 40/80 xent: 0.031 softIoU: 7.439 IoU: 0.345 
Execution time: 39.97004907997325

Saved model at /scratch/sr365/models/catalysth3_mb_3/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-40.pth.tar
[train] Epoch: 41/80 xent: 0.023 softIoU: 7.653 IoU: 0.427 
Execution time: 283.52227062592283

[valid] Epoch: 41/80 xent: 0.025 softIoU: 7.436 IoU: 0.401 
Execution time: 40.86895184731111

[train] Epoch: 42/80 xent: 0.023 softIoU: 7.652 IoU: 0.419 
Execution time: 284.4302786057815

[valid] Epoch: 42/80 xent: 0.025 softIoU: 7.430 IoU: 0.491 
Execution time: 40.31627295399085

[train] Epoch: 43/80 xent: 0.020 softIoU: 7.658 IoU: 0.438 
Execution time: 282.94472724944353

[valid] Epoch: 43/80 xent: 0.022 softIoU: 7.431 IoU: 0.462 
Execution time: 39.787183973006904

[train] Epoch: 44/80 xent: 0.020 softIoU: 7.653 IoU: 0.468 
Execution time: 282.4636217439547

[valid] Epoch: 44/80 xent: 0.026 softIoU: 7.428 IoU: 0.513 
Execution time: 41.396873394958675

[train] Epoch: 45/80 xent: 0.024 softIoU: 7.667 IoU: 0.420 
Execution time: 292.49351899698377

[valid] Epoch: 45/80 xent: 0.029 softIoU: 7.441 IoU: 0.309 
Execution time: 41.96073937276378

[train] Epoch: 46/80 xent: 0.023 softIoU: 7.667 IoU: 0.411 
Execution time: 289.6751043498516

[valid] Epoch: 46/80 xent: 0.025 softIoU: 7.426 IoU: 0.544 
Execution time: 41.650473786052316

[train] Epoch: 47/80 xent: 0.022 softIoU: 7.644 IoU: 0.416 
Execution time: 290.59018418192863

[valid] Epoch: 47/80 xent: 0.024 softIoU: 7.428 IoU: 0.505 
Execution time: 40.71290989499539

[train] Epoch: 48/80 xent: 0.021 softIoU: 7.653 IoU: 0.463 
Execution time: 292.3192931506783

[valid] Epoch: 48/80 xent: 0.027 softIoU: 7.436 IoU: 0.380 
Execution time: 40.58719707839191

[train] Epoch: 49/80 xent: 0.021 softIoU: 7.661 IoU: 0.447 
Execution time: 294.0118783856742

[valid] Epoch: 49/80 xent: 0.021 softIoU: 7.431 IoU: 0.469 
Execution time: 42.89454928319901

[train] Epoch: 50/80 xent: 0.018 softIoU: 7.635 IoU: 0.453 
Execution time: 288.9097860259935

[valid] Epoch: 50/80 xent: 0.023 softIoU: 7.426 IoU: 0.513 
Execution time: 42.21800335217267

[train] Epoch: 51/80 xent: 0.018 softIoU: 7.650 IoU: 0.467 
Execution time: 291.14720540493727

[valid] Epoch: 51/80 xent: 0.021 softIoU: 7.433 IoU: 0.435 
Execution time: 41.235692617017776

[train] Epoch: 52/80 xent: 0.022 softIoU: 7.652 IoU: 0.456 
Execution time: 291.4634862355888

[valid] Epoch: 52/80 xent: 0.022 softIoU: 7.432 IoU: 0.425 
Execution time: 42.62812007172033

[train] Epoch: 53/80 xent: 0.020 softIoU: 7.654 IoU: 0.465 
Execution time: 292.42871664324775

[valid] Epoch: 53/80 xent: 0.023 softIoU: 7.427 IoU: 0.488 
Execution time: 39.87293018819764

[train] Epoch: 54/80 xent: 0.019 softIoU: 7.643 IoU: 0.455 
Execution time: 292.4407726768404

[valid] Epoch: 54/80 xent: 0.022 softIoU: 7.431 IoU: 0.434 
Execution time: 40.81842874875292

[train] Epoch: 55/80 xent: 0.018 softIoU: 7.643 IoU: 0.474 
Execution time: 293.2354331356473

[valid] Epoch: 55/80 xent: 0.022 softIoU: 7.427 IoU: 0.473 
Execution time: 41.66462769173086

[train] Epoch: 56/80 xent: 0.018 softIoU: 7.646 IoU: 0.481 
Execution time: 289.4809238417074

[valid] Epoch: 56/80 xent: 0.023 softIoU: 7.428 IoU: 0.464 
Execution time: 41.98005509795621

[train] Epoch: 57/80 xent: 0.018 softIoU: 7.644 IoU: 0.472 
Execution time: 291.05925587471575

[valid] Epoch: 57/80 xent: 0.022 softIoU: 7.428 IoU: 0.485 
Execution time: 42.18415514193475

[train] Epoch: 58/80 xent: 0.020 softIoU: 7.650 IoU: 0.474 
Execution time: 293.1573424860835

[valid] Epoch: 58/80 xent: 0.023 softIoU: 7.428 IoU: 0.467 
Execution time: 42.11546701611951

[train] Epoch: 59/80 xent: 0.020 softIoU: 7.645 IoU: 0.477 
Execution time: 291.51081895967945

[valid] Epoch: 59/80 xent: 0.021 softIoU: 7.429 IoU: 0.456 
Execution time: 43.53041114192456

[train] Epoch: 60/80 xent: 0.018 softIoU: 7.639 IoU: 0.470 
Execution time: 290.68727514334023

[valid] Epoch: 60/80 xent: 0.021 softIoU: 7.428 IoU: 0.464 
Execution time: 42.135699139907956

Saved model at /scratch/sr365/models/catalysth3_mb_3/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-60.pth.tar
[train] Epoch: 61/80 xent: 0.020 softIoU: 7.644 IoU: 0.467 
Execution time: 292.48702260199934

[valid] Epoch: 61/80 xent: 0.021 softIoU: 7.427 IoU: 0.482 
Execution time: 42.712247209623456

[train] Epoch: 62/80 xent: 0.019 softIoU: 7.639 IoU: 0.483 
Execution time: 292.5353947128169

[valid] Epoch: 62/80 xent: 0.022 softIoU: 7.429 IoU: 0.454 
Execution time: 42.00791954481974

[train] Epoch: 63/80 xent: 0.019 softIoU: 7.646 IoU: 0.478 
Execution time: 296.5429495177232

[valid] Epoch: 63/80 xent: 0.022 softIoU: 7.428 IoU: 0.464 
Execution time: 41.13551814015955

[train] Epoch: 64/80 xent: 0.018 softIoU: 7.647 IoU: 0.467 
Execution time: 292.16340830316767

[valid] Epoch: 64/80 xent: 0.021 softIoU: 7.428 IoU: 0.474 
Execution time: 43.298656004015356

[train] Epoch: 65/80 xent: 0.019 softIoU: 7.653 IoU: 0.489 
Execution time: 293.85891620395705

[valid] Epoch: 65/80 xent: 0.021 softIoU: 7.428 IoU: 0.465 
Execution time: 42.15198688581586

[train] Epoch: 66/80 xent: 0.019 softIoU: 7.638 IoU: 0.491 
Execution time: 294.546340291854

[valid] Epoch: 66/80 xent: 0.021 softIoU: 7.426 IoU: 0.492 
Execution time: 42.10779371205717

[train] Epoch: 67/80 xent: 0.018 softIoU: 7.660 IoU: 0.483 
Execution time: 295.7679842901416

[valid] Epoch: 67/80 xent: 0.021 softIoU: 7.427 IoU: 0.482 
Execution time: 41.963637322187424

[train] Epoch: 68/80 xent: 0.019 softIoU: 7.652 IoU: 0.478 
Execution time: 292.278909211047

[valid] Epoch: 68/80 xent: 0.022 softIoU: 7.425 IoU: 0.509 
Execution time: 41.92834639037028

[train] Epoch: 69/80 xent: 0.019 softIoU: 7.644 IoU: 0.476 
Execution time: 292.0856695640832

[valid] Epoch: 69/80 xent: 0.020 softIoU: 7.429 IoU: 0.447 
Execution time: 39.93556439457461

[train] Epoch: 70/80 xent: 0.018 softIoU: 7.633 IoU: 0.476 
Execution time: 287.10627164598554

[valid] Epoch: 70/80 xent: 0.020 softIoU: 7.429 IoU: 0.460 
Execution time: 40.05650225980207

[train] Epoch: 71/80 xent: 0.019 softIoU: 7.643 IoU: 0.463 
Execution time: 286.82551075425

[valid] Epoch: 71/80 xent: 0.020 softIoU: 7.428 IoU: 0.470 
Execution time: 41.505081716924906

[train] Epoch: 72/80 xent: 0.019 softIoU: 7.652 IoU: 0.475 
Execution time: 282.97454905183986

[valid] Epoch: 72/80 xent: 0.021 softIoU: 7.426 IoU: 0.498 
Execution time: 40.56561003020033

[train] Epoch: 73/80 xent: 0.019 softIoU: 7.653 IoU: 0.487 
Execution time: 285.44662877032533

[valid] Epoch: 73/80 xent: 0.020 softIoU: 7.426 IoU: 0.473 
Execution time: 40.008737156167626

[train] Epoch: 74/80 xent: 0.019 softIoU: 7.637 IoU: 0.471 
Execution time: 282.35982522182167

[valid] Epoch: 74/80 xent: 0.020 softIoU: 7.428 IoU: 0.454 
Execution time: 39.86748161399737

[train] Epoch: 75/80 xent: 0.018 softIoU: 7.638 IoU: 0.472 
Execution time: 282.83609805302694

[valid] Epoch: 75/80 xent: 0.020 softIoU: 7.426 IoU: 0.484 
Execution time: 40.358959442935884

[train] Epoch: 76/80 xent: 0.018 softIoU: 7.636 IoU: 0.497 
Execution time: 288.76123180193827

[valid] Epoch: 76/80 xent: 0.020 softIoU: 7.428 IoU: 0.468 
Execution time: 42.216495640110224

[train] Epoch: 77/80 xent: 0.018 softIoU: 7.640 IoU: 0.482 
Execution time: 293.060197790619

[valid] Epoch: 77/80 xent: 0.019 softIoU: 7.430 IoU: 0.443 
Execution time: 42.26586791872978

[train] Epoch: 78/80 xent: 0.017 softIoU: 7.641 IoU: 0.480 
Execution time: 290.9748687320389

[valid] Epoch: 78/80 xent: 0.021 softIoU: 7.428 IoU: 0.465 
Execution time: 40.484340706374496

[train] Epoch: 79/80 xent: 0.019 softIoU: 7.638 IoU: 0.482 
Execution time: 285.9856014000252

[valid] Epoch: 79/80 xent: 0.019 softIoU: 7.428 IoU: 0.462 
Execution time: 39.945055860094726

Saved model at /scratch/sr365/models/catalysth3_mb_3/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-80.pth.tar
Device being used: cuda:0
Finetuning model from /scratch/wh145/models/solarmapper_final/ct/epoch-80.pth.tar
Warning: The following parameters in the pretrained model does not exist in the current model
	 decoder.uc.0.up_conv.weight
	 decoder.uc.0.up_conv.bias
	 decoder.uc.0.conv_1.weight
	 decoder.uc.0.conv_1.bias
	 decoder.uc.0.conv_2.weight
	 decoder.uc.0.conv_2.bias
	 decoder.uc.0.bn_1.weight
	 decoder.uc.0.bn_1.bias
	 decoder.uc.0.bn_1.running_mean
	 decoder.uc.0.bn_1.running_var
	 decoder.uc.0.bn_1.num_batches_tracked
	 decoder.uc.0.bn_2.weight
	 decoder.uc.0.bn_2.bias
	 decoder.uc.0.bn_2.running_mean
	 decoder.uc.0.bn_2.running_var
	 decoder.uc.0.bn_2.num_batches_tracked
	 decoder.uc.0.act.weight
	 decoder.uc.1.up_conv.weight
	 decoder.uc.1.up_conv.bias
	 decoder.uc.1.conv_1.weight
	 decoder.uc.1.conv_1.bias
	 decoder.uc.1.conv_2.weight
	 decoder.uc.1.conv_2.bias
	 decoder.uc.1.bn_1.weight
	 decoder.uc.1.bn_1.bias
	 decoder.uc.1.bn_1.running_mean
	 decoder.uc.1.bn_1.running_var
	 decoder.uc.1.bn_1.num_batches_tracked
	 decoder.uc.1.bn_2.weight
	 decoder.uc.1.bn_2.bias
	 decoder.uc.1.bn_2.running_mean
	 decoder.uc.1.bn_2.running_var
	 decoder.uc.1.bn_2.num_batches_tracked
	 decoder.uc.1.act.weight
	 decoder.uc.2.up_conv.weight
	 decoder.uc.2.up_conv.bias
	 decoder.uc.2.conv_1.weight
	 decoder.uc.2.conv_1.bias
	 decoder.uc.2.conv_2.weight
	 decoder.uc.2.conv_2.bias
	 decoder.uc.2.bn_1.weight
	 decoder.uc.2.bn_1.bias
	 decoder.uc.2.bn_1.running_mean
	 decoder.uc.2.bn_1.running_var
	 decoder.uc.2.bn_1.num_batches_tracked
	 decoder.uc.2.bn_2.weight
	 decoder.uc.2.bn_2.bias
	 decoder.uc.2.bn_2.running_mean
	 decoder.uc.2.bn_2.running_var
	 decoder.uc.2.bn_2.num_batches_tracked
	 decoder.uc.2.act.weight
	 decoder.uc.3.up_conv.weight
	 decoder.uc.3.up_conv.bias
	 decoder.uc.3.conv_1.weight
	 decoder.uc.3.conv_1.bias
	 decoder.uc.3.conv_2.weight
	 decoder.uc.3.conv_2.bias
	 decoder.uc.3.bn_1.weight
	 decoder.uc.3.bn_1.bias
	 decoder.uc.3.bn_1.running_mean
	 decoder.uc.3.bn_1.running_var
	 decoder.uc.3.bn_1.num_batches_tracked
	 decoder.uc.3.bn_2.weight
	 decoder.uc.3.bn_2.bias
	 decoder.uc.3.bn_2.running_mean
	 decoder.uc.3.bn_2.running_var
	 decoder.uc.3.bn_2.num_batches_tracked
	 decoder.uc.3.act.weight
Warning: The following parameters in the current model does not exist in the pretrained model
	 decoder.center_dilation.dconv_1.weight
	 decoder.center_dilation.dconv_1.bias
	 decoder.center_dilation.dconv_2.weight
	 decoder.center_dilation.dconv_2.bias
	 decoder.center_dilation.dconv_3.weight
	 decoder.center_dilation.dconv_3.bias
	 decoder.center_dilation.dconv_4.weight
	 decoder.center_dilation.dconv_4.bias
	 decoder.upsample_1.conv1.weight
	 decoder.upsample_1.conv1.bias
	 decoder.upsample_1.tconv.weight
	 decoder.upsample_1.tconv.bias
	 decoder.upsample_1.conv2.weight
	 decoder.upsample_1.conv2.bias
	 decoder.upsample_2.conv1.weight
	 decoder.upsample_2.conv1.bias
	 decoder.upsample_2.tconv.weight
	 decoder.upsample_2.tconv.bias
	 decoder.upsample_2.conv2.weight
	 decoder.upsample_2.conv2.bias
	 decoder.upsample_3.conv1.weight
	 decoder.upsample_3.conv1.bias
	 decoder.upsample_3.tconv.weight
	 decoder.upsample_3.tconv.bias
	 decoder.upsample_3.conv2.weight
	 decoder.upsample_3.conv2.bias
	 decoder.upsample_4.conv1.weight
	 decoder.upsample_4.conv1.bias
	 decoder.upsample_4.tconv.weight
	 decoder.upsample_4.tconv.bias
	 decoder.upsample_4.conv2.weight
	 decoder.upsample_4.conv2.bias
	 decoder.tconv.weight
	 decoder.tconv.bias
Warning: The size of the following parameters in the current model does not match the ones in the pretrained model
	 decoder.classify.weight
Try loading with relaxed naming rule:
Prefix in pretrained model 
	pretrained param: encoder.conv1.weight -> current param: encoder.conv1.weight
	pretrained param: encoder.bn1.weight -> current param: encoder.bn1.weight
	pretrained param: encoder.bn1.bias -> current param: encoder.bn1.bias
	pretrained param: encoder.bn1.running_mean -> current param: encoder.bn1.running_mean
	pretrained param: encoder.bn1.running_var -> current param: encoder.bn1.running_var
	pretrained param: encoder.bn1.num_batches_tracked -> current param: encoder.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv1.weight -> current param: encoder.layer1.0.conv1.weight
	pretrained param: encoder.layer1.0.bn1.weight -> current param: encoder.layer1.0.bn1.weight
	pretrained param: encoder.layer1.0.bn1.bias -> current param: encoder.layer1.0.bn1.bias
	pretrained param: encoder.layer1.0.bn1.running_mean -> current param: encoder.layer1.0.bn1.running_mean
	pretrained param: encoder.layer1.0.bn1.running_var -> current param: encoder.layer1.0.bn1.running_var
	pretrained param: encoder.layer1.0.bn1.num_batches_tracked -> current param: encoder.layer1.0.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv2.weight -> current param: encoder.layer1.0.conv2.weight
	pretrained param: encoder.layer1.0.bn2.weight -> current param: encoder.layer1.0.bn2.weight
	pretrained param: encoder.layer1.0.bn2.bias -> current param: encoder.layer1.0.bn2.bias
	pretrained param: encoder.layer1.0.bn2.running_mean -> current param: encoder.layer1.0.bn2.running_mean
	pretrained param: encoder.layer1.0.bn2.running_var -> current param: encoder.layer1.0.bn2.running_var
	pretrained param: encoder.layer1.0.bn2.num_batches_tracked -> current param: encoder.layer1.0.bn2.num_batches_tracked
	pretrained param: encoder.layer1.0.conv3.weight -> current param: encoder.layer1.0.conv3.weight
	pretrained param: encoder.layer1.0.bn3.weight -> current param: encoder.layer1.0.bn3.weight
	pretrained param: encoder.layer1.0.bn3.bias -> current param: encoder.layer1.0.bn3.bias
	pretrained param: encoder.layer1.0.bn3.running_mean -> current param: encoder.layer1.0.bn3.running_mean
	pretrained param: encoder.layer1.0.bn3.running_var -> current param: encoder.layer1.0.bn3.running_var
	pretrained param: encoder.layer1.0.bn3.num_batches_tracked -> current param: encoder.layer1.0.bn3.num_batches_tracked
	pretrained param: encoder.layer1.0.downsample.0.weight -> current param: encoder.layer1.0.downsample.0.weight
	pretrained param: encoder.layer1.0.downsample.1.weight -> current param: encoder.layer1.0.downsample.1.weight
	pretrained param: encoder.layer1.0.downsample.1.bias -> current param: encoder.layer1.0.downsample.1.bias
	pretrained param: encoder.layer1.0.downsample.1.running_mean -> current param: encoder.layer1.0.downsample.1.running_mean
	pretrained param: encoder.layer1.0.downsample.1.running_var -> current param: encoder.layer1.0.downsample.1.running_var
	pretrained param: encoder.layer1.0.downsample.1.num_batches_tracked -> current param: encoder.layer1.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv1.weight -> current param: encoder.layer1.1.conv1.weight
	pretrained param: encoder.layer1.1.bn1.weight -> current param: encoder.layer1.1.bn1.weight
	pretrained param: encoder.layer1.1.bn1.bias -> current param: encoder.layer1.1.bn1.bias
	pretrained param: encoder.layer1.1.bn1.running_mean -> current param: encoder.layer1.1.bn1.running_mean
	pretrained param: encoder.layer1.1.bn1.running_var -> current param: encoder.layer1.1.bn1.running_var
	pretrained param: encoder.layer1.1.bn1.num_batches_tracked -> current param: encoder.layer1.1.bn1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv2.weight -> current param: encoder.layer1.1.conv2.weight
	pretrained param: encoder.layer1.1.bn2.weight -> current param: encoder.layer1.1.bn2.weight
	pretrained param: encoder.layer1.1.bn2.bias -> current param: encoder.layer1.1.bn2.bias
	pretrained param: encoder.layer1.1.bn2.running_mean -> current param: encoder.layer1.1.bn2.running_mean
	pretrained param: encoder.layer1.1.bn2.running_var -> current param: encoder.layer1.1.bn2.running_var
	pretrained param: encoder.layer1.1.bn2.num_batches_tracked -> current param: encoder.layer1.1.bn2.num_batches_tracked
	pretrained param: encoder.layer1.1.conv3.weight -> current param: encoder.layer1.1.conv3.weight
	pretrained param: encoder.layer1.1.bn3.weight -> current param: encoder.layer1.1.bn3.weight
	pretrained param: encoder.layer1.1.bn3.bias -> current param: encoder.layer1.1.bn3.bias
	pretrained param: encoder.layer1.1.bn3.running_mean -> current param: encoder.layer1.1.bn3.running_mean
	pretrained param: encoder.layer1.1.bn3.running_var -> current param: encoder.layer1.1.bn3.running_var
	pretrained param: encoder.layer1.1.bn3.num_batches_tracked -> current param: encoder.layer1.1.bn3.num_batches_tracked
	pretrained param: encoder.layer1.2.conv1.weight -> current param: encoder.layer1.2.conv1.weight
	pretrained param: encoder.layer1.2.bn1.weight -> current param: encoder.layer1.2.bn1.weight
	pretrained param: encoder.layer1.2.bn1.bias -> current param: encoder.layer1.2.bn1.bias
	pretrained param: encoder.layer1.2.bn1.running_mean -> current param: encoder.layer1.2.bn1.running_mean
	pretrained param: encoder.layer1.2.bn1.running_var -> current param: encoder.layer1.2.bn1.running_var
	pretrained param: encoder.layer1.2.bn1.num_batches_tracked -> current param: encoder.layer1.2.bn1.num_batches_tracked
	pretrained param: encoder.layer1.2.conv2.weight -> current param: encoder.layer1.2.conv2.weight
	pretrained param: encoder.layer1.2.bn2.weight -> current param: encoder.layer1.2.bn2.weight
	pretrained param: encoder.layer1.2.bn2.bias -> current param: encoder.layer1.2.bn2.bias
	pretrained param: encoder.layer1.2.bn2.running_mean -> current param: encoder.layer1.2.bn2.running_mean
	pretrained param: encoder.layer1.2.bn2.running_var -> current param: encoder.layer1.2.bn2.running_var
	pretrained param: encoder.layer1.2.bn2.num_batches_tracked -> current param: encoder.layer1.2.bn2.num_batches_tracked
	pretrained param: encoder.layer1.2.conv3.weight -> current param: encoder.layer1.2.conv3.weight
	pretrained param: encoder.layer1.2.bn3.weight -> current param: encoder.layer1.2.bn3.weight
	pretrained param: encoder.layer1.2.bn3.bias -> current param: encoder.layer1.2.bn3.bias
	pretrained param: encoder.layer1.2.bn3.running_mean -> current param: encoder.layer1.2.bn3.running_mean
	pretrained param: encoder.layer1.2.bn3.running_var -> current param: encoder.layer1.2.bn3.running_var
	pretrained param: encoder.layer1.2.bn3.num_batches_tracked -> current param: encoder.layer1.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.conv1.weight -> current param: encoder.layer2.0.conv1.weight
	pretrained param: encoder.layer2.0.bn1.weight -> current param: encoder.layer2.0.bn1.weight
	pretrained param: encoder.layer2.0.bn1.bias -> current param: encoder.layer2.0.bn1.bias
	pretrained param: encoder.layer2.0.bn1.running_mean -> current param: encoder.layer2.0.bn1.running_mean
	pretrained param: encoder.layer2.0.bn1.running_var -> current param: encoder.layer2.0.bn1.running_var
	pretrained param: encoder.layer2.0.bn1.num_batches_tracked -> current param: encoder.layer2.0.bn1.num_batches_tracked
	pretrained param: encoder.layer2.0.conv2.weight -> current param: encoder.layer2.0.conv2.weight
	pretrained param: encoder.layer2.0.bn2.weight -> current param: encoder.layer2.0.bn2.weight
	pretrained param: encoder.layer2.0.bn2.bias -> current param: encoder.layer2.0.bn2.bias
	pretrained param: encoder.layer2.0.bn2.running_mean -> current param: encoder.layer2.0.bn2.running_mean
	pretrained param: encoder.layer2.0.bn2.running_var -> current param: encoder.layer2.0.bn2.running_var
	pretrained param: encoder.layer2.0.bn2.num_batches_tracked -> current param: encoder.layer2.0.bn2.num_batches_tracked
	pretrained param: encoder.layer2.0.conv3.weight -> current param: encoder.layer2.0.conv3.weight
	pretrained param: encoder.layer2.0.bn3.weight -> current param: encoder.layer2.0.bn3.weight
	pretrained param: encoder.layer2.0.bn3.bias -> current param: encoder.layer2.0.bn3.bias
	pretrained param: encoder.layer2.0.bn3.running_mean -> current param: encoder.layer2.0.bn3.running_mean
	pretrained param: encoder.layer2.0.bn3.running_var -> current param: encoder.layer2.0.bn3.running_var
	pretrained param: encoder.layer2.0.bn3.num_batches_tracked -> current param: encoder.layer2.0.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.downsample.0.weight -> current param: encoder.layer2.0.downsample.0.weight
	pretrained param: encoder.layer2.0.downsample.1.weight -> current param: encoder.layer2.0.downsample.1.weight
	pretrained param: encoder.layer2.0.downsample.1.bias -> current param: encoder.layer2.0.downsample.1.bias
	pretrained param: encoder.layer2.0.downsample.1.running_mean -> current param: encoder.layer2.0.downsample.1.running_mean
	pretrained param: encoder.layer2.0.downsample.1.running_var -> current param: encoder.layer2.0.downsample.1.running_var
	pretrained param: encoder.layer2.0.downsample.1.num_batches_tracked -> current param: encoder.layer2.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv1.weight -> current param: encoder.layer2.1.conv1.weight
	pretrained param: encoder.layer2.1.bn1.weight -> current param: encoder.layer2.1.bn1.weight
	pretrained param: encoder.layer2.1.bn1.bias -> current param: encoder.layer2.1.bn1.bias
	pretrained param: encoder.layer2.1.bn1.running_mean -> current param: encoder.layer2.1.bn1.running_mean
	pretrained param: encoder.layer2.1.bn1.running_var -> current param: encoder.layer2.1.bn1.running_var
	pretrained param: encoder.layer2.1.bn1.num_batches_tracked -> current param: encoder.layer2.1.bn1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv2.weight -> current param: encoder.layer2.1.conv2.weight
	pretrained param: encoder.layer2.1.bn2.weight -> current param: encoder.layer2.1.bn2.weight
	pretrained param: encoder.layer2.1.bn2.bias -> current param: encoder.layer2.1.bn2.bias
	pretrained param: encoder.layer2.1.bn2.running_mean -> current param: encoder.layer2.1.bn2.running_mean
	pretrained param: encoder.layer2.1.bn2.running_var -> current param: encoder.layer2.1.bn2.running_var
	pretrained param: encoder.layer2.1.bn2.num_batches_tracked -> current param: encoder.layer2.1.bn2.num_batches_tracked
	pretrained param: encoder.layer2.1.conv3.weight -> current param: encoder.layer2.1.conv3.weight
	pretrained param: encoder.layer2.1.bn3.weight -> current param: encoder.layer2.1.bn3.weight
	pretrained param: encoder.layer2.1.bn3.bias -> current param: encoder.layer2.1.bn3.bias
	pretrained param: encoder.layer2.1.bn3.running_mean -> current param: encoder.layer2.1.bn3.running_mean
	pretrained param: encoder.layer2.1.bn3.running_var -> current param: encoder.layer2.1.bn3.running_var
	pretrained param: encoder.layer2.1.bn3.num_batches_tracked -> current param: encoder.layer2.1.bn3.num_batches_tracked
	pretrained param: encoder.layer2.2.conv1.weight -> current param: encoder.layer2.2.conv1.weight
	pretrained param: encoder.layer2.2.bn1.weight -> current param: encoder.layer2.2.bn1.weight
	pretrained param: encoder.layer2.2.bn1.bias -> current param: encoder.layer2.2.bn1.bias
	pretrained param: encoder.layer2.2.bn1.running_mean -> current param: encoder.layer2.2.bn1.running_mean
	pretrained param: encoder.layer2.2.bn1.running_var -> current param: encoder.layer2.2.bn1.running_var
	pretrained param: encoder.layer2.2.bn1.num_batches_tracked -> current param: encoder.layer2.2.bn1.num_batches_tracked
	pretrained param: encoder.layer2.2.conv2.weight -> current param: encoder.layer2.2.conv2.weight
	pretrained param: encoder.layer2.2.bn2.weight -> current param: encoder.layer2.2.bn2.weight
	pretrained param: encoder.layer2.2.bn2.bias -> current param: encoder.layer2.2.bn2.bias
	pretrained param: encoder.layer2.2.bn2.running_mean -> current param: encoder.layer2.2.bn2.running_mean
	pretrained param: encoder.layer2.2.bn2.running_var -> current param: encoder.layer2.2.bn2.running_var
	pretrained param: encoder.layer2.2.bn2.num_batches_tracked -> current param: encoder.layer2.2.bn2.num_batches_tracked
	pretrained param: encoder.layer2.2.conv3.weight -> current param: encoder.layer2.2.conv3.weight
	pretrained param: encoder.layer2.2.bn3.weight -> current param: encoder.layer2.2.bn3.weight
	pretrained param: encoder.layer2.2.bn3.bias -> current param: encoder.layer2.2.bn3.bias
	pretrained param: encoder.layer2.2.bn3.running_mean -> current param: encoder.layer2.2.bn3.running_mean
	pretrained param: encoder.layer2.2.bn3.running_var -> current param: encoder.layer2.2.bn3.running_var
	pretrained param: encoder.layer2.2.bn3.num_batches_tracked -> current param: encoder.layer2.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.3.conv1.weight -> current param: encoder.layer2.3.conv1.weight
	pretrained param: encoder.layer2.3.bn1.weight -> current param: encoder.layer2.3.bn1.weight
	pretrained param: encoder.layer2.3.bn1.bias -> current param: encoder.layer2.3.bn1.bias
	pretrained param: encoder.layer2.3.bn1.running_mean -> current param: encoder.layer2.3.bn1.running_mean
	pretrained param: encoder.layer2.3.bn1.running_var -> current param: encoder.layer2.3.bn1.running_var
	pretrained param: encoder.layer2.3.bn1.num_batches_tracked -> current param: encoder.layer2.3.bn1.num_batches_tracked
	pretrained param: encoder.layer2.3.conv2.weight -> current param: encoder.layer2.3.conv2.weight
	pretrained param: encoder.layer2.3.bn2.weight -> current param: encoder.layer2.3.bn2.weight
	pretrained param: encoder.layer2.3.bn2.bias -> current param: encoder.layer2.3.bn2.bias
	pretrained param: encoder.layer2.3.bn2.running_mean -> current param: encoder.layer2.3.bn2.running_mean
	pretrained param: encoder.layer2.3.bn2.running_var -> current param: encoder.layer2.3.bn2.running_var
	pretrained param: encoder.layer2.3.bn2.num_batches_tracked -> current param: encoder.layer2.3.bn2.num_batches_tracked
	pretrained param: encoder.layer2.3.conv3.weight -> current param: encoder.layer2.3.conv3.weight
	pretrained param: encoder.layer2.3.bn3.weight -> current param: encoder.layer2.3.bn3.weight
	pretrained param: encoder.layer2.3.bn3.bias -> current param: encoder.layer2.3.bn3.bias
	pretrained param: encoder.layer2.3.bn3.running_mean -> current param: encoder.layer2.3.bn3.running_mean
	pretrained param: encoder.layer2.3.bn3.running_var -> current param: encoder.layer2.3.bn3.running_var
	pretrained param: encoder.layer2.3.bn3.num_batches_tracked -> current param: encoder.layer2.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.conv1.weight -> current param: encoder.layer3.0.conv1.weight
	pretrained param: encoder.layer3.0.bn1.weight -> current param: encoder.layer3.0.bn1.weight
	pretrained param: encoder.layer3.0.bn1.bias -> current param: encoder.layer3.0.bn1.bias
	pretrained param: encoder.layer3.0.bn1.running_mean -> current param: encoder.layer3.0.bn1.running_mean
	pretrained param: encoder.layer3.0.bn1.running_var -> current param: encoder.layer3.0.bn1.running_var
	pretrained param: encoder.layer3.0.bn1.num_batches_tracked -> current param: encoder.layer3.0.bn1.num_batches_tracked
	pretrained param: encoder.layer3.0.conv2.weight -> current param: encoder.layer3.0.conv2.weight
	pretrained param: encoder.layer3.0.bn2.weight -> current param: encoder.layer3.0.bn2.weight
	pretrained param: encoder.layer3.0.bn2.bias -> current param: encoder.layer3.0.bn2.bias
	pretrained param: encoder.layer3.0.bn2.running_mean -> current param: encoder.layer3.0.bn2.running_mean
	pretrained param: encoder.layer3.0.bn2.running_var -> current param: encoder.layer3.0.bn2.running_var
	pretrained param: encoder.layer3.0.bn2.num_batches_tracked -> current param: encoder.layer3.0.bn2.num_batches_tracked
	pretrained param: encoder.layer3.0.conv3.weight -> current param: encoder.layer3.0.conv3.weight
	pretrained param: encoder.layer3.0.bn3.weight -> current param: encoder.layer3.0.bn3.weight
	pretrained param: encoder.layer3.0.bn3.bias -> current param: encoder.layer3.0.bn3.bias
	pretrained param: encoder.layer3.0.bn3.running_mean -> current param: encoder.layer3.0.bn3.running_mean
	pretrained param: encoder.layer3.0.bn3.running_var -> current param: encoder.layer3.0.bn3.running_var
	pretrained param: encoder.layer3.0.bn3.num_batches_tracked -> current param: encoder.layer3.0.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.downsample.0.weight -> current param: encoder.layer3.0.downsample.0.weight
	pretrained param: encoder.layer3.0.downsample.1.weight -> current param: encoder.layer3.0.downsample.1.weight
	pretrained param: encoder.layer3.0.downsample.1.bias -> current param: encoder.layer3.0.downsample.1.bias
	pretrained param: encoder.layer3.0.downsample.1.running_mean -> current param: encoder.layer3.0.downsample.1.running_mean
	pretrained param: encoder.layer3.0.downsample.1.running_var -> current param: encoder.layer3.0.downsample.1.running_var
	pretrained param: encoder.layer3.0.downsample.1.num_batches_tracked -> current param: encoder.layer3.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv1.weight -> current param: encoder.layer3.1.conv1.weight
	pretrained param: encoder.layer3.1.bn1.weight -> current param: encoder.layer3.1.bn1.weight
	pretrained param: encoder.layer3.1.bn1.bias -> current param: encoder.layer3.1.bn1.bias
	pretrained param: encoder.layer3.1.bn1.running_mean -> current param: encoder.layer3.1.bn1.running_mean
	pretrained param: encoder.layer3.1.bn1.running_var -> current param: encoder.layer3.1.bn1.running_var
	pretrained param: encoder.layer3.1.bn1.num_batches_tracked -> current param: encoder.layer3.1.bn1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv2.weight -> current param: encoder.layer3.1.conv2.weight
	pretrained param: encoder.layer3.1.bn2.weight -> current param: encoder.layer3.1.bn2.weight
	pretrained param: encoder.layer3.1.bn2.bias -> current param: encoder.layer3.1.bn2.bias
	pretrained param: encoder.layer3.1.bn2.running_mean -> current param: encoder.layer3.1.bn2.running_mean
	pretrained param: encoder.layer3.1.bn2.running_var -> current param: encoder.layer3.1.bn2.running_var
	pretrained param: encoder.layer3.1.bn2.num_batches_tracked -> current param: encoder.layer3.1.bn2.num_batches_tracked
	pretrained param: encoder.layer3.1.conv3.weight -> current param: encoder.layer3.1.conv3.weight
	pretrained param: encoder.layer3.1.bn3.weight -> current param: encoder.layer3.1.bn3.weight
	pretrained param: encoder.layer3.1.bn3.bias -> current param: encoder.layer3.1.bn3.bias
	pretrained param: encoder.layer3.1.bn3.running_mean -> current param: encoder.layer3.1.bn3.running_mean
	pretrained param: encoder.layer3.1.bn3.running_var -> current param: encoder.layer3.1.bn3.running_var
	pretrained param: encoder.layer3.1.bn3.num_batches_tracked -> current param: encoder.layer3.1.bn3.num_batches_tracked
	pretrained param: encoder.layer3.2.conv1.weight -> current param: encoder.layer3.2.conv1.weight
	pretrained param: encoder.layer3.2.bn1.weight -> current param: encoder.layer3.2.bn1.weight
	pretrained param: encoder.layer3.2.bn1.bias -> current param: encoder.layer3.2.bn1.bias
	pretrained param: encoder.layer3.2.bn1.running_mean -> current param: encoder.layer3.2.bn1.running_mean
	pretrained param: encoder.layer3.2.bn1.running_var -> current param: encoder.layer3.2.bn1.running_var
	pretrained param: encoder.layer3.2.bn1.num_batches_tracked -> current param: encoder.layer3.2.bn1.num_batches_tracked
	pretrained param: encoder.layer3.2.conv2.weight -> current param: encoder.layer3.2.conv2.weight
	pretrained param: encoder.layer3.2.bn2.weight -> current param: encoder.layer3.2.bn2.weight
	pretrained param: encoder.layer3.2.bn2.bias -> current param: encoder.layer3.2.bn2.bias
	pretrained param: encoder.layer3.2.bn2.running_mean -> current param: encoder.layer3.2.bn2.running_mean
	pretrained param: encoder.layer3.2.bn2.running_var -> current param: encoder.layer3.2.bn2.running_var
	pretrained param: encoder.layer3.2.bn2.num_batches_tracked -> current param: encoder.layer3.2.bn2.num_batches_tracked
	pretrained param: encoder.layer3.2.conv3.weight -> current param: encoder.layer3.2.conv3.weight
	pretrained param: encoder.layer3.2.bn3.weight -> current param: encoder.layer3.2.bn3.weight
	pretrained param: encoder.layer3.2.bn3.bias -> current param: encoder.layer3.2.bn3.bias
	pretrained param: encoder.layer3.2.bn3.running_mean -> current param: encoder.layer3.2.bn3.running_mean
	pretrained param: encoder.layer3.2.bn3.running_var -> current param: encoder.layer3.2.bn3.running_var
	pretrained param: encoder.layer3.2.bn3.num_batches_tracked -> current param: encoder.layer3.2.bn3.num_batches_tracked
	pretrained param: encoder.layer3.3.conv1.weight -> current param: encoder.layer3.3.conv1.weight
	pretrained param: encoder.layer3.3.bn1.weight -> current param: encoder.layer3.3.bn1.weight
	pretrained param: encoder.layer3.3.bn1.bias -> current param: encoder.layer3.3.bn1.bias
	pretrained param: encoder.layer3.3.bn1.running_mean -> current param: encoder.layer3.3.bn1.running_mean
	pretrained param: encoder.layer3.3.bn1.running_var -> current param: encoder.layer3.3.bn1.running_var
	pretrained param: encoder.layer3.3.bn1.num_batches_tracked -> current param: encoder.layer3.3.bn1.num_batches_tracked
	pretrained param: encoder.layer3.3.conv2.weight -> current param: encoder.layer3.3.conv2.weight
	pretrained param: encoder.layer3.3.bn2.weight -> current param: encoder.layer3.3.bn2.weight
	pretrained param: encoder.layer3.3.bn2.bias -> current param: encoder.layer3.3.bn2.bias
	pretrained param: encoder.layer3.3.bn2.running_mean -> current param: encoder.layer3.3.bn2.running_mean
	pretrained param: encoder.layer3.3.bn2.running_var -> current param: encoder.layer3.3.bn2.running_var
	pretrained param: encoder.layer3.3.bn2.num_batches_tracked -> current param: encoder.layer3.3.bn2.num_batches_tracked
	pretrained param: encoder.layer3.3.conv3.weight -> current param: encoder.layer3.3.conv3.weight
	pretrained param: encoder.layer3.3.bn3.weight -> current param: encoder.layer3.3.bn3.weight
	pretrained param: encoder.layer3.3.bn3.bias -> current param: encoder.layer3.3.bn3.bias
	pretrained param: encoder.layer3.3.bn3.running_mean -> current param: encoder.layer3.3.bn3.running_mean
	pretrained param: encoder.layer3.3.bn3.running_var -> current param: encoder.layer3.3.bn3.running_var
	pretrained param: encoder.layer3.3.bn3.num_batches_tracked -> current param: encoder.layer3.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.4.conv1.weight -> current param: encoder.layer3.4.conv1.weight
	pretrained param: encoder.layer3.4.bn1.weight -> current param: encoder.layer3.4.bn1.weight
	pretrained param: encoder.layer3.4.bn1.bias -> current param: encoder.layer3.4.bn1.bias
	pretrained param: encoder.layer3.4.bn1.running_mean -> current param: encoder.layer3.4.bn1.running_mean
	pretrained param: encoder.layer3.4.bn1.running_var -> current param: encoder.layer3.4.bn1.running_var
	pretrained param: encoder.layer3.4.bn1.num_batches_tracked -> current param: encoder.layer3.4.bn1.num_batches_tracked
	pretrained param: encoder.layer3.4.conv2.weight -> current param: encoder.layer3.4.conv2.weight
	pretrained param: encoder.layer3.4.bn2.weight -> current param: encoder.layer3.4.bn2.weight
	pretrained param: encoder.layer3.4.bn2.bias -> current param: encoder.layer3.4.bn2.bias
	pretrained param: encoder.layer3.4.bn2.running_mean -> current param: encoder.layer3.4.bn2.running_mean
	pretrained param: encoder.layer3.4.bn2.running_var -> current param: encoder.layer3.4.bn2.running_var
	pretrained param: encoder.layer3.4.bn2.num_batches_tracked -> current param: encoder.layer3.4.bn2.num_batches_tracked
	pretrained param: encoder.layer3.4.conv3.weight -> current param: encoder.layer3.4.conv3.weight
	pretrained param: encoder.layer3.4.bn3.weight -> current param: encoder.layer3.4.bn3.weight
	pretrained param: encoder.layer3.4.bn3.bias -> current param: encoder.layer3.4.bn3.bias
	pretrained param: encoder.layer3.4.bn3.running_mean -> current param: encoder.layer3.4.bn3.running_mean
	pretrained param: encoder.layer3.4.bn3.running_var -> current param: encoder.layer3.4.bn3.running_var
	pretrained param: encoder.layer3.4.bn3.num_batches_tracked -> current param: encoder.layer3.4.bn3.num_batches_tracked
	pretrained param: encoder.layer3.5.conv1.weight -> current param: encoder.layer3.5.conv1.weight
	pretrained param: encoder.layer3.5.bn1.weight -> current param: encoder.layer3.5.bn1.weight
	pretrained param: encoder.layer3.5.bn1.bias -> current param: encoder.layer3.5.bn1.bias
	pretrained param: encoder.layer3.5.bn1.running_mean -> current param: encoder.layer3.5.bn1.running_mean
	pretrained param: encoder.layer3.5.bn1.running_var -> current param: encoder.layer3.5.bn1.running_var
	pretrained param: encoder.layer3.5.bn1.num_batches_tracked -> current param: encoder.layer3.5.bn1.num_batches_tracked
	pretrained param: encoder.layer3.5.conv2.weight -> current param: encoder.layer3.5.conv2.weight
	pretrained param: encoder.layer3.5.bn2.weight -> current param: encoder.layer3.5.bn2.weight
	pretrained param: encoder.layer3.5.bn2.bias -> current param: encoder.layer3.5.bn2.bias
	pretrained param: encoder.layer3.5.bn2.running_mean -> current param: encoder.layer3.5.bn2.running_mean
	pretrained param: encoder.layer3.5.bn2.running_var -> current param: encoder.layer3.5.bn2.running_var
	pretrained param: encoder.layer3.5.bn2.num_batches_tracked -> current param: encoder.layer3.5.bn2.num_batches_tracked
	pretrained param: encoder.layer3.5.conv3.weight -> current param: encoder.layer3.5.conv3.weight
	pretrained param: encoder.layer3.5.bn3.weight -> current param: encoder.layer3.5.bn3.weight
	pretrained param: encoder.layer3.5.bn3.bias -> current param: encoder.layer3.5.bn3.bias
	pretrained param: encoder.layer3.5.bn3.running_mean -> current param: encoder.layer3.5.bn3.running_mean
	pretrained param: encoder.layer3.5.bn3.running_var -> current param: encoder.layer3.5.bn3.running_var
	pretrained param: encoder.layer3.5.bn3.num_batches_tracked -> current param: encoder.layer3.5.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.conv1.weight -> current param: encoder.layer4.0.conv1.weight
	pretrained param: encoder.layer4.0.bn1.weight -> current param: encoder.layer4.0.bn1.weight
	pretrained param: encoder.layer4.0.bn1.bias -> current param: encoder.layer4.0.bn1.bias
	pretrained param: encoder.layer4.0.bn1.running_mean -> current param: encoder.layer4.0.bn1.running_mean
	pretrained param: encoder.layer4.0.bn1.running_var -> current param: encoder.layer4.0.bn1.running_var
	pretrained param: encoder.layer4.0.bn1.num_batches_tracked -> current param: encoder.layer4.0.bn1.num_batches_tracked
	pretrained param: encoder.layer4.0.conv2.weight -> current param: encoder.layer4.0.conv2.weight
	pretrained param: encoder.layer4.0.bn2.weight -> current param: encoder.layer4.0.bn2.weight
	pretrained param: encoder.layer4.0.bn2.bias -> current param: encoder.layer4.0.bn2.bias
	pretrained param: encoder.layer4.0.bn2.running_mean -> current param: encoder.layer4.0.bn2.running_mean
	pretrained param: encoder.layer4.0.bn2.running_var -> current param: encoder.layer4.0.bn2.running_var
	pretrained param: encoder.layer4.0.bn2.num_batches_tracked -> current param: encoder.layer4.0.bn2.num_batches_tracked
	pretrained param: encoder.layer4.0.conv3.weight -> current param: encoder.layer4.0.conv3.weight
	pretrained param: encoder.layer4.0.bn3.weight -> current param: encoder.layer4.0.bn3.weight
	pretrained param: encoder.layer4.0.bn3.bias -> current param: encoder.layer4.0.bn3.bias
	pretrained param: encoder.layer4.0.bn3.running_mean -> current param: encoder.layer4.0.bn3.running_mean
	pretrained param: encoder.layer4.0.bn3.running_var -> current param: encoder.layer4.0.bn3.running_var
	pretrained param: encoder.layer4.0.bn3.num_batches_tracked -> current param: encoder.layer4.0.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.downsample.0.weight -> current param: encoder.layer4.0.downsample.0.weight
	pretrained param: encoder.layer4.0.downsample.1.weight -> current param: encoder.layer4.0.downsample.1.weight
	pretrained param: encoder.layer4.0.downsample.1.bias -> current param: encoder.layer4.0.downsample.1.bias
	pretrained param: encoder.layer4.0.downsample.1.running_mean -> current param: encoder.layer4.0.downsample.1.running_mean
	pretrained param: encoder.layer4.0.downsample.1.running_var -> current param: encoder.layer4.0.downsample.1.running_var
	pretrained param: encoder.layer4.0.downsample.1.num_batches_tracked -> current param: encoder.layer4.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv1.weight -> current param: encoder.layer4.1.conv1.weight
	pretrained param: encoder.layer4.1.bn1.weight -> current param: encoder.layer4.1.bn1.weight
	pretrained param: encoder.layer4.1.bn1.bias -> current param: encoder.layer4.1.bn1.bias
	pretrained param: encoder.layer4.1.bn1.running_mean -> current param: encoder.layer4.1.bn1.running_mean
	pretrained param: encoder.layer4.1.bn1.running_var -> current param: encoder.layer4.1.bn1.running_var
	pretrained param: encoder.layer4.1.bn1.num_batches_tracked -> current param: encoder.layer4.1.bn1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv2.weight -> current param: encoder.layer4.1.conv2.weight
	pretrained param: encoder.layer4.1.bn2.weight -> current param: encoder.layer4.1.bn2.weight
	pretrained param: encoder.layer4.1.bn2.bias -> current param: encoder.layer4.1.bn2.bias
	pretrained param: encoder.layer4.1.bn2.running_mean -> current param: encoder.layer4.1.bn2.running_mean
	pretrained param: encoder.layer4.1.bn2.running_var -> current param: encoder.layer4.1.bn2.running_var
	pretrained param: encoder.layer4.1.bn2.num_batches_tracked -> current param: encoder.layer4.1.bn2.num_batches_tracked
	pretrained param: encoder.layer4.1.conv3.weight -> current param: encoder.layer4.1.conv3.weight
	pretrained param: encoder.layer4.1.bn3.weight -> current param: encoder.layer4.1.bn3.weight
	pretrained param: encoder.layer4.1.bn3.bias -> current param: encoder.layer4.1.bn3.bias
	pretrained param: encoder.layer4.1.bn3.running_mean -> current param: encoder.layer4.1.bn3.running_mean
	pretrained param: encoder.layer4.1.bn3.running_var -> current param: encoder.layer4.1.bn3.running_var
	pretrained param: encoder.layer4.1.bn3.num_batches_tracked -> current param: encoder.layer4.1.bn3.num_batches_tracked
	pretrained param: encoder.layer4.2.conv1.weight -> current param: encoder.layer4.2.conv1.weight
	pretrained param: encoder.layer4.2.bn1.weight -> current param: encoder.layer4.2.bn1.weight
	pretrained param: encoder.layer4.2.bn1.bias -> current param: encoder.layer4.2.bn1.bias
	pretrained param: encoder.layer4.2.bn1.running_mean -> current param: encoder.layer4.2.bn1.running_mean
	pretrained param: encoder.layer4.2.bn1.running_var -> current param: encoder.layer4.2.bn1.running_var
	pretrained param: encoder.layer4.2.bn1.num_batches_tracked -> current param: encoder.layer4.2.bn1.num_batches_tracked
	pretrained param: encoder.layer4.2.conv2.weight -> current param: encoder.layer4.2.conv2.weight
	pretrained param: encoder.layer4.2.bn2.weight -> current param: encoder.layer4.2.bn2.weight
	pretrained param: encoder.layer4.2.bn2.bias -> current param: encoder.layer4.2.bn2.bias
	pretrained param: encoder.layer4.2.bn2.running_mean -> current param: encoder.layer4.2.bn2.running_mean
	pretrained param: encoder.layer4.2.bn2.running_var -> current param: encoder.layer4.2.bn2.running_var
	pretrained param: encoder.layer4.2.bn2.num_batches_tracked -> current param: encoder.layer4.2.bn2.num_batches_tracked
	pretrained param: encoder.layer4.2.conv3.weight -> current param: encoder.layer4.2.conv3.weight
	pretrained param: encoder.layer4.2.bn3.weight -> current param: encoder.layer4.2.bn3.weight
	pretrained param: encoder.layer4.2.bn3.bias -> current param: encoder.layer4.2.bn3.bias
	pretrained param: encoder.layer4.2.bn3.running_mean -> current param: encoder.layer4.2.bn3.running_mean
	pretrained param: encoder.layer4.2.bn3.running_var -> current param: encoder.layer4.2.bn3.running_var
	pretrained param: encoder.layer4.2.bn3.num_batches_tracked -> current param: encoder.layer4.2.bn3.num_batches_tracked
	pretrained param: decoder.classify.weight -> current param: decoder.classify.weight
		Ignoring: decoder.classify.weight->decoder.classify.weight (size mismatch)
	pretrained param: decoder.classify.bias -> current param: decoder.classify.bias
90.11% of the model loaded from the pretrained
Total params: 179.77M
Dataset catalyst_h3 is not supported, use default mean stats instead
Training model on the catalyst_h3 dataset
Dataset catalyst_h3 is not supported, use default mean stats instead
[train] Epoch: 0/80 xent: 1.564 softIoU: 8.305 IoU: 0.000 
Execution time: 279.21571647329256

[valid] Epoch: 0/80 xent: 0.429 softIoU: 8.021 IoU: 0.000 
Execution time: 40.316019700840116

[train] Epoch: 1/80 xent: 0.512 softIoU: 8.019 IoU: 0.000 
Execution time: 280.05513535859063

[valid] Epoch: 1/80 xent: 0.427 softIoU: 8.018 IoU: 0.000 
Execution time: 41.13531137490645

[train] Epoch: 2/80 xent: 0.511 softIoU: 8.019 IoU: 0.000 
Execution time: 283.60686162207276

[valid] Epoch: 2/80 xent: 0.427 softIoU: 8.018 IoU: 0.000 
Execution time: 42.061152786016464

[train] Epoch: 3/80 xent: 0.511 softIoU: 8.019 IoU: 0.000 
Execution time: 281.07469788286835

[valid] Epoch: 3/80 xent: 0.426 softIoU: 8.018 IoU: 0.000 
Execution time: 41.0089538609609

[train] Epoch: 4/80 xent: 0.511 softIoU: 8.017 IoU: 0.000 
Execution time: 282.32157086301595

[valid] Epoch: 4/80 xent: 0.426 softIoU: 8.018 IoU: 0.000 
Execution time: 41.87407310213894

[train] Epoch: 5/80 xent: 0.509 softIoU: 8.019 IoU: 0.000 
Execution time: 280.080969016999

[valid] Epoch: 5/80 xent: 0.425 softIoU: 8.019 IoU: 0.000 
Execution time: 41.238766327966005

[train] Epoch: 6/80 xent: 0.509 softIoU: 8.018 IoU: 0.000 
Execution time: 280.97952972585335

[valid] Epoch: 6/80 xent: 0.425 softIoU: 8.019 IoU: 0.000 
Execution time: 41.42414395697415

[train] Epoch: 7/80 xent: 0.499 softIoU: 8.019 IoU: 0.000 
Execution time: 280.87618999602273

[valid] Epoch: 7/80 xent: 0.423 softIoU: 8.018 IoU: 0.000 
Execution time: 40.60859411302954

[train] Epoch: 8/80 xent: 0.504 softIoU: 8.018 IoU: 0.000 
Execution time: 282.3918746323325

[valid] Epoch: 8/80 xent: 0.423 softIoU: 8.018 IoU: 0.000 
Execution time: 42.45590922702104

[train] Epoch: 9/80 xent: 0.506 softIoU: 8.018 IoU: 0.000 
Execution time: 280.6310623199679

[valid] Epoch: 9/80 xent: 0.421 softIoU: 8.018 IoU: 0.000 
Execution time: 40.862890149932355

[train] Epoch: 10/80 xent: 0.504 softIoU: 8.019 IoU: 0.000 
Execution time: 280.7027103137225

[valid] Epoch: 10/80 xent: 0.420 softIoU: 8.017 IoU: 0.000 
Execution time: 40.72161682089791

[train] Epoch: 11/80 xent: 0.503 softIoU: 8.017 IoU: 0.000 
Execution time: 281.21051040897146

[valid] Epoch: 11/80 xent: 0.419 softIoU: 8.017 IoU: 0.000 
Execution time: 41.05094192177057

[train] Epoch: 12/80 xent: 0.500 softIoU: 8.018 IoU: 0.000 
Execution time: 279.95431848289445

[valid] Epoch: 12/80 xent: 0.418 softIoU: 8.019 IoU: 0.000 
Execution time: 41.106428757309914

[train] Epoch: 13/80 xent: 0.499 softIoU: 8.018 IoU: 0.000 
Execution time: 280.01015676464885

[valid] Epoch: 13/80 xent: 0.415 softIoU: 8.018 IoU: 0.000 
Execution time: 40.33111282996833

[train] Epoch: 14/80 xent: 0.487 softIoU: 8.017 IoU: 0.000 
Execution time: 280.36010678717867

[valid] Epoch: 14/80 xent: 0.413 softIoU: 8.019 IoU: 0.000 
Execution time: 41.58168382430449

[train] Epoch: 15/80 xent: 0.491 softIoU: 8.017 IoU: 0.000 
Execution time: 279.941792414058

[valid] Epoch: 15/80 xent: 0.409 softIoU: 8.018 IoU: 0.000 
Execution time: 41.01501185493544

[train] Epoch: 16/80 xent: 0.483 softIoU: 8.018 IoU: 0.000 
Execution time: 280.43703670287505

[valid] Epoch: 16/80 xent: 0.403 softIoU: 8.017 IoU: 0.000 
Execution time: 41.788270881865174

[train] Epoch: 17/80 xent: 0.477 softIoU: 8.017 IoU: 0.000 
Execution time: 284.06098919408396

[valid] Epoch: 17/80 xent: 0.396 softIoU: 8.017 IoU: 0.000 
Execution time: 42.439115073066205

[train] Epoch: 18/80 xent: 0.466 softIoU: 8.017 IoU: 0.000 
Execution time: 288.2808878822252

[valid] Epoch: 18/80 xent: 0.383 softIoU: 8.016 IoU: 0.000 
Execution time: 44.6566159799695

[train] Epoch: 19/80 xent: 0.441 softIoU: 8.016 IoU: 0.000 
Execution time: 288.8271011537872

[valid] Epoch: 19/80 xent: 0.362 softIoU: 8.014 IoU: 0.000 
Execution time: 42.57242736406624

[train] Epoch: 20/80 xent: 0.403 softIoU: 8.013 IoU: 0.000 
Execution time: 288.0962288971059

[valid] Epoch: 20/80 xent: 0.320 softIoU: 8.011 IoU: 0.000 
Execution time: 43.02522233594209

Saved model at /scratch/sr365/models/catalysth3_mb_4/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-20.pth.tar
[train] Epoch: 21/80 xent: 0.315 softIoU: 8.000 IoU: 0.010 
Execution time: 288.0310020339675

[valid] Epoch: 21/80 xent: 0.198 softIoU: 7.977 IoU: 0.039 
Execution time: 40.77416278561577

[train] Epoch: 22/80 xent: 0.143 softIoU: 7.895 IoU: 0.247 
Execution time: 284.2728627184406

[valid] Epoch: 22/80 xent: 0.067 softIoU: 7.825 IoU: 0.317 
Execution time: 40.71769624715671

[train] Epoch: 23/80 xent: 0.060 softIoU: 7.758 IoU: 0.294 
Execution time: 281.40843811118975

[valid] Epoch: 23/80 xent: 0.035 softIoU: 7.751 IoU: 0.368 
Execution time: 40.84098168602213

[train] Epoch: 24/80 xent: 0.045 softIoU: 7.699 IoU: 0.281 
Execution time: 283.766174740158

[valid] Epoch: 24/80 xent: 0.022 softIoU: 7.726 IoU: 0.370 
Execution time: 40.43234836915508

[train] Epoch: 25/80 xent: 0.037 softIoU: 7.711 IoU: 0.284 
Execution time: 280.6878412682563

[valid] Epoch: 25/80 xent: 0.020 softIoU: 7.722 IoU: 0.425 
Execution time: 40.590364965144545

[train] Epoch: 26/80 xent: 0.034 softIoU: 7.683 IoU: 0.302 
Execution time: 281.63312825607136

[valid] Epoch: 26/80 xent: 0.019 softIoU: 7.716 IoU: 0.452 
Execution time: 42.851674342062324

[train] Epoch: 27/80 xent: 0.032 softIoU: 7.676 IoU: 0.332 
Execution time: 283.77948591904715

[valid] Epoch: 27/80 xent: 0.017 softIoU: 7.714 IoU: 0.458 
Execution time: 40.95354104368016

[train] Epoch: 28/80 xent: 0.032 softIoU: 7.688 IoU: 0.329 
Execution time: 280.8217311417684

[valid] Epoch: 28/80 xent: 0.019 softIoU: 7.713 IoU: 0.386 
Execution time: 40.42382044484839

[train] Epoch: 29/80 xent: 0.033 softIoU: 7.669 IoU: 0.335 
Execution time: 281.69281833898276

[valid] Epoch: 29/80 xent: 0.016 softIoU: 7.713 IoU: 0.409 
Execution time: 41.53658824181184

[train] Epoch: 30/80 xent: 0.032 softIoU: 7.674 IoU: 0.321 
Execution time: 281.3924715719186

[valid] Epoch: 30/80 xent: 0.019 softIoU: 7.712 IoU: 0.461 
Execution time: 40.713007673155516

[train] Epoch: 31/80 xent: 0.030 softIoU: 7.670 IoU: 0.357 
Execution time: 282.12277758680284

[valid] Epoch: 31/80 xent: 0.015 softIoU: 7.711 IoU: 0.434 
Execution time: 41.196054313797504

[train] Epoch: 32/80 xent: 0.031 softIoU: 7.661 IoU: 0.341 
Execution time: 282.2913338202052

[valid] Epoch: 32/80 xent: 0.016 softIoU: 7.709 IoU: 0.408 
Execution time: 40.887744651176035

[train] Epoch: 33/80 xent: 0.027 softIoU: 7.669 IoU: 0.357 
Execution time: 280.2619845159352

[valid] Epoch: 33/80 xent: 0.014 softIoU: 7.708 IoU: 0.472 
Execution time: 42.41965913493186

[train] Epoch: 34/80 xent: 0.028 softIoU: 7.665 IoU: 0.369 
Execution time: 281.40841892687604

[valid] Epoch: 34/80 xent: 0.014 softIoU: 7.705 IoU: 0.512 
Execution time: 40.831070583779365

[train] Epoch: 35/80 xent: 0.026 softIoU: 7.644 IoU: 0.380 
Execution time: 279.98297298233956

[valid] Epoch: 35/80 xent: 0.014 softIoU: 7.707 IoU: 0.490 
Execution time: 40.642500861082226

[train] Epoch: 36/80 xent: 0.029 softIoU: 7.657 IoU: 0.377 
Execution time: 282.8197452626191

[valid] Epoch: 36/80 xent: 0.014 softIoU: 7.709 IoU: 0.399 
Execution time: 40.83200430870056

[train] Epoch: 37/80 xent: 0.030 softIoU: 7.672 IoU: 0.357 
Execution time: 280.2420191797428

[valid] Epoch: 37/80 xent: 0.015 softIoU: 7.705 IoU: 0.521 
Execution time: 42.85225264914334

[train] Epoch: 38/80 xent: 0.029 softIoU: 7.660 IoU: 0.382 
Execution time: 280.7523430339061

[valid] Epoch: 38/80 xent: 0.013 softIoU: 7.708 IoU: 0.442 
Execution time: 40.83753439830616

[train] Epoch: 39/80 xent: 0.023 softIoU: 7.660 IoU: 0.401 
Execution time: 281.6440961477347

[valid] Epoch: 39/80 xent: 0.014 softIoU: 7.703 IoU: 0.534 
Execution time: 42.16693581920117

[train] Epoch: 40/80 xent: 0.025 softIoU: 7.648 IoU: 0.377 
Execution time: 280.68570274906233

[valid] Epoch: 40/80 xent: 0.013 softIoU: 7.705 IoU: 0.499 
Execution time: 41.77302578324452

Saved model at /scratch/sr365/models/catalysth3_mb_4/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-40.pth.tar
[train] Epoch: 41/80 xent: 0.025 softIoU: 7.654 IoU: 0.434 
Execution time: 281.2914473861456

[valid] Epoch: 41/80 xent: 0.013 softIoU: 7.710 IoU: 0.443 
Execution time: 40.921351552940905

[train] Epoch: 42/80 xent: 0.024 softIoU: 7.649 IoU: 0.409 
Execution time: 281.82928226701915

[valid] Epoch: 42/80 xent: 0.012 softIoU: 7.705 IoU: 0.475 
Execution time: 40.80422927998006

[train] Epoch: 43/80 xent: 0.023 softIoU: 7.651 IoU: 0.422 
Execution time: 281.35485178790987

[valid] Epoch: 43/80 xent: 0.012 softIoU: 7.703 IoU: 0.518 
Execution time: 41.92034962726757

[train] Epoch: 44/80 xent: 0.024 softIoU: 7.649 IoU: 0.415 
Execution time: 283.93330017104745

[valid] Epoch: 44/80 xent: 0.013 softIoU: 7.699 IoU: 0.550 
Execution time: 41.38437711307779

[train] Epoch: 45/80 xent: 0.023 softIoU: 7.648 IoU: 0.406 
Execution time: 279.9894170323387

[valid] Epoch: 45/80 xent: 0.012 softIoU: 7.702 IoU: 0.520 
Execution time: 41.13422289211303

[train] Epoch: 46/80 xent: 0.025 softIoU: 7.651 IoU: 0.451 
Execution time: 279.9620742299594

[valid] Epoch: 46/80 xent: 0.012 softIoU: 7.702 IoU: 0.519 
Execution time: 40.52467190288007

[train] Epoch: 47/80 xent: 0.023 softIoU: 7.647 IoU: 0.432 
Execution time: 283.9602117007598

[valid] Epoch: 47/80 xent: 0.012 softIoU: 7.701 IoU: 0.520 
Execution time: 41.56140417838469

[train] Epoch: 48/80 xent: 0.023 softIoU: 7.662 IoU: 0.451 
Execution time: 281.71557994838804

[valid] Epoch: 48/80 xent: 0.012 softIoU: 7.703 IoU: 0.516 
Execution time: 42.56510825874284

[train] Epoch: 49/80 xent: 0.023 softIoU: 7.654 IoU: 0.424 
Execution time: 286.5984007436782

[valid] Epoch: 49/80 xent: 0.012 softIoU: 7.699 IoU: 0.532 
Execution time: 42.95916645415127

[train] Epoch: 50/80 xent: 0.021 softIoU: 7.651 IoU: 0.440 
Execution time: 292.69520683120936

[valid] Epoch: 50/80 xent: 0.011 softIoU: 7.704 IoU: 0.500 
Execution time: 43.194567195139825

[train] Epoch: 51/80 xent: 0.020 softIoU: 7.636 IoU: 0.444 
Execution time: 289.58670734008774

[valid] Epoch: 51/80 xent: 0.011 softIoU: 7.704 IoU: 0.501 
Execution time: 42.34119534585625

[train] Epoch: 52/80 xent: 0.021 softIoU: 7.664 IoU: 0.448 
Execution time: 296.63868280826136

[valid] Epoch: 52/80 xent: 0.011 softIoU: 7.701 IoU: 0.526 
Execution time: 43.8006497817114

[train] Epoch: 53/80 xent: 0.021 softIoU: 7.649 IoU: 0.470 
Execution time: 294.38825344573706

[valid] Epoch: 53/80 xent: 0.011 softIoU: 7.702 IoU: 0.514 
Execution time: 43.554759606253356

[train] Epoch: 54/80 xent: 0.019 softIoU: 7.659 IoU: 0.468 
Execution time: 300.1886385786347

[valid] Epoch: 54/80 xent: 0.012 softIoU: 7.699 IoU: 0.539 
Execution time: 45.020426540169865

[train] Epoch: 55/80 xent: 0.020 softIoU: 7.636 IoU: 0.473 
Execution time: 291.45821109972894

[valid] Epoch: 55/80 xent: 0.012 softIoU: 7.698 IoU: 0.545 
Execution time: 41.38929607812315

[train] Epoch: 56/80 xent: 0.021 softIoU: 7.640 IoU: 0.464 
Execution time: 296.45795228518546

[valid] Epoch: 56/80 xent: 0.012 softIoU: 7.699 IoU: 0.537 
Execution time: 44.476671013981104

[train] Epoch: 57/80 xent: 0.020 softIoU: 7.634 IoU: 0.474 
Execution time: 295.7231065509841

[valid] Epoch: 57/80 xent: 0.012 softIoU: 7.698 IoU: 0.548 
Execution time: 45.24234208930284

[train] Epoch: 58/80 xent: 0.020 softIoU: 7.640 IoU: 0.482 
Execution time: 292.46280455589294

[valid] Epoch: 58/80 xent: 0.012 softIoU: 7.700 IoU: 0.531 
Execution time: 43.550373792182654

[train] Epoch: 59/80 xent: 0.021 softIoU: 7.644 IoU: 0.467 
Execution time: 297.9821938308887

[valid] Epoch: 59/80 xent: 0.012 softIoU: 7.699 IoU: 0.538 
Execution time: 40.95689998706803

[train] Epoch: 60/80 xent: 0.022 softIoU: 7.631 IoU: 0.468 
Execution time: 281.03586943401024

[valid] Epoch: 60/80 xent: 0.012 softIoU: 7.698 IoU: 0.548 
Execution time: 40.72726170672104

Saved model at /scratch/sr365/models/catalysth3_mb_4/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-60.pth.tar
[train] Epoch: 61/80 xent: 0.021 softIoU: 7.639 IoU: 0.457 
Execution time: 281.11938351299614

[valid] Epoch: 61/80 xent: 0.011 softIoU: 7.701 IoU: 0.513 
Execution time: 41.00375042995438

[train] Epoch: 62/80 xent: 0.021 softIoU: 7.644 IoU: 0.467 
Execution time: 299.68416119599715

[valid] Epoch: 62/80 xent: 0.011 softIoU: 7.701 IoU: 0.523 
Execution time: 45.27172918524593

[train] Epoch: 63/80 xent: 0.020 softIoU: 7.636 IoU: 0.467 
Execution time: 294.44131532497704

[valid] Epoch: 63/80 xent: 0.012 softIoU: 7.699 IoU: 0.537 
Execution time: 44.20750199072063

[train] Epoch: 64/80 xent: 0.020 softIoU: 7.643 IoU: 0.472 
Execution time: 282.42725045001134

[valid] Epoch: 64/80 xent: 0.011 softIoU: 7.700 IoU: 0.524 
Execution time: 45.91984404437244

[train] Epoch: 65/80 xent: 0.020 softIoU: 7.648 IoU: 0.490 
Execution time: 293.95302990311757

[valid] Epoch: 65/80 xent: 0.012 softIoU: 7.699 IoU: 0.538 
Execution time: 41.24653881415725

[train] Epoch: 66/80 xent: 0.021 softIoU: 7.636 IoU: 0.474 
Execution time: 281.96215110691264

[valid] Epoch: 66/80 xent: 0.011 softIoU: 7.700 IoU: 0.528 
Execution time: 41.2034401060082

[train] Epoch: 67/80 xent: 0.021 softIoU: 7.638 IoU: 0.469 
Execution time: 282.35563788190484

[valid] Epoch: 67/80 xent: 0.012 softIoU: 7.697 IoU: 0.549 
Execution time: 40.99394448194653

[train] Epoch: 68/80 xent: 0.021 softIoU: 7.638 IoU: 0.465 
Execution time: 292.3847540933639

[valid] Epoch: 68/80 xent: 0.011 softIoU: 7.701 IoU: 0.525 
Execution time: 41.32880557188764

[train] Epoch: 69/80 xent: 0.020 softIoU: 7.641 IoU: 0.474 
Execution time: 301.4681688961573

[valid] Epoch: 69/80 xent: 0.011 softIoU: 7.700 IoU: 0.522 
Execution time: 45.69876555399969

[train] Epoch: 70/80 xent: 0.021 softIoU: 7.642 IoU: 0.473 
Execution time: 299.5498580476269

[valid] Epoch: 70/80 xent: 0.012 softIoU: 7.701 IoU: 0.521 
Execution time: 41.16236700583249

[train] Epoch: 71/80 xent: 0.020 softIoU: 7.641 IoU: 0.475 
Execution time: 281.088989934884

[valid] Epoch: 71/80 xent: 0.011 softIoU: 7.701 IoU: 0.519 
Execution time: 41.727180403191596

[train] Epoch: 72/80 xent: 0.020 softIoU: 7.648 IoU: 0.486 
Execution time: 281.41563244489953

[valid] Epoch: 72/80 xent: 0.012 softIoU: 7.698 IoU: 0.543 
Execution time: 45.03356530237943

[train] Epoch: 73/80 xent: 0.020 softIoU: 7.644 IoU: 0.482 
Execution time: 282.00141113018617

[valid] Epoch: 73/80 xent: 0.011 softIoU: 7.701 IoU: 0.523 
Execution time: 45.516130391974

[train] Epoch: 74/80 xent: 0.020 softIoU: 7.638 IoU: 0.475 
Execution time: 281.6195774991065

[valid] Epoch: 74/80 xent: 0.011 softIoU: 7.699 IoU: 0.533 
Execution time: 45.45833432395011

[train] Epoch: 75/80 xent: 0.021 softIoU: 7.640 IoU: 0.488 
Execution time: 280.98859417811036

[valid] Epoch: 75/80 xent: 0.011 softIoU: 7.699 IoU: 0.531 
Execution time: 41.40840967791155

[train] Epoch: 76/80 xent: 0.020 softIoU: 7.631 IoU: 0.474 
Execution time: 302.3113182610832

[valid] Epoch: 76/80 xent: 0.011 softIoU: 7.700 IoU: 0.523 
Execution time: 41.26335051190108

[train] Epoch: 77/80 xent: 0.022 softIoU: 7.650 IoU: 0.473 
Execution time: 281.27513100905344

[valid] Epoch: 77/80 xent: 0.013 softIoU: 7.697 IoU: 0.556 
Execution time: 45.571241394151

[train] Epoch: 78/80 xent: 0.020 softIoU: 7.647 IoU: 0.469 
Execution time: 288.2337779039517

[valid] Epoch: 78/80 xent: 0.012 softIoU: 7.698 IoU: 0.540 
Execution time: 40.890215288847685

[train] Epoch: 79/80 xent: 0.020 softIoU: 7.646 IoU: 0.474 
Execution time: 312.34530896367505

[valid] Epoch: 79/80 xent: 0.011 softIoU: 7.702 IoU: 0.509 
Execution time: 41.49787980271503

Saved model at /scratch/sr365/models/catalysth3_mb_4/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-80.pth.tar
Device being used: cuda:0
Finetuning model from /scratch/wh145/models/solarmapper_final/ct/epoch-80.pth.tar
Warning: The following parameters in the pretrained model does not exist in the current model
	 decoder.uc.0.up_conv.weight
	 decoder.uc.0.up_conv.bias
	 decoder.uc.0.conv_1.weight
	 decoder.uc.0.conv_1.bias
	 decoder.uc.0.conv_2.weight
	 decoder.uc.0.conv_2.bias
	 decoder.uc.0.bn_1.weight
	 decoder.uc.0.bn_1.bias
	 decoder.uc.0.bn_1.running_mean
	 decoder.uc.0.bn_1.running_var
	 decoder.uc.0.bn_1.num_batches_tracked
	 decoder.uc.0.bn_2.weight
	 decoder.uc.0.bn_2.bias
	 decoder.uc.0.bn_2.running_mean
	 decoder.uc.0.bn_2.running_var
	 decoder.uc.0.bn_2.num_batches_tracked
	 decoder.uc.0.act.weight
	 decoder.uc.1.up_conv.weight
	 decoder.uc.1.up_conv.bias
	 decoder.uc.1.conv_1.weight
	 decoder.uc.1.conv_1.bias
	 decoder.uc.1.conv_2.weight
	 decoder.uc.1.conv_2.bias
	 decoder.uc.1.bn_1.weight
	 decoder.uc.1.bn_1.bias
	 decoder.uc.1.bn_1.running_mean
	 decoder.uc.1.bn_1.running_var
	 decoder.uc.1.bn_1.num_batches_tracked
	 decoder.uc.1.bn_2.weight
	 decoder.uc.1.bn_2.bias
	 decoder.uc.1.bn_2.running_mean
	 decoder.uc.1.bn_2.running_var
	 decoder.uc.1.bn_2.num_batches_tracked
	 decoder.uc.1.act.weight
	 decoder.uc.2.up_conv.weight
	 decoder.uc.2.up_conv.bias
	 decoder.uc.2.conv_1.weight
	 decoder.uc.2.conv_1.bias
	 decoder.uc.2.conv_2.weight
	 decoder.uc.2.conv_2.bias
	 decoder.uc.2.bn_1.weight
	 decoder.uc.2.bn_1.bias
	 decoder.uc.2.bn_1.running_mean
	 decoder.uc.2.bn_1.running_var
	 decoder.uc.2.bn_1.num_batches_tracked
	 decoder.uc.2.bn_2.weight
	 decoder.uc.2.bn_2.bias
	 decoder.uc.2.bn_2.running_mean
	 decoder.uc.2.bn_2.running_var
	 decoder.uc.2.bn_2.num_batches_tracked
	 decoder.uc.2.act.weight
	 decoder.uc.3.up_conv.weight
	 decoder.uc.3.up_conv.bias
	 decoder.uc.3.conv_1.weight
	 decoder.uc.3.conv_1.bias
	 decoder.uc.3.conv_2.weight
	 decoder.uc.3.conv_2.bias
	 decoder.uc.3.bn_1.weight
	 decoder.uc.3.bn_1.bias
	 decoder.uc.3.bn_1.running_mean
	 decoder.uc.3.bn_1.running_var
	 decoder.uc.3.bn_1.num_batches_tracked
	 decoder.uc.3.bn_2.weight
	 decoder.uc.3.bn_2.bias
	 decoder.uc.3.bn_2.running_mean
	 decoder.uc.3.bn_2.running_var
	 decoder.uc.3.bn_2.num_batches_tracked
	 decoder.uc.3.act.weight
Warning: The following parameters in the current model does not exist in the pretrained model
	 decoder.center_dilation.dconv_1.weight
	 decoder.center_dilation.dconv_1.bias
	 decoder.center_dilation.dconv_2.weight
	 decoder.center_dilation.dconv_2.bias
	 decoder.center_dilation.dconv_3.weight
	 decoder.center_dilation.dconv_3.bias
	 decoder.center_dilation.dconv_4.weight
	 decoder.center_dilation.dconv_4.bias
	 decoder.upsample_1.conv1.weight
	 decoder.upsample_1.conv1.bias
	 decoder.upsample_1.tconv.weight
	 decoder.upsample_1.tconv.bias
	 decoder.upsample_1.conv2.weight
	 decoder.upsample_1.conv2.bias
	 decoder.upsample_2.conv1.weight
	 decoder.upsample_2.conv1.bias
	 decoder.upsample_2.tconv.weight
	 decoder.upsample_2.tconv.bias
	 decoder.upsample_2.conv2.weight
	 decoder.upsample_2.conv2.bias
	 decoder.upsample_3.conv1.weight
	 decoder.upsample_3.conv1.bias
	 decoder.upsample_3.tconv.weight
	 decoder.upsample_3.tconv.bias
	 decoder.upsample_3.conv2.weight
	 decoder.upsample_3.conv2.bias
	 decoder.upsample_4.conv1.weight
	 decoder.upsample_4.conv1.bias
	 decoder.upsample_4.tconv.weight
	 decoder.upsample_4.tconv.bias
	 decoder.upsample_4.conv2.weight
	 decoder.upsample_4.conv2.bias
	 decoder.tconv.weight
	 decoder.tconv.bias
Warning: The size of the following parameters in the current model does not match the ones in the pretrained model
	 decoder.classify.weight
Try loading with relaxed naming rule:
Prefix in pretrained model 
	pretrained param: encoder.conv1.weight -> current param: encoder.conv1.weight
	pretrained param: encoder.bn1.weight -> current param: encoder.bn1.weight
	pretrained param: encoder.bn1.bias -> current param: encoder.bn1.bias
	pretrained param: encoder.bn1.running_mean -> current param: encoder.bn1.running_mean
	pretrained param: encoder.bn1.running_var -> current param: encoder.bn1.running_var
	pretrained param: encoder.bn1.num_batches_tracked -> current param: encoder.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv1.weight -> current param: encoder.layer1.0.conv1.weight
	pretrained param: encoder.layer1.0.bn1.weight -> current param: encoder.layer1.0.bn1.weight
	pretrained param: encoder.layer1.0.bn1.bias -> current param: encoder.layer1.0.bn1.bias
	pretrained param: encoder.layer1.0.bn1.running_mean -> current param: encoder.layer1.0.bn1.running_mean
	pretrained param: encoder.layer1.0.bn1.running_var -> current param: encoder.layer1.0.bn1.running_var
	pretrained param: encoder.layer1.0.bn1.num_batches_tracked -> current param: encoder.layer1.0.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv2.weight -> current param: encoder.layer1.0.conv2.weight
	pretrained param: encoder.layer1.0.bn2.weight -> current param: encoder.layer1.0.bn2.weight
	pretrained param: encoder.layer1.0.bn2.bias -> current param: encoder.layer1.0.bn2.bias
	pretrained param: encoder.layer1.0.bn2.running_mean -> current param: encoder.layer1.0.bn2.running_mean
	pretrained param: encoder.layer1.0.bn2.running_var -> current param: encoder.layer1.0.bn2.running_var
	pretrained param: encoder.layer1.0.bn2.num_batches_tracked -> current param: encoder.layer1.0.bn2.num_batches_tracked
	pretrained param: encoder.layer1.0.conv3.weight -> current param: encoder.layer1.0.conv3.weight
	pretrained param: encoder.layer1.0.bn3.weight -> current param: encoder.layer1.0.bn3.weight
	pretrained param: encoder.layer1.0.bn3.bias -> current param: encoder.layer1.0.bn3.bias
	pretrained param: encoder.layer1.0.bn3.running_mean -> current param: encoder.layer1.0.bn3.running_mean
	pretrained param: encoder.layer1.0.bn3.running_var -> current param: encoder.layer1.0.bn3.running_var
	pretrained param: encoder.layer1.0.bn3.num_batches_tracked -> current param: encoder.layer1.0.bn3.num_batches_tracked
	pretrained param: encoder.layer1.0.downsample.0.weight -> current param: encoder.layer1.0.downsample.0.weight
	pretrained param: encoder.layer1.0.downsample.1.weight -> current param: encoder.layer1.0.downsample.1.weight
	pretrained param: encoder.layer1.0.downsample.1.bias -> current param: encoder.layer1.0.downsample.1.bias
	pretrained param: encoder.layer1.0.downsample.1.running_mean -> current param: encoder.layer1.0.downsample.1.running_mean
	pretrained param: encoder.layer1.0.downsample.1.running_var -> current param: encoder.layer1.0.downsample.1.running_var
	pretrained param: encoder.layer1.0.downsample.1.num_batches_tracked -> current param: encoder.layer1.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv1.weight -> current param: encoder.layer1.1.conv1.weight
	pretrained param: encoder.layer1.1.bn1.weight -> current param: encoder.layer1.1.bn1.weight
	pretrained param: encoder.layer1.1.bn1.bias -> current param: encoder.layer1.1.bn1.bias
	pretrained param: encoder.layer1.1.bn1.running_mean -> current param: encoder.layer1.1.bn1.running_mean
	pretrained param: encoder.layer1.1.bn1.running_var -> current param: encoder.layer1.1.bn1.running_var
	pretrained param: encoder.layer1.1.bn1.num_batches_tracked -> current param: encoder.layer1.1.bn1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv2.weight -> current param: encoder.layer1.1.conv2.weight
	pretrained param: encoder.layer1.1.bn2.weight -> current param: encoder.layer1.1.bn2.weight
	pretrained param: encoder.layer1.1.bn2.bias -> current param: encoder.layer1.1.bn2.bias
	pretrained param: encoder.layer1.1.bn2.running_mean -> current param: encoder.layer1.1.bn2.running_mean
	pretrained param: encoder.layer1.1.bn2.running_var -> current param: encoder.layer1.1.bn2.running_var
	pretrained param: encoder.layer1.1.bn2.num_batches_tracked -> current param: encoder.layer1.1.bn2.num_batches_tracked
	pretrained param: encoder.layer1.1.conv3.weight -> current param: encoder.layer1.1.conv3.weight
	pretrained param: encoder.layer1.1.bn3.weight -> current param: encoder.layer1.1.bn3.weight
	pretrained param: encoder.layer1.1.bn3.bias -> current param: encoder.layer1.1.bn3.bias
	pretrained param: encoder.layer1.1.bn3.running_mean -> current param: encoder.layer1.1.bn3.running_mean
	pretrained param: encoder.layer1.1.bn3.running_var -> current param: encoder.layer1.1.bn3.running_var
	pretrained param: encoder.layer1.1.bn3.num_batches_tracked -> current param: encoder.layer1.1.bn3.num_batches_tracked
	pretrained param: encoder.layer1.2.conv1.weight -> current param: encoder.layer1.2.conv1.weight
	pretrained param: encoder.layer1.2.bn1.weight -> current param: encoder.layer1.2.bn1.weight
	pretrained param: encoder.layer1.2.bn1.bias -> current param: encoder.layer1.2.bn1.bias
	pretrained param: encoder.layer1.2.bn1.running_mean -> current param: encoder.layer1.2.bn1.running_mean
	pretrained param: encoder.layer1.2.bn1.running_var -> current param: encoder.layer1.2.bn1.running_var
	pretrained param: encoder.layer1.2.bn1.num_batches_tracked -> current param: encoder.layer1.2.bn1.num_batches_tracked
	pretrained param: encoder.layer1.2.conv2.weight -> current param: encoder.layer1.2.conv2.weight
	pretrained param: encoder.layer1.2.bn2.weight -> current param: encoder.layer1.2.bn2.weight
	pretrained param: encoder.layer1.2.bn2.bias -> current param: encoder.layer1.2.bn2.bias
	pretrained param: encoder.layer1.2.bn2.running_mean -> current param: encoder.layer1.2.bn2.running_mean
	pretrained param: encoder.layer1.2.bn2.running_var -> current param: encoder.layer1.2.bn2.running_var
	pretrained param: encoder.layer1.2.bn2.num_batches_tracked -> current param: encoder.layer1.2.bn2.num_batches_tracked
	pretrained param: encoder.layer1.2.conv3.weight -> current param: encoder.layer1.2.conv3.weight
	pretrained param: encoder.layer1.2.bn3.weight -> current param: encoder.layer1.2.bn3.weight
	pretrained param: encoder.layer1.2.bn3.bias -> current param: encoder.layer1.2.bn3.bias
	pretrained param: encoder.layer1.2.bn3.running_mean -> current param: encoder.layer1.2.bn3.running_mean
	pretrained param: encoder.layer1.2.bn3.running_var -> current param: encoder.layer1.2.bn3.running_var
	pretrained param: encoder.layer1.2.bn3.num_batches_tracked -> current param: encoder.layer1.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.conv1.weight -> current param: encoder.layer2.0.conv1.weight
	pretrained param: encoder.layer2.0.bn1.weight -> current param: encoder.layer2.0.bn1.weight
	pretrained param: encoder.layer2.0.bn1.bias -> current param: encoder.layer2.0.bn1.bias
	pretrained param: encoder.layer2.0.bn1.running_mean -> current param: encoder.layer2.0.bn1.running_mean
	pretrained param: encoder.layer2.0.bn1.running_var -> current param: encoder.layer2.0.bn1.running_var
	pretrained param: encoder.layer2.0.bn1.num_batches_tracked -> current param: encoder.layer2.0.bn1.num_batches_tracked
	pretrained param: encoder.layer2.0.conv2.weight -> current param: encoder.layer2.0.conv2.weight
	pretrained param: encoder.layer2.0.bn2.weight -> current param: encoder.layer2.0.bn2.weight
	pretrained param: encoder.layer2.0.bn2.bias -> current param: encoder.layer2.0.bn2.bias
	pretrained param: encoder.layer2.0.bn2.running_mean -> current param: encoder.layer2.0.bn2.running_mean
	pretrained param: encoder.layer2.0.bn2.running_var -> current param: encoder.layer2.0.bn2.running_var
	pretrained param: encoder.layer2.0.bn2.num_batches_tracked -> current param: encoder.layer2.0.bn2.num_batches_tracked
	pretrained param: encoder.layer2.0.conv3.weight -> current param: encoder.layer2.0.conv3.weight
	pretrained param: encoder.layer2.0.bn3.weight -> current param: encoder.layer2.0.bn3.weight
	pretrained param: encoder.layer2.0.bn3.bias -> current param: encoder.layer2.0.bn3.bias
	pretrained param: encoder.layer2.0.bn3.running_mean -> current param: encoder.layer2.0.bn3.running_mean
	pretrained param: encoder.layer2.0.bn3.running_var -> current param: encoder.layer2.0.bn3.running_var
	pretrained param: encoder.layer2.0.bn3.num_batches_tracked -> current param: encoder.layer2.0.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.downsample.0.weight -> current param: encoder.layer2.0.downsample.0.weight
	pretrained param: encoder.layer2.0.downsample.1.weight -> current param: encoder.layer2.0.downsample.1.weight
	pretrained param: encoder.layer2.0.downsample.1.bias -> current param: encoder.layer2.0.downsample.1.bias
	pretrained param: encoder.layer2.0.downsample.1.running_mean -> current param: encoder.layer2.0.downsample.1.running_mean
	pretrained param: encoder.layer2.0.downsample.1.running_var -> current param: encoder.layer2.0.downsample.1.running_var
	pretrained param: encoder.layer2.0.downsample.1.num_batches_tracked -> current param: encoder.layer2.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv1.weight -> current param: encoder.layer2.1.conv1.weight
	pretrained param: encoder.layer2.1.bn1.weight -> current param: encoder.layer2.1.bn1.weight
	pretrained param: encoder.layer2.1.bn1.bias -> current param: encoder.layer2.1.bn1.bias
	pretrained param: encoder.layer2.1.bn1.running_mean -> current param: encoder.layer2.1.bn1.running_mean
	pretrained param: encoder.layer2.1.bn1.running_var -> current param: encoder.layer2.1.bn1.running_var
	pretrained param: encoder.layer2.1.bn1.num_batches_tracked -> current param: encoder.layer2.1.bn1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv2.weight -> current param: encoder.layer2.1.conv2.weight
	pretrained param: encoder.layer2.1.bn2.weight -> current param: encoder.layer2.1.bn2.weight
	pretrained param: encoder.layer2.1.bn2.bias -> current param: encoder.layer2.1.bn2.bias
	pretrained param: encoder.layer2.1.bn2.running_mean -> current param: encoder.layer2.1.bn2.running_mean
	pretrained param: encoder.layer2.1.bn2.running_var -> current param: encoder.layer2.1.bn2.running_var
	pretrained param: encoder.layer2.1.bn2.num_batches_tracked -> current param: encoder.layer2.1.bn2.num_batches_tracked
	pretrained param: encoder.layer2.1.conv3.weight -> current param: encoder.layer2.1.conv3.weight
	pretrained param: encoder.layer2.1.bn3.weight -> current param: encoder.layer2.1.bn3.weight
	pretrained param: encoder.layer2.1.bn3.bias -> current param: encoder.layer2.1.bn3.bias
	pretrained param: encoder.layer2.1.bn3.running_mean -> current param: encoder.layer2.1.bn3.running_mean
	pretrained param: encoder.layer2.1.bn3.running_var -> current param: encoder.layer2.1.bn3.running_var
	pretrained param: encoder.layer2.1.bn3.num_batches_tracked -> current param: encoder.layer2.1.bn3.num_batches_tracked
	pretrained param: encoder.layer2.2.conv1.weight -> current param: encoder.layer2.2.conv1.weight
	pretrained param: encoder.layer2.2.bn1.weight -> current param: encoder.layer2.2.bn1.weight
	pretrained param: encoder.layer2.2.bn1.bias -> current param: encoder.layer2.2.bn1.bias
	pretrained param: encoder.layer2.2.bn1.running_mean -> current param: encoder.layer2.2.bn1.running_mean
	pretrained param: encoder.layer2.2.bn1.running_var -> current param: encoder.layer2.2.bn1.running_var
	pretrained param: encoder.layer2.2.bn1.num_batches_tracked -> current param: encoder.layer2.2.bn1.num_batches_tracked
	pretrained param: encoder.layer2.2.conv2.weight -> current param: encoder.layer2.2.conv2.weight
	pretrained param: encoder.layer2.2.bn2.weight -> current param: encoder.layer2.2.bn2.weight
	pretrained param: encoder.layer2.2.bn2.bias -> current param: encoder.layer2.2.bn2.bias
	pretrained param: encoder.layer2.2.bn2.running_mean -> current param: encoder.layer2.2.bn2.running_mean
	pretrained param: encoder.layer2.2.bn2.running_var -> current param: encoder.layer2.2.bn2.running_var
	pretrained param: encoder.layer2.2.bn2.num_batches_tracked -> current param: encoder.layer2.2.bn2.num_batches_tracked
	pretrained param: encoder.layer2.2.conv3.weight -> current param: encoder.layer2.2.conv3.weight
	pretrained param: encoder.layer2.2.bn3.weight -> current param: encoder.layer2.2.bn3.weight
	pretrained param: encoder.layer2.2.bn3.bias -> current param: encoder.layer2.2.bn3.bias
	pretrained param: encoder.layer2.2.bn3.running_mean -> current param: encoder.layer2.2.bn3.running_mean
	pretrained param: encoder.layer2.2.bn3.running_var -> current param: encoder.layer2.2.bn3.running_var
	pretrained param: encoder.layer2.2.bn3.num_batches_tracked -> current param: encoder.layer2.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.3.conv1.weight -> current param: encoder.layer2.3.conv1.weight
	pretrained param: encoder.layer2.3.bn1.weight -> current param: encoder.layer2.3.bn1.weight
	pretrained param: encoder.layer2.3.bn1.bias -> current param: encoder.layer2.3.bn1.bias
	pretrained param: encoder.layer2.3.bn1.running_mean -> current param: encoder.layer2.3.bn1.running_mean
	pretrained param: encoder.layer2.3.bn1.running_var -> current param: encoder.layer2.3.bn1.running_var
	pretrained param: encoder.layer2.3.bn1.num_batches_tracked -> current param: encoder.layer2.3.bn1.num_batches_tracked
	pretrained param: encoder.layer2.3.conv2.weight -> current param: encoder.layer2.3.conv2.weight
	pretrained param: encoder.layer2.3.bn2.weight -> current param: encoder.layer2.3.bn2.weight
	pretrained param: encoder.layer2.3.bn2.bias -> current param: encoder.layer2.3.bn2.bias
	pretrained param: encoder.layer2.3.bn2.running_mean -> current param: encoder.layer2.3.bn2.running_mean
	pretrained param: encoder.layer2.3.bn2.running_var -> current param: encoder.layer2.3.bn2.running_var
	pretrained param: encoder.layer2.3.bn2.num_batches_tracked -> current param: encoder.layer2.3.bn2.num_batches_tracked
	pretrained param: encoder.layer2.3.conv3.weight -> current param: encoder.layer2.3.conv3.weight
	pretrained param: encoder.layer2.3.bn3.weight -> current param: encoder.layer2.3.bn3.weight
	pretrained param: encoder.layer2.3.bn3.bias -> current param: encoder.layer2.3.bn3.bias
	pretrained param: encoder.layer2.3.bn3.running_mean -> current param: encoder.layer2.3.bn3.running_mean
	pretrained param: encoder.layer2.3.bn3.running_var -> current param: encoder.layer2.3.bn3.running_var
	pretrained param: encoder.layer2.3.bn3.num_batches_tracked -> current param: encoder.layer2.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.conv1.weight -> current param: encoder.layer3.0.conv1.weight
	pretrained param: encoder.layer3.0.bn1.weight -> current param: encoder.layer3.0.bn1.weight
	pretrained param: encoder.layer3.0.bn1.bias -> current param: encoder.layer3.0.bn1.bias
	pretrained param: encoder.layer3.0.bn1.running_mean -> current param: encoder.layer3.0.bn1.running_mean
	pretrained param: encoder.layer3.0.bn1.running_var -> current param: encoder.layer3.0.bn1.running_var
	pretrained param: encoder.layer3.0.bn1.num_batches_tracked -> current param: encoder.layer3.0.bn1.num_batches_tracked
	pretrained param: encoder.layer3.0.conv2.weight -> current param: encoder.layer3.0.conv2.weight
	pretrained param: encoder.layer3.0.bn2.weight -> current param: encoder.layer3.0.bn2.weight
	pretrained param: encoder.layer3.0.bn2.bias -> current param: encoder.layer3.0.bn2.bias
	pretrained param: encoder.layer3.0.bn2.running_mean -> current param: encoder.layer3.0.bn2.running_mean
	pretrained param: encoder.layer3.0.bn2.running_var -> current param: encoder.layer3.0.bn2.running_var
	pretrained param: encoder.layer3.0.bn2.num_batches_tracked -> current param: encoder.layer3.0.bn2.num_batches_tracked
	pretrained param: encoder.layer3.0.conv3.weight -> current param: encoder.layer3.0.conv3.weight
	pretrained param: encoder.layer3.0.bn3.weight -> current param: encoder.layer3.0.bn3.weight
	pretrained param: encoder.layer3.0.bn3.bias -> current param: encoder.layer3.0.bn3.bias
	pretrained param: encoder.layer3.0.bn3.running_mean -> current param: encoder.layer3.0.bn3.running_mean
	pretrained param: encoder.layer3.0.bn3.running_var -> current param: encoder.layer3.0.bn3.running_var
	pretrained param: encoder.layer3.0.bn3.num_batches_tracked -> current param: encoder.layer3.0.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.downsample.0.weight -> current param: encoder.layer3.0.downsample.0.weight
	pretrained param: encoder.layer3.0.downsample.1.weight -> current param: encoder.layer3.0.downsample.1.weight
	pretrained param: encoder.layer3.0.downsample.1.bias -> current param: encoder.layer3.0.downsample.1.bias
	pretrained param: encoder.layer3.0.downsample.1.running_mean -> current param: encoder.layer3.0.downsample.1.running_mean
	pretrained param: encoder.layer3.0.downsample.1.running_var -> current param: encoder.layer3.0.downsample.1.running_var
	pretrained param: encoder.layer3.0.downsample.1.num_batches_tracked -> current param: encoder.layer3.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv1.weight -> current param: encoder.layer3.1.conv1.weight
	pretrained param: encoder.layer3.1.bn1.weight -> current param: encoder.layer3.1.bn1.weight
	pretrained param: encoder.layer3.1.bn1.bias -> current param: encoder.layer3.1.bn1.bias
	pretrained param: encoder.layer3.1.bn1.running_mean -> current param: encoder.layer3.1.bn1.running_mean
	pretrained param: encoder.layer3.1.bn1.running_var -> current param: encoder.layer3.1.bn1.running_var
	pretrained param: encoder.layer3.1.bn1.num_batches_tracked -> current param: encoder.layer3.1.bn1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv2.weight -> current param: encoder.layer3.1.conv2.weight
	pretrained param: encoder.layer3.1.bn2.weight -> current param: encoder.layer3.1.bn2.weight
	pretrained param: encoder.layer3.1.bn2.bias -> current param: encoder.layer3.1.bn2.bias
	pretrained param: encoder.layer3.1.bn2.running_mean -> current param: encoder.layer3.1.bn2.running_mean
	pretrained param: encoder.layer3.1.bn2.running_var -> current param: encoder.layer3.1.bn2.running_var
	pretrained param: encoder.layer3.1.bn2.num_batches_tracked -> current param: encoder.layer3.1.bn2.num_batches_tracked
	pretrained param: encoder.layer3.1.conv3.weight -> current param: encoder.layer3.1.conv3.weight
	pretrained param: encoder.layer3.1.bn3.weight -> current param: encoder.layer3.1.bn3.weight
	pretrained param: encoder.layer3.1.bn3.bias -> current param: encoder.layer3.1.bn3.bias
	pretrained param: encoder.layer3.1.bn3.running_mean -> current param: encoder.layer3.1.bn3.running_mean
	pretrained param: encoder.layer3.1.bn3.running_var -> current param: encoder.layer3.1.bn3.running_var
	pretrained param: encoder.layer3.1.bn3.num_batches_tracked -> current param: encoder.layer3.1.bn3.num_batches_tracked
	pretrained param: encoder.layer3.2.conv1.weight -> current param: encoder.layer3.2.conv1.weight
	pretrained param: encoder.layer3.2.bn1.weight -> current param: encoder.layer3.2.bn1.weight
	pretrained param: encoder.layer3.2.bn1.bias -> current param: encoder.layer3.2.bn1.bias
	pretrained param: encoder.layer3.2.bn1.running_mean -> current param: encoder.layer3.2.bn1.running_mean
	pretrained param: encoder.layer3.2.bn1.running_var -> current param: encoder.layer3.2.bn1.running_var
	pretrained param: encoder.layer3.2.bn1.num_batches_tracked -> current param: encoder.layer3.2.bn1.num_batches_tracked
	pretrained param: encoder.layer3.2.conv2.weight -> current param: encoder.layer3.2.conv2.weight
	pretrained param: encoder.layer3.2.bn2.weight -> current param: encoder.layer3.2.bn2.weight
	pretrained param: encoder.layer3.2.bn2.bias -> current param: encoder.layer3.2.bn2.bias
	pretrained param: encoder.layer3.2.bn2.running_mean -> current param: encoder.layer3.2.bn2.running_mean
	pretrained param: encoder.layer3.2.bn2.running_var -> current param: encoder.layer3.2.bn2.running_var
	pretrained param: encoder.layer3.2.bn2.num_batches_tracked -> current param: encoder.layer3.2.bn2.num_batches_tracked
	pretrained param: encoder.layer3.2.conv3.weight -> current param: encoder.layer3.2.conv3.weight
	pretrained param: encoder.layer3.2.bn3.weight -> current param: encoder.layer3.2.bn3.weight
	pretrained param: encoder.layer3.2.bn3.bias -> current param: encoder.layer3.2.bn3.bias
	pretrained param: encoder.layer3.2.bn3.running_mean -> current param: encoder.layer3.2.bn3.running_mean
	pretrained param: encoder.layer3.2.bn3.running_var -> current param: encoder.layer3.2.bn3.running_var
	pretrained param: encoder.layer3.2.bn3.num_batches_tracked -> current param: encoder.layer3.2.bn3.num_batches_tracked
	pretrained param: encoder.layer3.3.conv1.weight -> current param: encoder.layer3.3.conv1.weight
	pretrained param: encoder.layer3.3.bn1.weight -> current param: encoder.layer3.3.bn1.weight
	pretrained param: encoder.layer3.3.bn1.bias -> current param: encoder.layer3.3.bn1.bias
	pretrained param: encoder.layer3.3.bn1.running_mean -> current param: encoder.layer3.3.bn1.running_mean
	pretrained param: encoder.layer3.3.bn1.running_var -> current param: encoder.layer3.3.bn1.running_var
	pretrained param: encoder.layer3.3.bn1.num_batches_tracked -> current param: encoder.layer3.3.bn1.num_batches_tracked
	pretrained param: encoder.layer3.3.conv2.weight -> current param: encoder.layer3.3.conv2.weight
	pretrained param: encoder.layer3.3.bn2.weight -> current param: encoder.layer3.3.bn2.weight
	pretrained param: encoder.layer3.3.bn2.bias -> current param: encoder.layer3.3.bn2.bias
	pretrained param: encoder.layer3.3.bn2.running_mean -> current param: encoder.layer3.3.bn2.running_mean
	pretrained param: encoder.layer3.3.bn2.running_var -> current param: encoder.layer3.3.bn2.running_var
	pretrained param: encoder.layer3.3.bn2.num_batches_tracked -> current param: encoder.layer3.3.bn2.num_batches_tracked
	pretrained param: encoder.layer3.3.conv3.weight -> current param: encoder.layer3.3.conv3.weight
	pretrained param: encoder.layer3.3.bn3.weight -> current param: encoder.layer3.3.bn3.weight
	pretrained param: encoder.layer3.3.bn3.bias -> current param: encoder.layer3.3.bn3.bias
	pretrained param: encoder.layer3.3.bn3.running_mean -> current param: encoder.layer3.3.bn3.running_mean
	pretrained param: encoder.layer3.3.bn3.running_var -> current param: encoder.layer3.3.bn3.running_var
	pretrained param: encoder.layer3.3.bn3.num_batches_tracked -> current param: encoder.layer3.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.4.conv1.weight -> current param: encoder.layer3.4.conv1.weight
	pretrained param: encoder.layer3.4.bn1.weight -> current param: encoder.layer3.4.bn1.weight
	pretrained param: encoder.layer3.4.bn1.bias -> current param: encoder.layer3.4.bn1.bias
	pretrained param: encoder.layer3.4.bn1.running_mean -> current param: encoder.layer3.4.bn1.running_mean
	pretrained param: encoder.layer3.4.bn1.running_var -> current param: encoder.layer3.4.bn1.running_var
	pretrained param: encoder.layer3.4.bn1.num_batches_tracked -> current param: encoder.layer3.4.bn1.num_batches_tracked
	pretrained param: encoder.layer3.4.conv2.weight -> current param: encoder.layer3.4.conv2.weight
	pretrained param: encoder.layer3.4.bn2.weight -> current param: encoder.layer3.4.bn2.weight
	pretrained param: encoder.layer3.4.bn2.bias -> current param: encoder.layer3.4.bn2.bias
	pretrained param: encoder.layer3.4.bn2.running_mean -> current param: encoder.layer3.4.bn2.running_mean
	pretrained param: encoder.layer3.4.bn2.running_var -> current param: encoder.layer3.4.bn2.running_var
	pretrained param: encoder.layer3.4.bn2.num_batches_tracked -> current param: encoder.layer3.4.bn2.num_batches_tracked
	pretrained param: encoder.layer3.4.conv3.weight -> current param: encoder.layer3.4.conv3.weight
	pretrained param: encoder.layer3.4.bn3.weight -> current param: encoder.layer3.4.bn3.weight
	pretrained param: encoder.layer3.4.bn3.bias -> current param: encoder.layer3.4.bn3.bias
	pretrained param: encoder.layer3.4.bn3.running_mean -> current param: encoder.layer3.4.bn3.running_mean
	pretrained param: encoder.layer3.4.bn3.running_var -> current param: encoder.layer3.4.bn3.running_var
	pretrained param: encoder.layer3.4.bn3.num_batches_tracked -> current param: encoder.layer3.4.bn3.num_batches_tracked
	pretrained param: encoder.layer3.5.conv1.weight -> current param: encoder.layer3.5.conv1.weight
	pretrained param: encoder.layer3.5.bn1.weight -> current param: encoder.layer3.5.bn1.weight
	pretrained param: encoder.layer3.5.bn1.bias -> current param: encoder.layer3.5.bn1.bias
	pretrained param: encoder.layer3.5.bn1.running_mean -> current param: encoder.layer3.5.bn1.running_mean
	pretrained param: encoder.layer3.5.bn1.running_var -> current param: encoder.layer3.5.bn1.running_var
	pretrained param: encoder.layer3.5.bn1.num_batches_tracked -> current param: encoder.layer3.5.bn1.num_batches_tracked
	pretrained param: encoder.layer3.5.conv2.weight -> current param: encoder.layer3.5.conv2.weight
	pretrained param: encoder.layer3.5.bn2.weight -> current param: encoder.layer3.5.bn2.weight
	pretrained param: encoder.layer3.5.bn2.bias -> current param: encoder.layer3.5.bn2.bias
	pretrained param: encoder.layer3.5.bn2.running_mean -> current param: encoder.layer3.5.bn2.running_mean
	pretrained param: encoder.layer3.5.bn2.running_var -> current param: encoder.layer3.5.bn2.running_var
	pretrained param: encoder.layer3.5.bn2.num_batches_tracked -> current param: encoder.layer3.5.bn2.num_batches_tracked
	pretrained param: encoder.layer3.5.conv3.weight -> current param: encoder.layer3.5.conv3.weight
	pretrained param: encoder.layer3.5.bn3.weight -> current param: encoder.layer3.5.bn3.weight
	pretrained param: encoder.layer3.5.bn3.bias -> current param: encoder.layer3.5.bn3.bias
	pretrained param: encoder.layer3.5.bn3.running_mean -> current param: encoder.layer3.5.bn3.running_mean
	pretrained param: encoder.layer3.5.bn3.running_var -> current param: encoder.layer3.5.bn3.running_var
	pretrained param: encoder.layer3.5.bn3.num_batches_tracked -> current param: encoder.layer3.5.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.conv1.weight -> current param: encoder.layer4.0.conv1.weight
	pretrained param: encoder.layer4.0.bn1.weight -> current param: encoder.layer4.0.bn1.weight
	pretrained param: encoder.layer4.0.bn1.bias -> current param: encoder.layer4.0.bn1.bias
	pretrained param: encoder.layer4.0.bn1.running_mean -> current param: encoder.layer4.0.bn1.running_mean
	pretrained param: encoder.layer4.0.bn1.running_var -> current param: encoder.layer4.0.bn1.running_var
	pretrained param: encoder.layer4.0.bn1.num_batches_tracked -> current param: encoder.layer4.0.bn1.num_batches_tracked
	pretrained param: encoder.layer4.0.conv2.weight -> current param: encoder.layer4.0.conv2.weight
	pretrained param: encoder.layer4.0.bn2.weight -> current param: encoder.layer4.0.bn2.weight
	pretrained param: encoder.layer4.0.bn2.bias -> current param: encoder.layer4.0.bn2.bias
	pretrained param: encoder.layer4.0.bn2.running_mean -> current param: encoder.layer4.0.bn2.running_mean
	pretrained param: encoder.layer4.0.bn2.running_var -> current param: encoder.layer4.0.bn2.running_var
	pretrained param: encoder.layer4.0.bn2.num_batches_tracked -> current param: encoder.layer4.0.bn2.num_batches_tracked
	pretrained param: encoder.layer4.0.conv3.weight -> current param: encoder.layer4.0.conv3.weight
	pretrained param: encoder.layer4.0.bn3.weight -> current param: encoder.layer4.0.bn3.weight
	pretrained param: encoder.layer4.0.bn3.bias -> current param: encoder.layer4.0.bn3.bias
	pretrained param: encoder.layer4.0.bn3.running_mean -> current param: encoder.layer4.0.bn3.running_mean
	pretrained param: encoder.layer4.0.bn3.running_var -> current param: encoder.layer4.0.bn3.running_var
	pretrained param: encoder.layer4.0.bn3.num_batches_tracked -> current param: encoder.layer4.0.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.downsample.0.weight -> current param: encoder.layer4.0.downsample.0.weight
	pretrained param: encoder.layer4.0.downsample.1.weight -> current param: encoder.layer4.0.downsample.1.weight
	pretrained param: encoder.layer4.0.downsample.1.bias -> current param: encoder.layer4.0.downsample.1.bias
	pretrained param: encoder.layer4.0.downsample.1.running_mean -> current param: encoder.layer4.0.downsample.1.running_mean
	pretrained param: encoder.layer4.0.downsample.1.running_var -> current param: encoder.layer4.0.downsample.1.running_var
	pretrained param: encoder.layer4.0.downsample.1.num_batches_tracked -> current param: encoder.layer4.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv1.weight -> current param: encoder.layer4.1.conv1.weight
	pretrained param: encoder.layer4.1.bn1.weight -> current param: encoder.layer4.1.bn1.weight
	pretrained param: encoder.layer4.1.bn1.bias -> current param: encoder.layer4.1.bn1.bias
	pretrained param: encoder.layer4.1.bn1.running_mean -> current param: encoder.layer4.1.bn1.running_mean
	pretrained param: encoder.layer4.1.bn1.running_var -> current param: encoder.layer4.1.bn1.running_var
	pretrained param: encoder.layer4.1.bn1.num_batches_tracked -> current param: encoder.layer4.1.bn1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv2.weight -> current param: encoder.layer4.1.conv2.weight
	pretrained param: encoder.layer4.1.bn2.weight -> current param: encoder.layer4.1.bn2.weight
	pretrained param: encoder.layer4.1.bn2.bias -> current param: encoder.layer4.1.bn2.bias
	pretrained param: encoder.layer4.1.bn2.running_mean -> current param: encoder.layer4.1.bn2.running_mean
	pretrained param: encoder.layer4.1.bn2.running_var -> current param: encoder.layer4.1.bn2.running_var
	pretrained param: encoder.layer4.1.bn2.num_batches_tracked -> current param: encoder.layer4.1.bn2.num_batches_tracked
	pretrained param: encoder.layer4.1.conv3.weight -> current param: encoder.layer4.1.conv3.weight
	pretrained param: encoder.layer4.1.bn3.weight -> current param: encoder.layer4.1.bn3.weight
	pretrained param: encoder.layer4.1.bn3.bias -> current param: encoder.layer4.1.bn3.bias
	pretrained param: encoder.layer4.1.bn3.running_mean -> current param: encoder.layer4.1.bn3.running_mean
	pretrained param: encoder.layer4.1.bn3.running_var -> current param: encoder.layer4.1.bn3.running_var
	pretrained param: encoder.layer4.1.bn3.num_batches_tracked -> current param: encoder.layer4.1.bn3.num_batches_tracked
	pretrained param: encoder.layer4.2.conv1.weight -> current param: encoder.layer4.2.conv1.weight
	pretrained param: encoder.layer4.2.bn1.weight -> current param: encoder.layer4.2.bn1.weight
	pretrained param: encoder.layer4.2.bn1.bias -> current param: encoder.layer4.2.bn1.bias
	pretrained param: encoder.layer4.2.bn1.running_mean -> current param: encoder.layer4.2.bn1.running_mean
	pretrained param: encoder.layer4.2.bn1.running_var -> current param: encoder.layer4.2.bn1.running_var
	pretrained param: encoder.layer4.2.bn1.num_batches_tracked -> current param: encoder.layer4.2.bn1.num_batches_tracked
	pretrained param: encoder.layer4.2.conv2.weight -> current param: encoder.layer4.2.conv2.weight
	pretrained param: encoder.layer4.2.bn2.weight -> current param: encoder.layer4.2.bn2.weight
	pretrained param: encoder.layer4.2.bn2.bias -> current param: encoder.layer4.2.bn2.bias
	pretrained param: encoder.layer4.2.bn2.running_mean -> current param: encoder.layer4.2.bn2.running_mean
	pretrained param: encoder.layer4.2.bn2.running_var -> current param: encoder.layer4.2.bn2.running_var
	pretrained param: encoder.layer4.2.bn2.num_batches_tracked -> current param: encoder.layer4.2.bn2.num_batches_tracked
	pretrained param: encoder.layer4.2.conv3.weight -> current param: encoder.layer4.2.conv3.weight
	pretrained param: encoder.layer4.2.bn3.weight -> current param: encoder.layer4.2.bn3.weight
	pretrained param: encoder.layer4.2.bn3.bias -> current param: encoder.layer4.2.bn3.bias
	pretrained param: encoder.layer4.2.bn3.running_mean -> current param: encoder.layer4.2.bn3.running_mean
	pretrained param: encoder.layer4.2.bn3.running_var -> current param: encoder.layer4.2.bn3.running_var
	pretrained param: encoder.layer4.2.bn3.num_batches_tracked -> current param: encoder.layer4.2.bn3.num_batches_tracked
	pretrained param: decoder.classify.weight -> current param: decoder.classify.weight
		Ignoring: decoder.classify.weight->decoder.classify.weight (size mismatch)
	pretrained param: decoder.classify.bias -> current param: decoder.classify.bias
90.11% of the model loaded from the pretrained
Total params: 179.77M
Dataset catalyst_h3 is not supported, use default mean stats instead
Training model on the catalyst_h3 dataset
Dataset catalyst_h3 is not supported, use default mean stats instead
[train] Epoch: 0/80 xent: 1.533 softIoU: 8.303 IoU: 0.000 
Execution time: 301.04504454508424

[valid] Epoch: 0/80 xent: 0.393 softIoU: 7.751 IoU: 0.000 
Execution time: 43.01579813705757

[train] Epoch: 1/80 xent: 0.513 softIoU: 8.018 IoU: 0.000 
Execution time: 299.4406646890566

[valid] Epoch: 1/80 xent: 0.393 softIoU: 7.751 IoU: 0.000 
Execution time: 44.95166209107265

[train] Epoch: 2/80 xent: 0.512 softIoU: 8.018 IoU: 0.000 
Execution time: 298.6384991691448

[valid] Epoch: 2/80 xent: 0.392 softIoU: 7.751 IoU: 0.000 
Execution time: 43.46264350274578

[train] Epoch: 3/80 xent: 0.511 softIoU: 8.018 IoU: 0.000 
Execution time: 298.43604499986395

[valid] Epoch: 3/80 xent: 0.393 softIoU: 7.752 IoU: 0.000 
Execution time: 41.37119784299284

[train] Epoch: 4/80 xent: 0.510 softIoU: 8.020 IoU: 0.000 
Execution time: 286.0144979720935

[valid] Epoch: 4/80 xent: 0.391 softIoU: 7.751 IoU: 0.000 
Execution time: 44.855540784075856

[train] Epoch: 5/80 xent: 0.511 softIoU: 8.018 IoU: 0.000 
Execution time: 300.9565063151531

[valid] Epoch: 5/80 xent: 0.391 softIoU: 7.752 IoU: 0.000 
Execution time: 40.34809213411063

[train] Epoch: 6/80 xent: 0.509 softIoU: 8.018 IoU: 0.000 
Execution time: 286.68448769580573

[valid] Epoch: 6/80 xent: 0.391 softIoU: 7.752 IoU: 0.000 
Execution time: 40.56282901810482

[train] Epoch: 7/80 xent: 0.507 softIoU: 8.018 IoU: 0.000 
Execution time: 284.0205818358809

[valid] Epoch: 7/80 xent: 0.389 softIoU: 7.750 IoU: 0.000 
Execution time: 44.20331808179617

[train] Epoch: 8/80 xent: 0.506 softIoU: 8.017 IoU: 0.000 
Execution time: 294.92614521598443

[valid] Epoch: 8/80 xent: 0.390 softIoU: 7.752 IoU: 0.000 
Execution time: 40.295660397969186

[train] Epoch: 9/80 xent: 0.506 softIoU: 8.019 IoU: 0.000 
Execution time: 285.4307859088294

[valid] Epoch: 9/80 xent: 0.388 softIoU: 7.751 IoU: 0.000 
Execution time: 40.10697956383228

[train] Epoch: 10/80 xent: 0.505 softIoU: 8.018 IoU: 0.000 
Execution time: 284.09265294577926

[valid] Epoch: 10/80 xent: 0.387 softIoU: 7.751 IoU: 0.000 
Execution time: 41.11621217802167

[train] Epoch: 11/80 xent: 0.504 softIoU: 8.018 IoU: 0.000 
Execution time: 286.184869161807

[valid] Epoch: 11/80 xent: 0.386 softIoU: 7.752 IoU: 0.000 
Execution time: 40.4179478501901

[train] Epoch: 12/80 xent: 0.502 softIoU: 8.018 IoU: 0.000 
Execution time: 306.00117607042193

[valid] Epoch: 12/80 xent: 0.385 softIoU: 7.752 IoU: 0.000 
Execution time: 40.59344258578494

[train] Epoch: 13/80 xent: 0.498 softIoU: 8.018 IoU: 0.000 
Execution time: 285.85827104607597

[valid] Epoch: 13/80 xent: 0.383 softIoU: 7.752 IoU: 0.000 
Execution time: 44.41885339608416

[train] Epoch: 14/80 xent: 0.495 softIoU: 8.017 IoU: 0.000 
Execution time: 288.3930991408415

[valid] Epoch: 14/80 xent: 0.379 softIoU: 7.750 IoU: 0.000 
Execution time: 40.2606785162352

[train] Epoch: 15/80 xent: 0.491 softIoU: 8.018 IoU: 0.000 
Execution time: 309.3701344821602

[valid] Epoch: 15/80 xent: 0.376 softIoU: 7.750 IoU: 0.000 
Execution time: 40.28451608680189

[train] Epoch: 16/80 xent: 0.485 softIoU: 8.017 IoU: 0.000 
Execution time: 297.5298211821355

[valid] Epoch: 16/80 xent: 0.373 softIoU: 7.752 IoU: 0.000 
Execution time: 39.74303785804659

[train] Epoch: 17/80 xent: 0.476 softIoU: 8.017 IoU: 0.000 
Execution time: 312.035612706095

[valid] Epoch: 17/80 xent: 0.364 softIoU: 7.750 IoU: 0.000 
Execution time: 44.335036950651556

[train] Epoch: 18/80 xent: 0.462 softIoU: 8.017 IoU: 0.000 
Execution time: 286.5666571613401

[valid] Epoch: 18/80 xent: 0.352 softIoU: 7.750 IoU: 0.000 
Execution time: 40.425372729077935

[train] Epoch: 19/80 xent: 0.439 softIoU: 8.015 IoU: 0.000 
Execution time: 286.0368604189716

[valid] Epoch: 19/80 xent: 0.329 softIoU: 7.749 IoU: 0.000 
Execution time: 40.92432263633236

[train] Epoch: 20/80 xent: 0.391 softIoU: 8.013 IoU: 0.000 
Execution time: 287.26831013709307

[valid] Epoch: 20/80 xent: 0.278 softIoU: 7.743 IoU: 0.000 
Execution time: 40.32969754608348

Saved model at /scratch/sr365/models/catalysth3_mb_5/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-20.pth.tar
[train] Epoch: 21/80 xent: 0.273 softIoU: 7.987 IoU: 0.023 
Execution time: 293.2548970831558

[valid] Epoch: 21/80 xent: 0.160 softIoU: 7.698 IoU: 0.101 
Execution time: 43.96519361296669

[train] Epoch: 22/80 xent: 0.104 softIoU: 7.854 IoU: 0.293 
Execution time: 306.86670667957515

[valid] Epoch: 22/80 xent: 0.061 softIoU: 7.561 IoU: 0.446 
Execution time: 40.91950731584802

[train] Epoch: 23/80 xent: 0.053 softIoU: 7.743 IoU: 0.301 
Execution time: 304.71598530979827

[valid] Epoch: 23/80 xent: 0.032 softIoU: 7.503 IoU: 0.338 
Execution time: 39.95893318904564

[train] Epoch: 24/80 xent: 0.040 softIoU: 7.708 IoU: 0.280 
Execution time: 315.79501674417406

[valid] Epoch: 24/80 xent: 0.024 softIoU: 7.488 IoU: 0.373 
Execution time: 40.154878470581025

[train] Epoch: 25/80 xent: 0.035 softIoU: 7.684 IoU: 0.318 
Execution time: 314.0720174051821

[valid] Epoch: 25/80 xent: 0.023 softIoU: 7.483 IoU: 0.433 
Execution time: 40.80732587678358

[train] Epoch: 26/80 xent: 0.032 softIoU: 7.676 IoU: 0.344 
Execution time: 313.6246975190006

[valid] Epoch: 26/80 xent: 0.020 softIoU: 7.480 IoU: 0.299 
Execution time: 40.246402494143695

[train] Epoch: 27/80 xent: 0.034 softIoU: 7.680 IoU: 0.325 
Execution time: 287.4165256829001

[valid] Epoch: 27/80 xent: 0.020 softIoU: 7.475 IoU: 0.359 
Execution time: 40.9193139676936

[train] Epoch: 28/80 xent: 0.029 softIoU: 7.669 IoU: 0.351 
Execution time: 284.6350778876804

[valid] Epoch: 28/80 xent: 0.026 softIoU: 7.474 IoU: 0.517 
Execution time: 44.563671043142676

[train] Epoch: 29/80 xent: 0.034 softIoU: 7.687 IoU: 0.323 
Execution time: 282.6224548909813

[valid] Epoch: 29/80 xent: 0.020 softIoU: 7.468 IoU: 0.487 
Execution time: 44.127123064827174

[train] Epoch: 30/80 xent: 0.030 softIoU: 7.670 IoU: 0.339 
Execution time: 312.19556692568585

[valid] Epoch: 30/80 xent: 0.016 softIoU: 7.473 IoU: 0.422 
Execution time: 44.05532290879637

[train] Epoch: 31/80 xent: 0.030 softIoU: 7.661 IoU: 0.375 
Execution time: 306.82682106876746

[valid] Epoch: 31/80 xent: 0.016 softIoU: 7.468 IoU: 0.428 
Execution time: 44.39879588689655

[train] Epoch: 32/80 xent: 0.026 softIoU: 7.664 IoU: 0.366 
Execution time: 283.05047256918624

[valid] Epoch: 32/80 xent: 0.020 softIoU: 7.466 IoU: 0.436 
Execution time: 41.05098650418222

[train] Epoch: 33/80 xent: 0.029 softIoU: 7.675 IoU: 0.367 
Execution time: 288.20992200402543

[valid] Epoch: 33/80 xent: 0.015 softIoU: 7.469 IoU: 0.421 
Execution time: 43.70889398083091

[train] Epoch: 34/80 xent: 0.024 softIoU: 7.668 IoU: 0.397 
Execution time: 284.00374493934214

[valid] Epoch: 34/80 xent: 0.016 softIoU: 7.465 IoU: 0.441 
Execution time: 44.06796535477042

[train] Epoch: 35/80 xent: 0.028 softIoU: 7.670 IoU: 0.378 
Execution time: 313.33202362200245

[valid] Epoch: 35/80 xent: 0.022 softIoU: 7.461 IoU: 0.568 
Execution time: 39.60563919506967

[train] Epoch: 36/80 xent: 0.025 softIoU: 7.667 IoU: 0.385 
Execution time: 283.14060625620186

[valid] Epoch: 36/80 xent: 0.014 softIoU: 7.462 IoU: 0.479 
Execution time: 39.944658807013184

[train] Epoch: 37/80 xent: 0.024 softIoU: 7.644 IoU: 0.393 
Execution time: 283.61533903423697

[valid] Epoch: 37/80 xent: 0.014 softIoU: 7.460 IoU: 0.513 
Execution time: 40.15243805618957

[train] Epoch: 38/80 xent: 0.026 softIoU: 7.658 IoU: 0.403 
Execution time: 289.94452566001564

[valid] Epoch: 38/80 xent: 0.016 softIoU: 7.459 IoU: 0.537 
Execution time: 39.74970005825162

[train] Epoch: 39/80 xent: 0.026 softIoU: 7.663 IoU: 0.417 
Execution time: 299.00888677686453

[valid] Epoch: 39/80 xent: 0.015 softIoU: 7.458 IoU: 0.524 
Execution time: 40.217778036836535

[train] Epoch: 40/80 xent: 0.023 softIoU: 7.655 IoU: 0.399 
Execution time: 310.4251099792309

[valid] Epoch: 40/80 xent: 0.015 softIoU: 7.456 IoU: 0.536 
Execution time: 40.06387023301795

Saved model at /scratch/sr365/models/catalysth3_mb_5/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-40.pth.tar
[train] Epoch: 41/80 xent: 0.025 softIoU: 7.654 IoU: 0.427 
Execution time: 297.39061453100294

[valid] Epoch: 41/80 xent: 0.013 softIoU: 7.460 IoU: 0.473 
Execution time: 44.44731358019635

[train] Epoch: 42/80 xent: 0.025 softIoU: 7.657 IoU: 0.395 
Execution time: 308.71067028073594

[valid] Epoch: 42/80 xent: 0.013 softIoU: 7.456 IoU: 0.504 
Execution time: 43.46493267407641

[train] Epoch: 43/80 xent: 0.022 softIoU: 7.656 IoU: 0.444 
Execution time: 289.9799544168636

[valid] Epoch: 43/80 xent: 0.013 softIoU: 7.453 IoU: 0.545 
Execution time: 42.405459381174296

[train] Epoch: 44/80 xent: 0.022 softIoU: 7.651 IoU: 0.446 
Execution time: 298.6478306632489

[valid] Epoch: 44/80 xent: 0.014 softIoU: 7.451 IoU: 0.566 
Execution time: 42.942675755824894

[train] Epoch: 45/80 xent: 0.023 softIoU: 7.660 IoU: 0.445 
Execution time: 300.1600169618614

[valid] Epoch: 45/80 xent: 0.018 softIoU: 7.461 IoU: 0.395 
Execution time: 40.27718486217782

[train] Epoch: 46/80 xent: 0.024 softIoU: 7.651 IoU: 0.430 
Execution time: 307.16243347432464

[valid] Epoch: 46/80 xent: 0.017 softIoU: 7.449 IoU: 0.600 
Execution time: 39.6070645400323

[train] Epoch: 47/80 xent: 0.024 softIoU: 7.650 IoU: 0.441 
Execution time: 294.71762165986

[valid] Epoch: 47/80 xent: 0.014 softIoU: 7.450 IoU: 0.564 
Execution time: 40.55259778723121

[train] Epoch: 48/80 xent: 0.023 softIoU: 7.653 IoU: 0.455 
Execution time: 305.51230570301414

[valid] Epoch: 48/80 xent: 0.017 softIoU: 7.456 IoU: 0.438 
Execution time: 40.004120954778045

[train] Epoch: 49/80 xent: 0.021 softIoU: 7.661 IoU: 0.446 
Execution time: 300.9112467067316

[valid] Epoch: 49/80 xent: 0.012 softIoU: 7.449 IoU: 0.549 
Execution time: 43.77028960408643

[train] Epoch: 50/80 xent: 0.019 softIoU: 7.638 IoU: 0.453 
Execution time: 296.4761544279754

[valid] Epoch: 50/80 xent: 0.013 softIoU: 7.446 IoU: 0.572 
Execution time: 39.99241203023121

[train] Epoch: 51/80 xent: 0.019 softIoU: 7.652 IoU: 0.458 
Execution time: 292.5101043661125

[valid] Epoch: 51/80 xent: 0.012 softIoU: 7.449 IoU: 0.525 
Execution time: 40.246742584276944

[train] Epoch: 52/80 xent: 0.022 softIoU: 7.652 IoU: 0.470 
Execution time: 296.27854816103354

[valid] Epoch: 52/80 xent: 0.013 softIoU: 7.449 IoU: 0.516 
Execution time: 43.52586154779419

[train] Epoch: 53/80 xent: 0.020 softIoU: 7.656 IoU: 0.469 
Execution time: 299.2825806289911

[valid] Epoch: 53/80 xent: 0.013 softIoU: 7.447 IoU: 0.547 
Execution time: 43.278438531793654

[train] Epoch: 54/80 xent: 0.020 softIoU: 7.643 IoU: 0.460 
Execution time: 296.6361770397052

[valid] Epoch: 54/80 xent: 0.014 softIoU: 7.448 IoU: 0.522 
Execution time: 40.39561437815428

[train] Epoch: 55/80 xent: 0.019 softIoU: 7.646 IoU: 0.477 
Execution time: 295.4130280902609

[valid] Epoch: 55/80 xent: 0.013 softIoU: 7.447 IoU: 0.545 
Execution time: 40.146281097084284

[train] Epoch: 56/80 xent: 0.020 softIoU: 7.652 IoU: 0.473 
Execution time: 293.452020698227

[valid] Epoch: 56/80 xent: 0.013 softIoU: 7.449 IoU: 0.517 
Execution time: 41.395354349166155

[train] Epoch: 57/80 xent: 0.019 softIoU: 7.641 IoU: 0.468 
Execution time: 287.4258386329748

[valid] Epoch: 57/80 xent: 0.012 softIoU: 7.448 IoU: 0.546 
Execution time: 39.947507882956415

[train] Epoch: 58/80 xent: 0.023 softIoU: 7.654 IoU: 0.469 
Execution time: 293.53283389331773

[valid] Epoch: 58/80 xent: 0.014 softIoU: 7.447 IoU: 0.531 
Execution time: 44.12948304321617

[train] Epoch: 59/80 xent: 0.021 softIoU: 7.649 IoU: 0.460 
Execution time: 285.24053323687986

[valid] Epoch: 59/80 xent: 0.013 softIoU: 7.449 IoU: 0.516 
Execution time: 43.838667273987085

[train] Epoch: 60/80 xent: 0.020 softIoU: 7.640 IoU: 0.462 
Execution time: 301.4872670536861

[valid] Epoch: 60/80 xent: 0.012 softIoU: 7.449 IoU: 0.510 
Execution time: 40.30780375469476

Saved model at /scratch/sr365/models/catalysth3_mb_5/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-60.pth.tar
[train] Epoch: 61/80 xent: 0.021 softIoU: 7.641 IoU: 0.458 
Execution time: 301.98738379916176

[valid] Epoch: 61/80 xent: 0.012 softIoU: 7.447 IoU: 0.524 
Execution time: 40.01573764625937

[train] Epoch: 62/80 xent: 0.020 softIoU: 7.640 IoU: 0.461 
Execution time: 301.335759408772

[valid] Epoch: 62/80 xent: 0.013 softIoU: 7.449 IoU: 0.508 
Execution time: 41.46160139283165

[train] Epoch: 63/80 xent: 0.020 softIoU: 7.649 IoU: 0.474 
Execution time: 300.9734637700021

[valid] Epoch: 63/80 xent: 0.014 softIoU: 7.446 IoU: 0.549 
Execution time: 40.113353522028774

[train] Epoch: 64/80 xent: 0.020 softIoU: 7.634 IoU: 0.457 
Execution time: 299.60084657697007

[valid] Epoch: 64/80 xent: 0.013 softIoU: 7.447 IoU: 0.538 
Execution time: 43.918657107278705

[train] Epoch: 65/80 xent: 0.021 softIoU: 7.644 IoU: 0.472 
Execution time: 301.5589890680276

[valid] Epoch: 65/80 xent: 0.013 softIoU: 7.447 IoU: 0.519 
Execution time: 42.826267645694315

[train] Epoch: 66/80 xent: 0.021 softIoU: 7.641 IoU: 0.475 
Execution time: 294.93571784812957

[valid] Epoch: 66/80 xent: 0.013 softIoU: 7.446 IoU: 0.549 
Execution time: 44.80352300591767

[train] Epoch: 67/80 xent: 0.019 softIoU: 7.651 IoU: 0.475 
Execution time: 295.06284760311246

[valid] Epoch: 67/80 xent: 0.013 softIoU: 7.446 IoU: 0.541 
Execution time: 42.081526283640414

[train] Epoch: 68/80 xent: 0.021 softIoU: 7.651 IoU: 0.469 
Execution time: 303.6625249572098

[valid] Epoch: 68/80 xent: 0.014 softIoU: 7.445 IoU: 0.572 
Execution time: 44.47207572311163

[train] Epoch: 69/80 xent: 0.020 softIoU: 7.649 IoU: 0.464 
Execution time: 288.5101771298796

[valid] Epoch: 69/80 xent: 0.012 softIoU: 7.449 IoU: 0.500 
Execution time: 44.71294102212414

[train] Epoch: 70/80 xent: 0.020 softIoU: 7.639 IoU: 0.472 
Execution time: 297.0939875775948

[valid] Epoch: 70/80 xent: 0.013 softIoU: 7.447 IoU: 0.526 
Execution time: 41.135132195893675

[train] Epoch: 71/80 xent: 0.021 softIoU: 7.650 IoU: 0.461 
Execution time: 297.29177048197016

[valid] Epoch: 71/80 xent: 0.012 softIoU: 7.447 IoU: 0.537 
Execution time: 40.01078691938892

[train] Epoch: 72/80 xent: 0.020 softIoU: 7.648 IoU: 0.476 
Execution time: 297.71518783969805

[valid] Epoch: 72/80 xent: 0.013 softIoU: 7.446 IoU: 0.549 
Execution time: 44.6466361428611

[train] Epoch: 73/80 xent: 0.020 softIoU: 7.654 IoU: 0.465 
Execution time: 301.2489900412038

[valid] Epoch: 73/80 xent: 0.013 softIoU: 7.447 IoU: 0.528 
Execution time: 41.645518923178315

[train] Epoch: 74/80 xent: 0.020 softIoU: 7.638 IoU: 0.463 
Execution time: 295.95423624664545

[valid] Epoch: 74/80 xent: 0.012 softIoU: 7.446 IoU: 0.520 
Execution time: 42.96177342906594

[train] Epoch: 75/80 xent: 0.018 softIoU: 7.631 IoU: 0.468 
Execution time: 293.1374985319562

[valid] Epoch: 75/80 xent: 0.013 softIoU: 7.445 IoU: 0.559 
Execution time: 44.016968657728285

[train] Epoch: 76/80 xent: 0.020 softIoU: 7.644 IoU: 0.482 
Execution time: 289.29149910993874

[valid] Epoch: 76/80 xent: 0.012 softIoU: 7.447 IoU: 0.538 
Execution time: 44.26050660898909

[train] Epoch: 77/80 xent: 0.019 softIoU: 7.632 IoU: 0.480 
Execution time: 294.0581470183097

[valid] Epoch: 77/80 xent: 0.011 softIoU: 7.449 IoU: 0.499 
Execution time: 44.224623112007976

[train] Epoch: 78/80 xent: 0.020 softIoU: 7.646 IoU: 0.478 
Execution time: 296.8372785812244

[valid] Epoch: 78/80 xent: 0.013 softIoU: 7.447 IoU: 0.547 
Execution time: 42.94816335523501

[train] Epoch: 79/80 xent: 0.023 softIoU: 7.641 IoU: 0.464 
Execution time: 298.5572446747683

[valid] Epoch: 79/80 xent: 0.011 softIoU: 7.449 IoU: 0.504 
Execution time: 41.79561126092449

Saved model at /scratch/sr365/models/catalysth3_mb_5/ecresnet50_dcdlinknet_dscatalyst_h3_lre1e-03_lrd1e-02_ep80_bs16_ds50_100_dr0p1_crxent7p0_softiou3p0/epoch-80.pth.tar
