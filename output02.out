Device being used: cuda:1
Finetuning model from /scratch/wh145/models/solarmapper_final/ct/epoch-80.pth.tar
Warning: The following parameters in the pretrained model does not exist in the current model
	 decoder.uc.0.up_conv.weight
	 decoder.uc.0.up_conv.bias
	 decoder.uc.0.conv_1.weight
	 decoder.uc.0.conv_1.bias
	 decoder.uc.0.conv_2.weight
	 decoder.uc.0.conv_2.bias
	 decoder.uc.0.bn_1.weight
	 decoder.uc.0.bn_1.bias
	 decoder.uc.0.bn_1.running_mean
	 decoder.uc.0.bn_1.running_var
	 decoder.uc.0.bn_1.num_batches_tracked
	 decoder.uc.0.bn_2.weight
	 decoder.uc.0.bn_2.bias
	 decoder.uc.0.bn_2.running_mean
	 decoder.uc.0.bn_2.running_var
	 decoder.uc.0.bn_2.num_batches_tracked
	 decoder.uc.0.act.weight
	 decoder.uc.1.up_conv.weight
	 decoder.uc.1.up_conv.bias
	 decoder.uc.1.conv_1.weight
	 decoder.uc.1.conv_1.bias
	 decoder.uc.1.conv_2.weight
	 decoder.uc.1.conv_2.bias
	 decoder.uc.1.bn_1.weight
	 decoder.uc.1.bn_1.bias
	 decoder.uc.1.bn_1.running_mean
	 decoder.uc.1.bn_1.running_var
	 decoder.uc.1.bn_1.num_batches_tracked
	 decoder.uc.1.bn_2.weight
	 decoder.uc.1.bn_2.bias
	 decoder.uc.1.bn_2.running_mean
	 decoder.uc.1.bn_2.running_var
	 decoder.uc.1.bn_2.num_batches_tracked
	 decoder.uc.1.act.weight
	 decoder.uc.2.up_conv.weight
	 decoder.uc.2.up_conv.bias
	 decoder.uc.2.conv_1.weight
	 decoder.uc.2.conv_1.bias
	 decoder.uc.2.conv_2.weight
	 decoder.uc.2.conv_2.bias
	 decoder.uc.2.bn_1.weight
	 decoder.uc.2.bn_1.bias
	 decoder.uc.2.bn_1.running_mean
	 decoder.uc.2.bn_1.running_var
	 decoder.uc.2.bn_1.num_batches_tracked
	 decoder.uc.2.bn_2.weight
	 decoder.uc.2.bn_2.bias
	 decoder.uc.2.bn_2.running_mean
	 decoder.uc.2.bn_2.running_var
	 decoder.uc.2.bn_2.num_batches_tracked
	 decoder.uc.2.act.weight
	 decoder.uc.3.up_conv.weight
	 decoder.uc.3.up_conv.bias
	 decoder.uc.3.conv_1.weight
	 decoder.uc.3.conv_1.bias
	 decoder.uc.3.conv_2.weight
	 decoder.uc.3.conv_2.bias
	 decoder.uc.3.bn_1.weight
	 decoder.uc.3.bn_1.bias
	 decoder.uc.3.bn_1.running_mean
	 decoder.uc.3.bn_1.running_var
	 decoder.uc.3.bn_1.num_batches_tracked
	 decoder.uc.3.bn_2.weight
	 decoder.uc.3.bn_2.bias
	 decoder.uc.3.bn_2.running_mean
	 decoder.uc.3.bn_2.running_var
	 decoder.uc.3.bn_2.num_batches_tracked
	 decoder.uc.3.act.weight
Warning: The following parameters in the current model does not exist in the pretrained model
	 decoder.center_dilation.dconv_1.weight
	 decoder.center_dilation.dconv_1.bias
	 decoder.center_dilation.dconv_2.weight
	 decoder.center_dilation.dconv_2.bias
	 decoder.center_dilation.dconv_3.weight
	 decoder.center_dilation.dconv_3.bias
	 decoder.center_dilation.dconv_4.weight
	 decoder.center_dilation.dconv_4.bias
	 decoder.upsample_1.conv1.weight
	 decoder.upsample_1.conv1.bias
	 decoder.upsample_1.tconv.weight
	 decoder.upsample_1.tconv.bias
	 decoder.upsample_1.conv2.weight
	 decoder.upsample_1.conv2.bias
	 decoder.upsample_2.conv1.weight
	 decoder.upsample_2.conv1.bias
	 decoder.upsample_2.tconv.weight
	 decoder.upsample_2.tconv.bias
	 decoder.upsample_2.conv2.weight
	 decoder.upsample_2.conv2.bias
	 decoder.upsample_3.conv1.weight
	 decoder.upsample_3.conv1.bias
	 decoder.upsample_3.tconv.weight
	 decoder.upsample_3.tconv.bias
	 decoder.upsample_3.conv2.weight
	 decoder.upsample_3.conv2.bias
	 decoder.upsample_4.conv1.weight
	 decoder.upsample_4.conv1.bias
	 decoder.upsample_4.tconv.weight
	 decoder.upsample_4.tconv.bias
	 decoder.upsample_4.conv2.weight
	 decoder.upsample_4.conv2.bias
	 decoder.tconv.weight
	 decoder.tconv.bias
Warning: The size of the following parameters in the current model does not match the ones in the pretrained model
	 decoder.classify.weight
Try loading with relaxed naming rule:
Prefix in pretrained model 
	pretrained param: encoder.conv1.weight -> current param: encoder.conv1.weight
	pretrained param: encoder.bn1.weight -> current param: encoder.bn1.weight
	pretrained param: encoder.bn1.bias -> current param: encoder.bn1.bias
	pretrained param: encoder.bn1.running_mean -> current param: encoder.bn1.running_mean
	pretrained param: encoder.bn1.running_var -> current param: encoder.bn1.running_var
	pretrained param: encoder.bn1.num_batches_tracked -> current param: encoder.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv1.weight -> current param: encoder.layer1.0.conv1.weight
	pretrained param: encoder.layer1.0.bn1.weight -> current param: encoder.layer1.0.bn1.weight
	pretrained param: encoder.layer1.0.bn1.bias -> current param: encoder.layer1.0.bn1.bias
	pretrained param: encoder.layer1.0.bn1.running_mean -> current param: encoder.layer1.0.bn1.running_mean
	pretrained param: encoder.layer1.0.bn1.running_var -> current param: encoder.layer1.0.bn1.running_var
	pretrained param: encoder.layer1.0.bn1.num_batches_tracked -> current param: encoder.layer1.0.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv2.weight -> current param: encoder.layer1.0.conv2.weight
	pretrained param: encoder.layer1.0.bn2.weight -> current param: encoder.layer1.0.bn2.weight
	pretrained param: encoder.layer1.0.bn2.bias -> current param: encoder.layer1.0.bn2.bias
	pretrained param: encoder.layer1.0.bn2.running_mean -> current param: encoder.layer1.0.bn2.running_mean
	pretrained param: encoder.layer1.0.bn2.running_var -> current param: encoder.layer1.0.bn2.running_var
	pretrained param: encoder.layer1.0.bn2.num_batches_tracked -> current param: encoder.layer1.0.bn2.num_batches_tracked
	pretrained param: encoder.layer1.0.conv3.weight -> current param: encoder.layer1.0.conv3.weight
	pretrained param: encoder.layer1.0.bn3.weight -> current param: encoder.layer1.0.bn3.weight
	pretrained param: encoder.layer1.0.bn3.bias -> current param: encoder.layer1.0.bn3.bias
	pretrained param: encoder.layer1.0.bn3.running_mean -> current param: encoder.layer1.0.bn3.running_mean
	pretrained param: encoder.layer1.0.bn3.running_var -> current param: encoder.layer1.0.bn3.running_var
	pretrained param: encoder.layer1.0.bn3.num_batches_tracked -> current param: encoder.layer1.0.bn3.num_batches_tracked
	pretrained param: encoder.layer1.0.downsample.0.weight -> current param: encoder.layer1.0.downsample.0.weight
	pretrained param: encoder.layer1.0.downsample.1.weight -> current param: encoder.layer1.0.downsample.1.weight
	pretrained param: encoder.layer1.0.downsample.1.bias -> current param: encoder.layer1.0.downsample.1.bias
	pretrained param: encoder.layer1.0.downsample.1.running_mean -> current param: encoder.layer1.0.downsample.1.running_mean
	pretrained param: encoder.layer1.0.downsample.1.running_var -> current param: encoder.layer1.0.downsample.1.running_var
	pretrained param: encoder.layer1.0.downsample.1.num_batches_tracked -> current param: encoder.layer1.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv1.weight -> current param: encoder.layer1.1.conv1.weight
	pretrained param: encoder.layer1.1.bn1.weight -> current param: encoder.layer1.1.bn1.weight
	pretrained param: encoder.layer1.1.bn1.bias -> current param: encoder.layer1.1.bn1.bias
	pretrained param: encoder.layer1.1.bn1.running_mean -> current param: encoder.layer1.1.bn1.running_mean
	pretrained param: encoder.layer1.1.bn1.running_var -> current param: encoder.layer1.1.bn1.running_var
	pretrained param: encoder.layer1.1.bn1.num_batches_tracked -> current param: encoder.layer1.1.bn1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv2.weight -> current param: encoder.layer1.1.conv2.weight
	pretrained param: encoder.layer1.1.bn2.weight -> current param: encoder.layer1.1.bn2.weight
	pretrained param: encoder.layer1.1.bn2.bias -> current param: encoder.layer1.1.bn2.bias
	pretrained param: encoder.layer1.1.bn2.running_mean -> current param: encoder.layer1.1.bn2.running_mean
	pretrained param: encoder.layer1.1.bn2.running_var -> current param: encoder.layer1.1.bn2.running_var
	pretrained param: encoder.layer1.1.bn2.num_batches_tracked -> current param: encoder.layer1.1.bn2.num_batches_tracked
	pretrained param: encoder.layer1.1.conv3.weight -> current param: encoder.layer1.1.conv3.weight
	pretrained param: encoder.layer1.1.bn3.weight -> current param: encoder.layer1.1.bn3.weight
	pretrained param: encoder.layer1.1.bn3.bias -> current param: encoder.layer1.1.bn3.bias
	pretrained param: encoder.layer1.1.bn3.running_mean -> current param: encoder.layer1.1.bn3.running_mean
	pretrained param: encoder.layer1.1.bn3.running_var -> current param: encoder.layer1.1.bn3.running_var
	pretrained param: encoder.layer1.1.bn3.num_batches_tracked -> current param: encoder.layer1.1.bn3.num_batches_tracked
	pretrained param: encoder.layer1.2.conv1.weight -> current param: encoder.layer1.2.conv1.weight
	pretrained param: encoder.layer1.2.bn1.weight -> current param: encoder.layer1.2.bn1.weight
	pretrained param: encoder.layer1.2.bn1.bias -> current param: encoder.layer1.2.bn1.bias
	pretrained param: encoder.layer1.2.bn1.running_mean -> current param: encoder.layer1.2.bn1.running_mean
	pretrained param: encoder.layer1.2.bn1.running_var -> current param: encoder.layer1.2.bn1.running_var
	pretrained param: encoder.layer1.2.bn1.num_batches_tracked -> current param: encoder.layer1.2.bn1.num_batches_tracked
	pretrained param: encoder.layer1.2.conv2.weight -> current param: encoder.layer1.2.conv2.weight
	pretrained param: encoder.layer1.2.bn2.weight -> current param: encoder.layer1.2.bn2.weight
	pretrained param: encoder.layer1.2.bn2.bias -> current param: encoder.layer1.2.bn2.bias
	pretrained param: encoder.layer1.2.bn2.running_mean -> current param: encoder.layer1.2.bn2.running_mean
	pretrained param: encoder.layer1.2.bn2.running_var -> current param: encoder.layer1.2.bn2.running_var
	pretrained param: encoder.layer1.2.bn2.num_batches_tracked -> current param: encoder.layer1.2.bn2.num_batches_tracked
	pretrained param: encoder.layer1.2.conv3.weight -> current param: encoder.layer1.2.conv3.weight
	pretrained param: encoder.layer1.2.bn3.weight -> current param: encoder.layer1.2.bn3.weight
	pretrained param: encoder.layer1.2.bn3.bias -> current param: encoder.layer1.2.bn3.bias
	pretrained param: encoder.layer1.2.bn3.running_mean -> current param: encoder.layer1.2.bn3.running_mean
	pretrained param: encoder.layer1.2.bn3.running_var -> current param: encoder.layer1.2.bn3.running_var
	pretrained param: encoder.layer1.2.bn3.num_batches_tracked -> current param: encoder.layer1.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.conv1.weight -> current param: encoder.layer2.0.conv1.weight
	pretrained param: encoder.layer2.0.bn1.weight -> current param: encoder.layer2.0.bn1.weight
	pretrained param: encoder.layer2.0.bn1.bias -> current param: encoder.layer2.0.bn1.bias
	pretrained param: encoder.layer2.0.bn1.running_mean -> current param: encoder.layer2.0.bn1.running_mean
	pretrained param: encoder.layer2.0.bn1.running_var -> current param: encoder.layer2.0.bn1.running_var
	pretrained param: encoder.layer2.0.bn1.num_batches_tracked -> current param: encoder.layer2.0.bn1.num_batches_tracked
	pretrained param: encoder.layer2.0.conv2.weight -> current param: encoder.layer2.0.conv2.weight
	pretrained param: encoder.layer2.0.bn2.weight -> current param: encoder.layer2.0.bn2.weight
	pretrained param: encoder.layer2.0.bn2.bias -> current param: encoder.layer2.0.bn2.bias
	pretrained param: encoder.layer2.0.bn2.running_mean -> current param: encoder.layer2.0.bn2.running_mean
	pretrained param: encoder.layer2.0.bn2.running_var -> current param: encoder.layer2.0.bn2.running_var
	pretrained param: encoder.layer2.0.bn2.num_batches_tracked -> current param: encoder.layer2.0.bn2.num_batches_tracked
	pretrained param: encoder.layer2.0.conv3.weight -> current param: encoder.layer2.0.conv3.weight
	pretrained param: encoder.layer2.0.bn3.weight -> current param: encoder.layer2.0.bn3.weight
	pretrained param: encoder.layer2.0.bn3.bias -> current param: encoder.layer2.0.bn3.bias
	pretrained param: encoder.layer2.0.bn3.running_mean -> current param: encoder.layer2.0.bn3.running_mean
	pretrained param: encoder.layer2.0.bn3.running_var -> current param: encoder.layer2.0.bn3.running_var
	pretrained param: encoder.layer2.0.bn3.num_batches_tracked -> current param: encoder.layer2.0.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.downsample.0.weight -> current param: encoder.layer2.0.downsample.0.weight
	pretrained param: encoder.layer2.0.downsample.1.weight -> current param: encoder.layer2.0.downsample.1.weight
	pretrained param: encoder.layer2.0.downsample.1.bias -> current param: encoder.layer2.0.downsample.1.bias
	pretrained param: encoder.layer2.0.downsample.1.running_mean -> current param: encoder.layer2.0.downsample.1.running_mean
	pretrained param: encoder.layer2.0.downsample.1.running_var -> current param: encoder.layer2.0.downsample.1.running_var
	pretrained param: encoder.layer2.0.downsample.1.num_batches_tracked -> current param: encoder.layer2.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv1.weight -> current param: encoder.layer2.1.conv1.weight
	pretrained param: encoder.layer2.1.bn1.weight -> current param: encoder.layer2.1.bn1.weight
	pretrained param: encoder.layer2.1.bn1.bias -> current param: encoder.layer2.1.bn1.bias
	pretrained param: encoder.layer2.1.bn1.running_mean -> current param: encoder.layer2.1.bn1.running_mean
	pretrained param: encoder.layer2.1.bn1.running_var -> current param: encoder.layer2.1.bn1.running_var
	pretrained param: encoder.layer2.1.bn1.num_batches_tracked -> current param: encoder.layer2.1.bn1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv2.weight -> current param: encoder.layer2.1.conv2.weight
	pretrained param: encoder.layer2.1.bn2.weight -> current param: encoder.layer2.1.bn2.weight
	pretrained param: encoder.layer2.1.bn2.bias -> current param: encoder.layer2.1.bn2.bias
	pretrained param: encoder.layer2.1.bn2.running_mean -> current param: encoder.layer2.1.bn2.running_mean
	pretrained param: encoder.layer2.1.bn2.running_var -> current param: encoder.layer2.1.bn2.running_var
	pretrained param: encoder.layer2.1.bn2.num_batches_tracked -> current param: encoder.layer2.1.bn2.num_batches_tracked
	pretrained param: encoder.layer2.1.conv3.weight -> current param: encoder.layer2.1.conv3.weight
	pretrained param: encoder.layer2.1.bn3.weight -> current param: encoder.layer2.1.bn3.weight
	pretrained param: encoder.layer2.1.bn3.bias -> current param: encoder.layer2.1.bn3.bias
	pretrained param: encoder.layer2.1.bn3.running_mean -> current param: encoder.layer2.1.bn3.running_mean
	pretrained param: encoder.layer2.1.bn3.running_var -> current param: encoder.layer2.1.bn3.running_var
	pretrained param: encoder.layer2.1.bn3.num_batches_tracked -> current param: encoder.layer2.1.bn3.num_batches_tracked
	pretrained param: encoder.layer2.2.conv1.weight -> current param: encoder.layer2.2.conv1.weight
	pretrained param: encoder.layer2.2.bn1.weight -> current param: encoder.layer2.2.bn1.weight
	pretrained param: encoder.layer2.2.bn1.bias -> current param: encoder.layer2.2.bn1.bias
	pretrained param: encoder.layer2.2.bn1.running_mean -> current param: encoder.layer2.2.bn1.running_mean
	pretrained param: encoder.layer2.2.bn1.running_var -> current param: encoder.layer2.2.bn1.running_var
	pretrained param: encoder.layer2.2.bn1.num_batches_tracked -> current param: encoder.layer2.2.bn1.num_batches_tracked
	pretrained param: encoder.layer2.2.conv2.weight -> current param: encoder.layer2.2.conv2.weight
	pretrained param: encoder.layer2.2.bn2.weight -> current param: encoder.layer2.2.bn2.weight
	pretrained param: encoder.layer2.2.bn2.bias -> current param: encoder.layer2.2.bn2.bias
	pretrained param: encoder.layer2.2.bn2.running_mean -> current param: encoder.layer2.2.bn2.running_mean
	pretrained param: encoder.layer2.2.bn2.running_var -> current param: encoder.layer2.2.bn2.running_var
	pretrained param: encoder.layer2.2.bn2.num_batches_tracked -> current param: encoder.layer2.2.bn2.num_batches_tracked
	pretrained param: encoder.layer2.2.conv3.weight -> current param: encoder.layer2.2.conv3.weight
	pretrained param: encoder.layer2.2.bn3.weight -> current param: encoder.layer2.2.bn3.weight
	pretrained param: encoder.layer2.2.bn3.bias -> current param: encoder.layer2.2.bn3.bias
	pretrained param: encoder.layer2.2.bn3.running_mean -> current param: encoder.layer2.2.bn3.running_mean
	pretrained param: encoder.layer2.2.bn3.running_var -> current param: encoder.layer2.2.bn3.running_var
	pretrained param: encoder.layer2.2.bn3.num_batches_tracked -> current param: encoder.layer2.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.3.conv1.weight -> current param: encoder.layer2.3.conv1.weight
	pretrained param: encoder.layer2.3.bn1.weight -> current param: encoder.layer2.3.bn1.weight
	pretrained param: encoder.layer2.3.bn1.bias -> current param: encoder.layer2.3.bn1.bias
	pretrained param: encoder.layer2.3.bn1.running_mean -> current param: encoder.layer2.3.bn1.running_mean
	pretrained param: encoder.layer2.3.bn1.running_var -> current param: encoder.layer2.3.bn1.running_var
	pretrained param: encoder.layer2.3.bn1.num_batches_tracked -> current param: encoder.layer2.3.bn1.num_batches_tracked
	pretrained param: encoder.layer2.3.conv2.weight -> current param: encoder.layer2.3.conv2.weight
	pretrained param: encoder.layer2.3.bn2.weight -> current param: encoder.layer2.3.bn2.weight
	pretrained param: encoder.layer2.3.bn2.bias -> current param: encoder.layer2.3.bn2.bias
	pretrained param: encoder.layer2.3.bn2.running_mean -> current param: encoder.layer2.3.bn2.running_mean
	pretrained param: encoder.layer2.3.bn2.running_var -> current param: encoder.layer2.3.bn2.running_var
	pretrained param: encoder.layer2.3.bn2.num_batches_tracked -> current param: encoder.layer2.3.bn2.num_batches_tracked
	pretrained param: encoder.layer2.3.conv3.weight -> current param: encoder.layer2.3.conv3.weight
	pretrained param: encoder.layer2.3.bn3.weight -> current param: encoder.layer2.3.bn3.weight
	pretrained param: encoder.layer2.3.bn3.bias -> current param: encoder.layer2.3.bn3.bias
	pretrained param: encoder.layer2.3.bn3.running_mean -> current param: encoder.layer2.3.bn3.running_mean
	pretrained param: encoder.layer2.3.bn3.running_var -> current param: encoder.layer2.3.bn3.running_var
	pretrained param: encoder.layer2.3.bn3.num_batches_tracked -> current param: encoder.layer2.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.conv1.weight -> current param: encoder.layer3.0.conv1.weight
	pretrained param: encoder.layer3.0.bn1.weight -> current param: encoder.layer3.0.bn1.weight
	pretrained param: encoder.layer3.0.bn1.bias -> current param: encoder.layer3.0.bn1.bias
	pretrained param: encoder.layer3.0.bn1.running_mean -> current param: encoder.layer3.0.bn1.running_mean
	pretrained param: encoder.layer3.0.bn1.running_var -> current param: encoder.layer3.0.bn1.running_var
	pretrained param: encoder.layer3.0.bn1.num_batches_tracked -> current param: encoder.layer3.0.bn1.num_batches_tracked
	pretrained param: encoder.layer3.0.conv2.weight -> current param: encoder.layer3.0.conv2.weight
	pretrained param: encoder.layer3.0.bn2.weight -> current param: encoder.layer3.0.bn2.weight
	pretrained param: encoder.layer3.0.bn2.bias -> current param: encoder.layer3.0.bn2.bias
	pretrained param: encoder.layer3.0.bn2.running_mean -> current param: encoder.layer3.0.bn2.running_mean
	pretrained param: encoder.layer3.0.bn2.running_var -> current param: encoder.layer3.0.bn2.running_var
	pretrained param: encoder.layer3.0.bn2.num_batches_tracked -> current param: encoder.layer3.0.bn2.num_batches_tracked
	pretrained param: encoder.layer3.0.conv3.weight -> current param: encoder.layer3.0.conv3.weight
	pretrained param: encoder.layer3.0.bn3.weight -> current param: encoder.layer3.0.bn3.weight
	pretrained param: encoder.layer3.0.bn3.bias -> current param: encoder.layer3.0.bn3.bias
	pretrained param: encoder.layer3.0.bn3.running_mean -> current param: encoder.layer3.0.bn3.running_mean
	pretrained param: encoder.layer3.0.bn3.running_var -> current param: encoder.layer3.0.bn3.running_var
	pretrained param: encoder.layer3.0.bn3.num_batches_tracked -> current param: encoder.layer3.0.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.downsample.0.weight -> current param: encoder.layer3.0.downsample.0.weight
	pretrained param: encoder.layer3.0.downsample.1.weight -> current param: encoder.layer3.0.downsample.1.weight
	pretrained param: encoder.layer3.0.downsample.1.bias -> current param: encoder.layer3.0.downsample.1.bias
	pretrained param: encoder.layer3.0.downsample.1.running_mean -> current param: encoder.layer3.0.downsample.1.running_mean
	pretrained param: encoder.layer3.0.downsample.1.running_var -> current param: encoder.layer3.0.downsample.1.running_var
	pretrained param: encoder.layer3.0.downsample.1.num_batches_tracked -> current param: encoder.layer3.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv1.weight -> current param: encoder.layer3.1.conv1.weight
	pretrained param: encoder.layer3.1.bn1.weight -> current param: encoder.layer3.1.bn1.weight
	pretrained param: encoder.layer3.1.bn1.bias -> current param: encoder.layer3.1.bn1.bias
	pretrained param: encoder.layer3.1.bn1.running_mean -> current param: encoder.layer3.1.bn1.running_mean
	pretrained param: encoder.layer3.1.bn1.running_var -> current param: encoder.layer3.1.bn1.running_var
	pretrained param: encoder.layer3.1.bn1.num_batches_tracked -> current param: encoder.layer3.1.bn1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv2.weight -> current param: encoder.layer3.1.conv2.weight
	pretrained param: encoder.layer3.1.bn2.weight -> current param: encoder.layer3.1.bn2.weight
	pretrained param: encoder.layer3.1.bn2.bias -> current param: encoder.layer3.1.bn2.bias
	pretrained param: encoder.layer3.1.bn2.running_mean -> current param: encoder.layer3.1.bn2.running_mean
	pretrained param: encoder.layer3.1.bn2.running_var -> current param: encoder.layer3.1.bn2.running_var
	pretrained param: encoder.layer3.1.bn2.num_batches_tracked -> current param: encoder.layer3.1.bn2.num_batches_tracked
	pretrained param: encoder.layer3.1.conv3.weight -> current param: encoder.layer3.1.conv3.weight
	pretrained param: encoder.layer3.1.bn3.weight -> current param: encoder.layer3.1.bn3.weight
	pretrained param: encoder.layer3.1.bn3.bias -> current param: encoder.layer3.1.bn3.bias
	pretrained param: encoder.layer3.1.bn3.running_mean -> current param: encoder.layer3.1.bn3.running_mean
	pretrained param: encoder.layer3.1.bn3.running_var -> current param: encoder.layer3.1.bn3.running_var
	pretrained param: encoder.layer3.1.bn3.num_batches_tracked -> current param: encoder.layer3.1.bn3.num_batches_tracked
	pretrained param: encoder.layer3.2.conv1.weight -> current param: encoder.layer3.2.conv1.weight
	pretrained param: encoder.layer3.2.bn1.weight -> current param: encoder.layer3.2.bn1.weight
	pretrained param: encoder.layer3.2.bn1.bias -> current param: encoder.layer3.2.bn1.bias
	pretrained param: encoder.layer3.2.bn1.running_mean -> current param: encoder.layer3.2.bn1.running_mean
	pretrained param: encoder.layer3.2.bn1.running_var -> current param: encoder.layer3.2.bn1.running_var
	pretrained param: encoder.layer3.2.bn1.num_batches_tracked -> current param: encoder.layer3.2.bn1.num_batches_tracked
	pretrained param: encoder.layer3.2.conv2.weight -> current param: encoder.layer3.2.conv2.weight
	pretrained param: encoder.layer3.2.bn2.weight -> current param: encoder.layer3.2.bn2.weight
	pretrained param: encoder.layer3.2.bn2.bias -> current param: encoder.layer3.2.bn2.bias
	pretrained param: encoder.layer3.2.bn2.running_mean -> current param: encoder.layer3.2.bn2.running_mean
	pretrained param: encoder.layer3.2.bn2.running_var -> current param: encoder.layer3.2.bn2.running_var
	pretrained param: encoder.layer3.2.bn2.num_batches_tracked -> current param: encoder.layer3.2.bn2.num_batches_tracked
	pretrained param: encoder.layer3.2.conv3.weight -> current param: encoder.layer3.2.conv3.weight
	pretrained param: encoder.layer3.2.bn3.weight -> current param: encoder.layer3.2.bn3.weight
	pretrained param: encoder.layer3.2.bn3.bias -> current param: encoder.layer3.2.bn3.bias
	pretrained param: encoder.layer3.2.bn3.running_mean -> current param: encoder.layer3.2.bn3.running_mean
	pretrained param: encoder.layer3.2.bn3.running_var -> current param: encoder.layer3.2.bn3.running_var
	pretrained param: encoder.layer3.2.bn3.num_batches_tracked -> current param: encoder.layer3.2.bn3.num_batches_tracked
	pretrained param: encoder.layer3.3.conv1.weight -> current param: encoder.layer3.3.conv1.weight
	pretrained param: encoder.layer3.3.bn1.weight -> current param: encoder.layer3.3.bn1.weight
	pretrained param: encoder.layer3.3.bn1.bias -> current param: encoder.layer3.3.bn1.bias
	pretrained param: encoder.layer3.3.bn1.running_mean -> current param: encoder.layer3.3.bn1.running_mean
	pretrained param: encoder.layer3.3.bn1.running_var -> current param: encoder.layer3.3.bn1.running_var
	pretrained param: encoder.layer3.3.bn1.num_batches_tracked -> current param: encoder.layer3.3.bn1.num_batches_tracked
	pretrained param: encoder.layer3.3.conv2.weight -> current param: encoder.layer3.3.conv2.weight
	pretrained param: encoder.layer3.3.bn2.weight -> current param: encoder.layer3.3.bn2.weight
	pretrained param: encoder.layer3.3.bn2.bias -> current param: encoder.layer3.3.bn2.bias
	pretrained param: encoder.layer3.3.bn2.running_mean -> current param: encoder.layer3.3.bn2.running_mean
	pretrained param: encoder.layer3.3.bn2.running_var -> current param: encoder.layer3.3.bn2.running_var
	pretrained param: encoder.layer3.3.bn2.num_batches_tracked -> current param: encoder.layer3.3.bn2.num_batches_tracked
	pretrained param: encoder.layer3.3.conv3.weight -> current param: encoder.layer3.3.conv3.weight
	pretrained param: encoder.layer3.3.bn3.weight -> current param: encoder.layer3.3.bn3.weight
	pretrained param: encoder.layer3.3.bn3.bias -> current param: encoder.layer3.3.bn3.bias
	pretrained param: encoder.layer3.3.bn3.running_mean -> current param: encoder.layer3.3.bn3.running_mean
	pretrained param: encoder.layer3.3.bn3.running_var -> current param: encoder.layer3.3.bn3.running_var
	pretrained param: encoder.layer3.3.bn3.num_batches_tracked -> current param: encoder.layer3.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.4.conv1.weight -> current param: encoder.layer3.4.conv1.weight
	pretrained param: encoder.layer3.4.bn1.weight -> current param: encoder.layer3.4.bn1.weight
	pretrained param: encoder.layer3.4.bn1.bias -> current param: encoder.layer3.4.bn1.bias
	pretrained param: encoder.layer3.4.bn1.running_mean -> current param: encoder.layer3.4.bn1.running_mean
	pretrained param: encoder.layer3.4.bn1.running_var -> current param: encoder.layer3.4.bn1.running_var
	pretrained param: encoder.layer3.4.bn1.num_batches_tracked -> current param: encoder.layer3.4.bn1.num_batches_tracked
	pretrained param: encoder.layer3.4.conv2.weight -> current param: encoder.layer3.4.conv2.weight
	pretrained param: encoder.layer3.4.bn2.weight -> current param: encoder.layer3.4.bn2.weight
	pretrained param: encoder.layer3.4.bn2.bias -> current param: encoder.layer3.4.bn2.bias
	pretrained param: encoder.layer3.4.bn2.running_mean -> current param: encoder.layer3.4.bn2.running_mean
	pretrained param: encoder.layer3.4.bn2.running_var -> current param: encoder.layer3.4.bn2.running_var
	pretrained param: encoder.layer3.4.bn2.num_batches_tracked -> current param: encoder.layer3.4.bn2.num_batches_tracked
	pretrained param: encoder.layer3.4.conv3.weight -> current param: encoder.layer3.4.conv3.weight
	pretrained param: encoder.layer3.4.bn3.weight -> current param: encoder.layer3.4.bn3.weight
	pretrained param: encoder.layer3.4.bn3.bias -> current param: encoder.layer3.4.bn3.bias
	pretrained param: encoder.layer3.4.bn3.running_mean -> current param: encoder.layer3.4.bn3.running_mean
	pretrained param: encoder.layer3.4.bn3.running_var -> current param: encoder.layer3.4.bn3.running_var
	pretrained param: encoder.layer3.4.bn3.num_batches_tracked -> current param: encoder.layer3.4.bn3.num_batches_tracked
	pretrained param: encoder.layer3.5.conv1.weight -> current param: encoder.layer3.5.conv1.weight
	pretrained param: encoder.layer3.5.bn1.weight -> current param: encoder.layer3.5.bn1.weight
	pretrained param: encoder.layer3.5.bn1.bias -> current param: encoder.layer3.5.bn1.bias
	pretrained param: encoder.layer3.5.bn1.running_mean -> current param: encoder.layer3.5.bn1.running_mean
	pretrained param: encoder.layer3.5.bn1.running_var -> current param: encoder.layer3.5.bn1.running_var
	pretrained param: encoder.layer3.5.bn1.num_batches_tracked -> current param: encoder.layer3.5.bn1.num_batches_tracked
	pretrained param: encoder.layer3.5.conv2.weight -> current param: encoder.layer3.5.conv2.weight
	pretrained param: encoder.layer3.5.bn2.weight -> current param: encoder.layer3.5.bn2.weight
	pretrained param: encoder.layer3.5.bn2.bias -> current param: encoder.layer3.5.bn2.bias
	pretrained param: encoder.layer3.5.bn2.running_mean -> current param: encoder.layer3.5.bn2.running_mean
	pretrained param: encoder.layer3.5.bn2.running_var -> current param: encoder.layer3.5.bn2.running_var
	pretrained param: encoder.layer3.5.bn2.num_batches_tracked -> current param: encoder.layer3.5.bn2.num_batches_tracked
	pretrained param: encoder.layer3.5.conv3.weight -> current param: encoder.layer3.5.conv3.weight
	pretrained param: encoder.layer3.5.bn3.weight -> current param: encoder.layer3.5.bn3.weight
	pretrained param: encoder.layer3.5.bn3.bias -> current param: encoder.layer3.5.bn3.bias
	pretrained param: encoder.layer3.5.bn3.running_mean -> current param: encoder.layer3.5.bn3.running_mean
	pretrained param: encoder.layer3.5.bn3.running_var -> current param: encoder.layer3.5.bn3.running_var
	pretrained param: encoder.layer3.5.bn3.num_batches_tracked -> current param: encoder.layer3.5.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.conv1.weight -> current param: encoder.layer4.0.conv1.weight
	pretrained param: encoder.layer4.0.bn1.weight -> current param: encoder.layer4.0.bn1.weight
	pretrained param: encoder.layer4.0.bn1.bias -> current param: encoder.layer4.0.bn1.bias
	pretrained param: encoder.layer4.0.bn1.running_mean -> current param: encoder.layer4.0.bn1.running_mean
	pretrained param: encoder.layer4.0.bn1.running_var -> current param: encoder.layer4.0.bn1.running_var
	pretrained param: encoder.layer4.0.bn1.num_batches_tracked -> current param: encoder.layer4.0.bn1.num_batches_tracked
	pretrained param: encoder.layer4.0.conv2.weight -> current param: encoder.layer4.0.conv2.weight
	pretrained param: encoder.layer4.0.bn2.weight -> current param: encoder.layer4.0.bn2.weight
	pretrained param: encoder.layer4.0.bn2.bias -> current param: encoder.layer4.0.bn2.bias
	pretrained param: encoder.layer4.0.bn2.running_mean -> current param: encoder.layer4.0.bn2.running_mean
	pretrained param: encoder.layer4.0.bn2.running_var -> current param: encoder.layer4.0.bn2.running_var
	pretrained param: encoder.layer4.0.bn2.num_batches_tracked -> current param: encoder.layer4.0.bn2.num_batches_tracked
	pretrained param: encoder.layer4.0.conv3.weight -> current param: encoder.layer4.0.conv3.weight
	pretrained param: encoder.layer4.0.bn3.weight -> current param: encoder.layer4.0.bn3.weight
	pretrained param: encoder.layer4.0.bn3.bias -> current param: encoder.layer4.0.bn3.bias
	pretrained param: encoder.layer4.0.bn3.running_mean -> current param: encoder.layer4.0.bn3.running_mean
	pretrained param: encoder.layer4.0.bn3.running_var -> current param: encoder.layer4.0.bn3.running_var
	pretrained param: encoder.layer4.0.bn3.num_batches_tracked -> current param: encoder.layer4.0.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.downsample.0.weight -> current param: encoder.layer4.0.downsample.0.weight
	pretrained param: encoder.layer4.0.downsample.1.weight -> current param: encoder.layer4.0.downsample.1.weight
	pretrained param: encoder.layer4.0.downsample.1.bias -> current param: encoder.layer4.0.downsample.1.bias
	pretrained param: encoder.layer4.0.downsample.1.running_mean -> current param: encoder.layer4.0.downsample.1.running_mean
	pretrained param: encoder.layer4.0.downsample.1.running_var -> current param: encoder.layer4.0.downsample.1.running_var
	pretrained param: encoder.layer4.0.downsample.1.num_batches_tracked -> current param: encoder.layer4.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv1.weight -> current param: encoder.layer4.1.conv1.weight
	pretrained param: encoder.layer4.1.bn1.weight -> current param: encoder.layer4.1.bn1.weight
	pretrained param: encoder.layer4.1.bn1.bias -> current param: encoder.layer4.1.bn1.bias
	pretrained param: encoder.layer4.1.bn1.running_mean -> current param: encoder.layer4.1.bn1.running_mean
	pretrained param: encoder.layer4.1.bn1.running_var -> current param: encoder.layer4.1.bn1.running_var
	pretrained param: encoder.layer4.1.bn1.num_batches_tracked -> current param: encoder.layer4.1.bn1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv2.weight -> current param: encoder.layer4.1.conv2.weight
	pretrained param: encoder.layer4.1.bn2.weight -> current param: encoder.layer4.1.bn2.weight
	pretrained param: encoder.layer4.1.bn2.bias -> current param: encoder.layer4.1.bn2.bias
	pretrained param: encoder.layer4.1.bn2.running_mean -> current param: encoder.layer4.1.bn2.running_mean
	pretrained param: encoder.layer4.1.bn2.running_var -> current param: encoder.layer4.1.bn2.running_var
	pretrained param: encoder.layer4.1.bn2.num_batches_tracked -> current param: encoder.layer4.1.bn2.num_batches_tracked
	pretrained param: encoder.layer4.1.conv3.weight -> current param: encoder.layer4.1.conv3.weight
	pretrained param: encoder.layer4.1.bn3.weight -> current param: encoder.layer4.1.bn3.weight
	pretrained param: encoder.layer4.1.bn3.bias -> current param: encoder.layer4.1.bn3.bias
	pretrained param: encoder.layer4.1.bn3.running_mean -> current param: encoder.layer4.1.bn3.running_mean
	pretrained param: encoder.layer4.1.bn3.running_var -> current param: encoder.layer4.1.bn3.running_var
	pretrained param: encoder.layer4.1.bn3.num_batches_tracked -> current param: encoder.layer4.1.bn3.num_batches_tracked
	pretrained param: encoder.layer4.2.conv1.weight -> current param: encoder.layer4.2.conv1.weight
	pretrained param: encoder.layer4.2.bn1.weight -> current param: encoder.layer4.2.bn1.weight
	pretrained param: encoder.layer4.2.bn1.bias -> current param: encoder.layer4.2.bn1.bias
	pretrained param: encoder.layer4.2.bn1.running_mean -> current param: encoder.layer4.2.bn1.running_mean
	pretrained param: encoder.layer4.2.bn1.running_var -> current param: encoder.layer4.2.bn1.running_var
	pretrained param: encoder.layer4.2.bn1.num_batches_tracked -> current param: encoder.layer4.2.bn1.num_batches_tracked
	pretrained param: encoder.layer4.2.conv2.weight -> current param: encoder.layer4.2.conv2.weight
	pretrained param: encoder.layer4.2.bn2.weight -> current param: encoder.layer4.2.bn2.weight
	pretrained param: encoder.layer4.2.bn2.bias -> current param: encoder.layer4.2.bn2.bias
	pretrained param: encoder.layer4.2.bn2.running_mean -> current param: encoder.layer4.2.bn2.running_mean
	pretrained param: encoder.layer4.2.bn2.running_var -> current param: encoder.layer4.2.bn2.running_var
	pretrained param: encoder.layer4.2.bn2.num_batches_tracked -> current param: encoder.layer4.2.bn2.num_batches_tracked
	pretrained param: encoder.layer4.2.conv3.weight -> current param: encoder.layer4.2.conv3.weight
	pretrained param: encoder.layer4.2.bn3.weight -> current param: encoder.layer4.2.bn3.weight
	pretrained param: encoder.layer4.2.bn3.bias -> current param: encoder.layer4.2.bn3.bias
	pretrained param: encoder.layer4.2.bn3.running_mean -> current param: encoder.layer4.2.bn3.running_mean
	pretrained param: encoder.layer4.2.bn3.running_var -> current param: encoder.layer4.2.bn3.running_var
	pretrained param: encoder.layer4.2.bn3.num_batches_tracked -> current param: encoder.layer4.2.bn3.num_batches_tracked
	pretrained param: decoder.classify.weight -> current param: decoder.classify.weight
		Ignoring: decoder.classify.weight->decoder.classify.weight (size mismatch)
	pretrained param: decoder.classify.bias -> current param: decoder.classify.bias
90.11% of the model loaded from the pretrained
Total params: 179.77M
Dataset catalyst_h2 is not supported, use default mean stats instead
Training model on the catalyst_h2 dataset
Dataset catalyst_h2 is not supported, use default mean stats instead
[train] Epoch: 0/80 xent: 1.349 softIoU: 8.283 IoU: 0.000 
Execution time: 286.97117538237944

[valid] Epoch: 0/80 xent: 0.378 softIoU: 7.888 IoU: 0.000 
Execution time: 66.71166589017957

[train] Epoch: 1/80 xent: 0.323 softIoU: 8.012 IoU: 0.000 
Execution time: 287.1118944073096

[valid] Epoch: 1/80 xent: 0.379 softIoU: 7.886 IoU: 0.000 
Execution time: 67.96397803490981

[train] Epoch: 2/80 xent: 0.323 softIoU: 8.011 IoU: 0.000 
Execution time: 284.86361213820055

[valid] Epoch: 2/80 xent: 0.379 softIoU: 7.885 IoU: 0.000 
Execution time: 67.51964066969231

[train] Epoch: 3/80 xent: 0.322 softIoU: 8.010 IoU: 0.000 
Execution time: 286.2490765368566

[valid] Epoch: 3/80 xent: 0.378 softIoU: 7.886 IoU: 0.000 
Execution time: 69.48709639208391

[train] Epoch: 4/80 xent: 0.322 softIoU: 8.010 IoU: 0.000 
Execution time: 288.8112986413762

[valid] Epoch: 4/80 xent: 0.378 softIoU: 7.886 IoU: 0.000 
Execution time: 67.09235144825652

[train] Epoch: 5/80 xent: 0.322 softIoU: 8.011 IoU: 0.000 
Execution time: 288.22820666525513

[valid] Epoch: 5/80 xent: 0.378 softIoU: 7.886 IoU: 0.000 
Execution time: 67.61241583805531

[train] Epoch: 6/80 xent: 0.321 softIoU: 8.010 IoU: 0.000 
Execution time: 288.27108460105956

[valid] Epoch: 6/80 xent: 0.377 softIoU: 7.885 IoU: 0.000 
Execution time: 67.47586473124102

[train] Epoch: 7/80 xent: 0.321 softIoU: 8.010 IoU: 0.000 
Execution time: 284.8380671408959

[valid] Epoch: 7/80 xent: 0.378 softIoU: 7.885 IoU: 0.000 
Execution time: 68.01063809497282

[train] Epoch: 8/80 xent: 0.320 softIoU: 8.011 IoU: 0.000 
Execution time: 287.212266638875

[valid] Epoch: 8/80 xent: 0.376 softIoU: 7.885 IoU: 0.000 
Execution time: 67.98825829895213

[train] Epoch: 9/80 xent: 0.320 softIoU: 8.010 IoU: 0.000 
Execution time: 285.6148809976876

[valid] Epoch: 9/80 xent: 0.376 softIoU: 7.885 IoU: 0.000 
Execution time: 67.09396826894954

[train] Epoch: 10/80 xent: 0.319 softIoU: 8.009 IoU: 0.000 
Execution time: 285.19781536981463

[valid] Epoch: 10/80 xent: 0.374 softIoU: 7.886 IoU: 0.000 
Execution time: 66.61305983783677

[train] Epoch: 11/80 xent: 0.318 softIoU: 8.011 IoU: 0.000 
Execution time: 288.4308110252023

[valid] Epoch: 11/80 xent: 0.373 softIoU: 7.886 IoU: 0.000 
Execution time: 67.50422165216878

[train] Epoch: 12/80 xent: 0.318 softIoU: 8.011 IoU: 0.000 
Execution time: 285.788869747892

[valid] Epoch: 12/80 xent: 0.372 softIoU: 7.886 IoU: 0.000 
Execution time: 68.7405243893154

[train] Epoch: 13/80 xent: 0.317 softIoU: 8.009 IoU: 0.000 
Execution time: 287.84763843612745

[valid] Epoch: 13/80 xent: 0.371 softIoU: 7.886 IoU: 0.000 
Execution time: 67.43388638971373

[train] Epoch: 14/80 xent: 0.316 softIoU: 8.011 IoU: 0.000 
Execution time: 287.2445806139149

[valid] Epoch: 14/80 xent: 0.371 softIoU: 7.885 IoU: 0.000 
Execution time: 68.82182824099436

[train] Epoch: 15/80 xent: 0.315 softIoU: 8.010 IoU: 0.000 
Execution time: 287.8971830382943

[valid] Epoch: 15/80 xent: 0.370 softIoU: 7.885 IoU: 0.000 
Execution time: 68.24056671187282

[train] Epoch: 16/80 xent: 0.314 softIoU: 8.010 IoU: 0.000 
Execution time: 285.49632768006995

[valid] Epoch: 16/80 xent: 0.367 softIoU: 7.885 IoU: 0.000 
Execution time: 68.15996919106692

[train] Epoch: 17/80 xent: 0.312 softIoU: 8.010 IoU: 0.000 
Execution time: 288.95723555609584

[valid] Epoch: 17/80 xent: 0.366 softIoU: 7.885 IoU: 0.000 
Execution time: 66.83308993512765

[train] Epoch: 18/80 xent: 0.311 softIoU: 8.010 IoU: 0.000 
Execution time: 289.0498027172871

[valid] Epoch: 18/80 xent: 0.364 softIoU: 7.885 IoU: 0.000 
Execution time: 67.3231868762523

[train] Epoch: 19/80 xent: 0.309 softIoU: 8.010 IoU: 0.000 
Execution time: 285.91135605284944

[valid] Epoch: 19/80 xent: 0.361 softIoU: 7.884 IoU: 0.000 
Execution time: 69.58889378234744

[train] Epoch: 20/80 xent: 0.307 softIoU: 8.009 IoU: 0.000 
Execution time: 288.539918188937

[valid] Epoch: 20/80 xent: 0.357 softIoU: 7.884 IoU: 0.000 
Execution time: 68.35502335987985

Saved model at /scratch/sr365/models/catalysth2_mb_2/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-20.pth.tar
[train] Epoch: 21/80 xent: 0.303 softIoU: 8.009 IoU: 0.000 
Execution time: 286.99443879909813

[valid] Epoch: 21/80 xent: 0.352 softIoU: 7.884 IoU: 0.000 
Execution time: 67.31991175096482

[train] Epoch: 22/80 xent: 0.299 softIoU: 8.008 IoU: 0.000 
Execution time: 286.6566850929521

[valid] Epoch: 22/80 xent: 0.347 softIoU: 7.883 IoU: 0.000 
Execution time: 67.71369687421247

[train] Epoch: 23/80 xent: 0.292 softIoU: 8.008 IoU: 0.000 
Execution time: 289.27225422579795

[valid] Epoch: 23/80 xent: 0.338 softIoU: 7.882 IoU: 0.000 
Execution time: 67.70458099385723

[train] Epoch: 24/80 xent: 0.283 softIoU: 8.007 IoU: 0.000 
Execution time: 286.069833335001

[valid] Epoch: 24/80 xent: 0.322 softIoU: 7.881 IoU: 0.000 
Execution time: 68.6945315930061

[train] Epoch: 25/80 xent: 0.267 softIoU: 8.004 IoU: 0.000 
Execution time: 286.95717735914513

[valid] Epoch: 25/80 xent: 0.297 softIoU: 7.877 IoU: 0.000 
Execution time: 68.1107431622222

[train] Epoch: 26/80 xent: 0.241 softIoU: 7.998 IoU: 0.000 
Execution time: 285.4887636201456

[valid] Epoch: 26/80 xent: 0.249 softIoU: 7.862 IoU: 0.000 
Execution time: 67.17839248804376

[train] Epoch: 27/80 xent: 0.173 softIoU: 7.927 IoU: 0.055 
Execution time: 284.97908463934436

[valid] Epoch: 27/80 xent: 0.117 softIoU: 7.649 IoU: 0.312 
Execution time: 68.09859765786678

[train] Epoch: 28/80 xent: 0.090 softIoU: 7.685 IoU: 0.393 
Execution time: 288.5818651537411

[valid] Epoch: 28/80 xent: 0.058 softIoU: 7.432 IoU: 0.560 
Execution time: 67.69156429963186

[train] Epoch: 29/80 xent: 0.066 softIoU: 7.557 IoU: 0.383 
Execution time: 287.07331253401935

[valid] Epoch: 29/80 xent: 0.050 softIoU: 7.373 IoU: 0.592 
Execution time: 66.45111464103684

[train] Epoch: 30/80 xent: 0.057 softIoU: 7.481 IoU: 0.419 
Execution time: 289.5732117872685

[valid] Epoch: 30/80 xent: 0.041 softIoU: 7.333 IoU: 0.605 
Execution time: 67.71521825995296

[train] Epoch: 31/80 xent: 0.058 softIoU: 7.483 IoU: 0.409 
Execution time: 287.07915349910036

[valid] Epoch: 31/80 xent: 0.041 softIoU: 7.322 IoU: 0.604 
Execution time: 70.86364195076749

[train] Epoch: 32/80 xent: 0.052 softIoU: 7.422 IoU: 0.446 
Execution time: 286.34589218208566

[valid] Epoch: 32/80 xent: 0.045 softIoU: 7.344 IoU: 0.588 
Execution time: 67.65483536105603

[train] Epoch: 33/80 xent: 0.059 softIoU: 7.462 IoU: 0.396 
Execution time: 289.27385971229523

[valid] Epoch: 33/80 xent: 0.039 softIoU: 7.300 IoU: 0.613 
Execution time: 67.02966161305085

[train] Epoch: 34/80 xent: 0.054 softIoU: 7.423 IoU: 0.413 
Execution time: 287.09489946905524

[valid] Epoch: 34/80 xent: 0.042 softIoU: 7.321 IoU: 0.610 
Execution time: 67.59487211983651

[train] Epoch: 35/80 xent: 0.055 softIoU: 7.443 IoU: 0.421 
Execution time: 287.8833783096634

[valid] Epoch: 35/80 xent: 0.037 softIoU: 7.297 IoU: 0.602 
Execution time: 66.9259685240686

[train] Epoch: 36/80 xent: 0.050 softIoU: 7.423 IoU: 0.484 
Execution time: 285.019713671878

[valid] Epoch: 36/80 xent: 0.046 softIoU: 7.332 IoU: 0.614 
Execution time: 66.94649654394016

[train] Epoch: 37/80 xent: 0.047 softIoU: 7.409 IoU: 0.474 
Execution time: 287.132686171215

[valid] Epoch: 37/80 xent: 0.036 softIoU: 7.301 IoU: 0.613 
Execution time: 66.98839692911133

[train] Epoch: 38/80 xent: 0.047 softIoU: 7.408 IoU: 0.478 
Execution time: 297.1891473727301

[valid] Epoch: 38/80 xent: 0.038 softIoU: 7.308 IoU: 0.631 
Execution time: 88.30497042415664

[train] Epoch: 39/80 xent: 0.048 softIoU: 7.412 IoU: 0.457 
Execution time: 293.2448622910306

[valid] Epoch: 39/80 xent: 0.035 softIoU: 7.282 IoU: 0.626 
Execution time: 67.12707789102569

[train] Epoch: 40/80 xent: 0.043 softIoU: 7.394 IoU: 0.489 
Execution time: 289.1905907439068

[valid] Epoch: 40/80 xent: 0.034 softIoU: 7.291 IoU: 0.636 
Execution time: 67.75656434614211

Saved model at /scratch/sr365/models/catalysth2_mb_2/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-40.pth.tar
[train] Epoch: 41/80 xent: 0.046 softIoU: 7.427 IoU: 0.479 
Execution time: 286.39608388906345

[valid] Epoch: 41/80 xent: 0.033 softIoU: 7.286 IoU: 0.643 
Execution time: 66.89949697908014

[train] Epoch: 42/80 xent: 0.043 softIoU: 7.386 IoU: 0.511 
Execution time: 286.3964489819482

[valid] Epoch: 42/80 xent: 0.033 softIoU: 7.284 IoU: 0.643 
Execution time: 66.35434807697311

[train] Epoch: 43/80 xent: 0.042 softIoU: 7.378 IoU: 0.515 
Execution time: 285.1897183540277

[valid] Epoch: 43/80 xent: 0.034 softIoU: 7.291 IoU: 0.641 
Execution time: 67.52301965095103

[train] Epoch: 44/80 xent: 0.041 softIoU: 7.399 IoU: 0.530 
Execution time: 285.9888161672279

[valid] Epoch: 44/80 xent: 0.032 softIoU: 7.270 IoU: 0.635 
Execution time: 67.38435146491975

[train] Epoch: 45/80 xent: 0.042 softIoU: 7.427 IoU: 0.511 
Execution time: 288.0401984481141

[valid] Epoch: 45/80 xent: 0.032 softIoU: 7.280 IoU: 0.645 
Execution time: 66.64645117195323

[train] Epoch: 46/80 xent: 0.043 softIoU: 7.373 IoU: 0.524 
Execution time: 287.987483299803

[valid] Epoch: 46/80 xent: 0.031 softIoU: 7.279 IoU: 0.646 
Execution time: 66.74295233003795

[train] Epoch: 47/80 xent: 0.042 softIoU: 7.409 IoU: 0.502 
Execution time: 285.10593130113557

[valid] Epoch: 47/80 xent: 0.032 softIoU: 7.280 IoU: 0.648 
Execution time: 67.68796578096226

[train] Epoch: 48/80 xent: 0.045 softIoU: 7.397 IoU: 0.476 
Execution time: 284.80810647131875

[valid] Epoch: 48/80 xent: 0.030 softIoU: 7.265 IoU: 0.639 
Execution time: 66.66531822830439

[train] Epoch: 49/80 xent: 0.042 softIoU: 7.380 IoU: 0.527 
Execution time: 288.9221728630364

[valid] Epoch: 49/80 xent: 0.030 softIoU: 7.267 IoU: 0.640 
Execution time: 67.35259844362736

[train] Epoch: 50/80 xent: 0.040 softIoU: 7.419 IoU: 0.512 
Execution time: 286.24467242509127

[valid] Epoch: 50/80 xent: 0.030 softIoU: 7.269 IoU: 0.649 
Execution time: 69.10401013912633

[train] Epoch: 51/80 xent: 0.043 softIoU: 7.377 IoU: 0.535 
Execution time: 284.01987910224125

[valid] Epoch: 51/80 xent: 0.030 softIoU: 7.274 IoU: 0.648 
Execution time: 66.27112158108503

[train] Epoch: 52/80 xent: 0.039 softIoU: 7.385 IoU: 0.540 
Execution time: 286.77185309072956

[valid] Epoch: 52/80 xent: 0.033 softIoU: 7.289 IoU: 0.646 
Execution time: 66.98597485991195

[train] Epoch: 53/80 xent: 0.040 softIoU: 7.381 IoU: 0.538 
Execution time: 286.73244347283617

[valid] Epoch: 53/80 xent: 0.034 softIoU: 7.295 IoU: 0.643 
Execution time: 69.14995166519657

[train] Epoch: 54/80 xent: 0.041 softIoU: 7.367 IoU: 0.517 
Execution time: 286.7668775487691

[valid] Epoch: 54/80 xent: 0.030 softIoU: 7.272 IoU: 0.647 
Execution time: 67.82017902797088

[train] Epoch: 55/80 xent: 0.039 softIoU: 7.367 IoU: 0.535 
Execution time: 287.53460348024964

[valid] Epoch: 55/80 xent: 0.032 softIoU: 7.286 IoU: 0.642 
Execution time: 66.59370403829962

[train] Epoch: 56/80 xent: 0.039 softIoU: 7.375 IoU: 0.508 
Execution time: 289.2847643303685

[valid] Epoch: 56/80 xent: 0.030 softIoU: 7.271 IoU: 0.646 
Execution time: 66.98616286180913

[train] Epoch: 57/80 xent: 0.039 softIoU: 7.387 IoU: 0.545 
Execution time: 285.8591990270652

[valid] Epoch: 57/80 xent: 0.029 softIoU: 7.270 IoU: 0.650 
Execution time: 66.74206913309172

[train] Epoch: 58/80 xent: 0.041 softIoU: 7.401 IoU: 0.535 
Execution time: 286.6822663741186

[valid] Epoch: 58/80 xent: 0.030 softIoU: 7.277 IoU: 0.653 
Execution time: 65.91324867587537

[train] Epoch: 59/80 xent: 0.040 softIoU: 7.387 IoU: 0.528 
Execution time: 286.3166797501035

[valid] Epoch: 59/80 xent: 0.031 softIoU: 7.282 IoU: 0.658 
Execution time: 67.83207732904702

[train] Epoch: 60/80 xent: 0.037 softIoU: 7.377 IoU: 0.548 
Execution time: 288.1805981518701

[valid] Epoch: 60/80 xent: 0.028 softIoU: 7.266 IoU: 0.650 
Execution time: 66.98426069691777

Saved model at /scratch/sr365/models/catalysth2_mb_2/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-60.pth.tar
[train] Epoch: 61/80 xent: 0.040 softIoU: 7.384 IoU: 0.507 
Execution time: 291.06156557798386

[valid] Epoch: 61/80 xent: 0.031 softIoU: 7.284 IoU: 0.654 
Execution time: 68.01007528603077

[train] Epoch: 62/80 xent: 0.037 softIoU: 7.388 IoU: 0.531 
Execution time: 288.57521677203476

[valid] Epoch: 62/80 xent: 0.029 softIoU: 7.269 IoU: 0.651 
Execution time: 66.80957015324384

[train] Epoch: 63/80 xent: 0.042 softIoU: 7.397 IoU: 0.502 
Execution time: 286.15372382616624

[valid] Epoch: 63/80 xent: 0.030 softIoU: 7.275 IoU: 0.656 
Execution time: 66.70108996378258

[train] Epoch: 64/80 xent: 0.041 softIoU: 7.395 IoU: 0.522 
Execution time: 285.5077966256067

[valid] Epoch: 64/80 xent: 0.030 softIoU: 7.275 IoU: 0.655 
Execution time: 67.1601873007603

[train] Epoch: 65/80 xent: 0.038 softIoU: 7.379 IoU: 0.520 
Execution time: 285.53792589111254

[valid] Epoch: 65/80 xent: 0.029 softIoU: 7.267 IoU: 0.646 
Execution time: 67.1618447941728

[train] Epoch: 66/80 xent: 0.039 softIoU: 7.404 IoU: 0.524 
Execution time: 285.6673023602925

[valid] Epoch: 66/80 xent: 0.030 softIoU: 7.271 IoU: 0.654 
Execution time: 67.45446242718026

[train] Epoch: 67/80 xent: 0.037 softIoU: 7.376 IoU: 0.538 
Execution time: 289.3075762060471

[valid] Epoch: 67/80 xent: 0.030 softIoU: 7.274 IoU: 0.653 
Execution time: 66.90135783236474

[train] Epoch: 68/80 xent: 0.038 softIoU: 7.379 IoU: 0.540 
Execution time: 284.4090311191976

[valid] Epoch: 68/80 xent: 0.029 softIoU: 7.271 IoU: 0.656 
Execution time: 68.38825750118122

[train] Epoch: 69/80 xent: 0.038 softIoU: 7.401 IoU: 0.547 
Execution time: 289.7572170640342

[valid] Epoch: 69/80 xent: 0.030 softIoU: 7.267 IoU: 0.645 
Execution time: 67.56223451672122

[train] Epoch: 70/80 xent: 0.042 softIoU: 7.387 IoU: 0.527 
Execution time: 286.0584858460352

[valid] Epoch: 70/80 xent: 0.030 softIoU: 7.272 IoU: 0.656 
Execution time: 66.59244325105101

[train] Epoch: 71/80 xent: 0.041 softIoU: 7.376 IoU: 0.518 
Execution time: 285.0866459538229

[valid] Epoch: 71/80 xent: 0.029 softIoU: 7.263 IoU: 0.637 
Execution time: 66.62998292827979

[train] Epoch: 72/80 xent: 0.039 softIoU: 7.394 IoU: 0.539 
Execution time: 287.17772783199325

[valid] Epoch: 72/80 xent: 0.029 softIoU: 7.271 IoU: 0.655 
Execution time: 66.79778692591935

[train] Epoch: 73/80 xent: 0.041 softIoU: 7.385 IoU: 0.520 
Execution time: 283.9253890896216

[valid] Epoch: 73/80 xent: 0.029 softIoU: 7.273 IoU: 0.654 
Execution time: 67.16646272037178

[train] Epoch: 74/80 xent: 0.039 softIoU: 7.382 IoU: 0.548 
Execution time: 285.45746125932783

[valid] Epoch: 74/80 xent: 0.029 softIoU: 7.273 IoU: 0.656 
Execution time: 68.06996989203617

[train] Epoch: 75/80 xent: 0.039 softIoU: 7.366 IoU: 0.525 
Execution time: 285.6004173019901

[valid] Epoch: 75/80 xent: 0.030 softIoU: 7.280 IoU: 0.657 
Execution time: 66.24423411814496

[train] Epoch: 76/80 xent: 0.040 softIoU: 7.380 IoU: 0.524 
Execution time: 285.0640243757516

[valid] Epoch: 76/80 xent: 0.029 softIoU: 7.269 IoU: 0.653 
Execution time: 66.99912441568449

[train] Epoch: 77/80 xent: 0.038 softIoU: 7.374 IoU: 0.539 
Execution time: 285.39741375716403

[valid] Epoch: 77/80 xent: 0.030 softIoU: 7.273 IoU: 0.656 
Execution time: 67.03139564674348

[train] Epoch: 78/80 xent: 0.040 softIoU: 7.374 IoU: 0.542 
Execution time: 284.5901239090599

[valid] Epoch: 78/80 xent: 0.032 softIoU: 7.286 IoU: 0.654 
Execution time: 66.56668274803087

[train] Epoch: 79/80 xent: 0.040 softIoU: 7.389 IoU: 0.534 
Execution time: 286.8878838759847

[valid] Epoch: 79/80 xent: 0.032 softIoU: 7.284 IoU: 0.655 
Execution time: 68.633530956693

Saved model at /scratch/sr365/models/catalysth2_mb_2/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-80.pth.tar
Device being used: cuda:1
Finetuning model from /scratch/wh145/models/solarmapper_final/ct/epoch-80.pth.tar
Warning: The following parameters in the pretrained model does not exist in the current model
	 decoder.uc.0.up_conv.weight
	 decoder.uc.0.up_conv.bias
	 decoder.uc.0.conv_1.weight
	 decoder.uc.0.conv_1.bias
	 decoder.uc.0.conv_2.weight
	 decoder.uc.0.conv_2.bias
	 decoder.uc.0.bn_1.weight
	 decoder.uc.0.bn_1.bias
	 decoder.uc.0.bn_1.running_mean
	 decoder.uc.0.bn_1.running_var
	 decoder.uc.0.bn_1.num_batches_tracked
	 decoder.uc.0.bn_2.weight
	 decoder.uc.0.bn_2.bias
	 decoder.uc.0.bn_2.running_mean
	 decoder.uc.0.bn_2.running_var
	 decoder.uc.0.bn_2.num_batches_tracked
	 decoder.uc.0.act.weight
	 decoder.uc.1.up_conv.weight
	 decoder.uc.1.up_conv.bias
	 decoder.uc.1.conv_1.weight
	 decoder.uc.1.conv_1.bias
	 decoder.uc.1.conv_2.weight
	 decoder.uc.1.conv_2.bias
	 decoder.uc.1.bn_1.weight
	 decoder.uc.1.bn_1.bias
	 decoder.uc.1.bn_1.running_mean
	 decoder.uc.1.bn_1.running_var
	 decoder.uc.1.bn_1.num_batches_tracked
	 decoder.uc.1.bn_2.weight
	 decoder.uc.1.bn_2.bias
	 decoder.uc.1.bn_2.running_mean
	 decoder.uc.1.bn_2.running_var
	 decoder.uc.1.bn_2.num_batches_tracked
	 decoder.uc.1.act.weight
	 decoder.uc.2.up_conv.weight
	 decoder.uc.2.up_conv.bias
	 decoder.uc.2.conv_1.weight
	 decoder.uc.2.conv_1.bias
	 decoder.uc.2.conv_2.weight
	 decoder.uc.2.conv_2.bias
	 decoder.uc.2.bn_1.weight
	 decoder.uc.2.bn_1.bias
	 decoder.uc.2.bn_1.running_mean
	 decoder.uc.2.bn_1.running_var
	 decoder.uc.2.bn_1.num_batches_tracked
	 decoder.uc.2.bn_2.weight
	 decoder.uc.2.bn_2.bias
	 decoder.uc.2.bn_2.running_mean
	 decoder.uc.2.bn_2.running_var
	 decoder.uc.2.bn_2.num_batches_tracked
	 decoder.uc.2.act.weight
	 decoder.uc.3.up_conv.weight
	 decoder.uc.3.up_conv.bias
	 decoder.uc.3.conv_1.weight
	 decoder.uc.3.conv_1.bias
	 decoder.uc.3.conv_2.weight
	 decoder.uc.3.conv_2.bias
	 decoder.uc.3.bn_1.weight
	 decoder.uc.3.bn_1.bias
	 decoder.uc.3.bn_1.running_mean
	 decoder.uc.3.bn_1.running_var
	 decoder.uc.3.bn_1.num_batches_tracked
	 decoder.uc.3.bn_2.weight
	 decoder.uc.3.bn_2.bias
	 decoder.uc.3.bn_2.running_mean
	 decoder.uc.3.bn_2.running_var
	 decoder.uc.3.bn_2.num_batches_tracked
	 decoder.uc.3.act.weight
Warning: The following parameters in the current model does not exist in the pretrained model
	 decoder.center_dilation.dconv_1.weight
	 decoder.center_dilation.dconv_1.bias
	 decoder.center_dilation.dconv_2.weight
	 decoder.center_dilation.dconv_2.bias
	 decoder.center_dilation.dconv_3.weight
	 decoder.center_dilation.dconv_3.bias
	 decoder.center_dilation.dconv_4.weight
	 decoder.center_dilation.dconv_4.bias
	 decoder.upsample_1.conv1.weight
	 decoder.upsample_1.conv1.bias
	 decoder.upsample_1.tconv.weight
	 decoder.upsample_1.tconv.bias
	 decoder.upsample_1.conv2.weight
	 decoder.upsample_1.conv2.bias
	 decoder.upsample_2.conv1.weight
	 decoder.upsample_2.conv1.bias
	 decoder.upsample_2.tconv.weight
	 decoder.upsample_2.tconv.bias
	 decoder.upsample_2.conv2.weight
	 decoder.upsample_2.conv2.bias
	 decoder.upsample_3.conv1.weight
	 decoder.upsample_3.conv1.bias
	 decoder.upsample_3.tconv.weight
	 decoder.upsample_3.tconv.bias
	 decoder.upsample_3.conv2.weight
	 decoder.upsample_3.conv2.bias
	 decoder.upsample_4.conv1.weight
	 decoder.upsample_4.conv1.bias
	 decoder.upsample_4.tconv.weight
	 decoder.upsample_4.tconv.bias
	 decoder.upsample_4.conv2.weight
	 decoder.upsample_4.conv2.bias
	 decoder.tconv.weight
	 decoder.tconv.bias
Warning: The size of the following parameters in the current model does not match the ones in the pretrained model
	 decoder.classify.weight
Try loading with relaxed naming rule:
Prefix in pretrained model 
	pretrained param: encoder.conv1.weight -> current param: encoder.conv1.weight
	pretrained param: encoder.bn1.weight -> current param: encoder.bn1.weight
	pretrained param: encoder.bn1.bias -> current param: encoder.bn1.bias
	pretrained param: encoder.bn1.running_mean -> current param: encoder.bn1.running_mean
	pretrained param: encoder.bn1.running_var -> current param: encoder.bn1.running_var
	pretrained param: encoder.bn1.num_batches_tracked -> current param: encoder.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv1.weight -> current param: encoder.layer1.0.conv1.weight
	pretrained param: encoder.layer1.0.bn1.weight -> current param: encoder.layer1.0.bn1.weight
	pretrained param: encoder.layer1.0.bn1.bias -> current param: encoder.layer1.0.bn1.bias
	pretrained param: encoder.layer1.0.bn1.running_mean -> current param: encoder.layer1.0.bn1.running_mean
	pretrained param: encoder.layer1.0.bn1.running_var -> current param: encoder.layer1.0.bn1.running_var
	pretrained param: encoder.layer1.0.bn1.num_batches_tracked -> current param: encoder.layer1.0.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv2.weight -> current param: encoder.layer1.0.conv2.weight
	pretrained param: encoder.layer1.0.bn2.weight -> current param: encoder.layer1.0.bn2.weight
	pretrained param: encoder.layer1.0.bn2.bias -> current param: encoder.layer1.0.bn2.bias
	pretrained param: encoder.layer1.0.bn2.running_mean -> current param: encoder.layer1.0.bn2.running_mean
	pretrained param: encoder.layer1.0.bn2.running_var -> current param: encoder.layer1.0.bn2.running_var
	pretrained param: encoder.layer1.0.bn2.num_batches_tracked -> current param: encoder.layer1.0.bn2.num_batches_tracked
	pretrained param: encoder.layer1.0.conv3.weight -> current param: encoder.layer1.0.conv3.weight
	pretrained param: encoder.layer1.0.bn3.weight -> current param: encoder.layer1.0.bn3.weight
	pretrained param: encoder.layer1.0.bn3.bias -> current param: encoder.layer1.0.bn3.bias
	pretrained param: encoder.layer1.0.bn3.running_mean -> current param: encoder.layer1.0.bn3.running_mean
	pretrained param: encoder.layer1.0.bn3.running_var -> current param: encoder.layer1.0.bn3.running_var
	pretrained param: encoder.layer1.0.bn3.num_batches_tracked -> current param: encoder.layer1.0.bn3.num_batches_tracked
	pretrained param: encoder.layer1.0.downsample.0.weight -> current param: encoder.layer1.0.downsample.0.weight
	pretrained param: encoder.layer1.0.downsample.1.weight -> current param: encoder.layer1.0.downsample.1.weight
	pretrained param: encoder.layer1.0.downsample.1.bias -> current param: encoder.layer1.0.downsample.1.bias
	pretrained param: encoder.layer1.0.downsample.1.running_mean -> current param: encoder.layer1.0.downsample.1.running_mean
	pretrained param: encoder.layer1.0.downsample.1.running_var -> current param: encoder.layer1.0.downsample.1.running_var
	pretrained param: encoder.layer1.0.downsample.1.num_batches_tracked -> current param: encoder.layer1.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv1.weight -> current param: encoder.layer1.1.conv1.weight
	pretrained param: encoder.layer1.1.bn1.weight -> current param: encoder.layer1.1.bn1.weight
	pretrained param: encoder.layer1.1.bn1.bias -> current param: encoder.layer1.1.bn1.bias
	pretrained param: encoder.layer1.1.bn1.running_mean -> current param: encoder.layer1.1.bn1.running_mean
	pretrained param: encoder.layer1.1.bn1.running_var -> current param: encoder.layer1.1.bn1.running_var
	pretrained param: encoder.layer1.1.bn1.num_batches_tracked -> current param: encoder.layer1.1.bn1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv2.weight -> current param: encoder.layer1.1.conv2.weight
	pretrained param: encoder.layer1.1.bn2.weight -> current param: encoder.layer1.1.bn2.weight
	pretrained param: encoder.layer1.1.bn2.bias -> current param: encoder.layer1.1.bn2.bias
	pretrained param: encoder.layer1.1.bn2.running_mean -> current param: encoder.layer1.1.bn2.running_mean
	pretrained param: encoder.layer1.1.bn2.running_var -> current param: encoder.layer1.1.bn2.running_var
	pretrained param: encoder.layer1.1.bn2.num_batches_tracked -> current param: encoder.layer1.1.bn2.num_batches_tracked
	pretrained param: encoder.layer1.1.conv3.weight -> current param: encoder.layer1.1.conv3.weight
	pretrained param: encoder.layer1.1.bn3.weight -> current param: encoder.layer1.1.bn3.weight
	pretrained param: encoder.layer1.1.bn3.bias -> current param: encoder.layer1.1.bn3.bias
	pretrained param: encoder.layer1.1.bn3.running_mean -> current param: encoder.layer1.1.bn3.running_mean
	pretrained param: encoder.layer1.1.bn3.running_var -> current param: encoder.layer1.1.bn3.running_var
	pretrained param: encoder.layer1.1.bn3.num_batches_tracked -> current param: encoder.layer1.1.bn3.num_batches_tracked
	pretrained param: encoder.layer1.2.conv1.weight -> current param: encoder.layer1.2.conv1.weight
	pretrained param: encoder.layer1.2.bn1.weight -> current param: encoder.layer1.2.bn1.weight
	pretrained param: encoder.layer1.2.bn1.bias -> current param: encoder.layer1.2.bn1.bias
	pretrained param: encoder.layer1.2.bn1.running_mean -> current param: encoder.layer1.2.bn1.running_mean
	pretrained param: encoder.layer1.2.bn1.running_var -> current param: encoder.layer1.2.bn1.running_var
	pretrained param: encoder.layer1.2.bn1.num_batches_tracked -> current param: encoder.layer1.2.bn1.num_batches_tracked
	pretrained param: encoder.layer1.2.conv2.weight -> current param: encoder.layer1.2.conv2.weight
	pretrained param: encoder.layer1.2.bn2.weight -> current param: encoder.layer1.2.bn2.weight
	pretrained param: encoder.layer1.2.bn2.bias -> current param: encoder.layer1.2.bn2.bias
	pretrained param: encoder.layer1.2.bn2.running_mean -> current param: encoder.layer1.2.bn2.running_mean
	pretrained param: encoder.layer1.2.bn2.running_var -> current param: encoder.layer1.2.bn2.running_var
	pretrained param: encoder.layer1.2.bn2.num_batches_tracked -> current param: encoder.layer1.2.bn2.num_batches_tracked
	pretrained param: encoder.layer1.2.conv3.weight -> current param: encoder.layer1.2.conv3.weight
	pretrained param: encoder.layer1.2.bn3.weight -> current param: encoder.layer1.2.bn3.weight
	pretrained param: encoder.layer1.2.bn3.bias -> current param: encoder.layer1.2.bn3.bias
	pretrained param: encoder.layer1.2.bn3.running_mean -> current param: encoder.layer1.2.bn3.running_mean
	pretrained param: encoder.layer1.2.bn3.running_var -> current param: encoder.layer1.2.bn3.running_var
	pretrained param: encoder.layer1.2.bn3.num_batches_tracked -> current param: encoder.layer1.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.conv1.weight -> current param: encoder.layer2.0.conv1.weight
	pretrained param: encoder.layer2.0.bn1.weight -> current param: encoder.layer2.0.bn1.weight
	pretrained param: encoder.layer2.0.bn1.bias -> current param: encoder.layer2.0.bn1.bias
	pretrained param: encoder.layer2.0.bn1.running_mean -> current param: encoder.layer2.0.bn1.running_mean
	pretrained param: encoder.layer2.0.bn1.running_var -> current param: encoder.layer2.0.bn1.running_var
	pretrained param: encoder.layer2.0.bn1.num_batches_tracked -> current param: encoder.layer2.0.bn1.num_batches_tracked
	pretrained param: encoder.layer2.0.conv2.weight -> current param: encoder.layer2.0.conv2.weight
	pretrained param: encoder.layer2.0.bn2.weight -> current param: encoder.layer2.0.bn2.weight
	pretrained param: encoder.layer2.0.bn2.bias -> current param: encoder.layer2.0.bn2.bias
	pretrained param: encoder.layer2.0.bn2.running_mean -> current param: encoder.layer2.0.bn2.running_mean
	pretrained param: encoder.layer2.0.bn2.running_var -> current param: encoder.layer2.0.bn2.running_var
	pretrained param: encoder.layer2.0.bn2.num_batches_tracked -> current param: encoder.layer2.0.bn2.num_batches_tracked
	pretrained param: encoder.layer2.0.conv3.weight -> current param: encoder.layer2.0.conv3.weight
	pretrained param: encoder.layer2.0.bn3.weight -> current param: encoder.layer2.0.bn3.weight
	pretrained param: encoder.layer2.0.bn3.bias -> current param: encoder.layer2.0.bn3.bias
	pretrained param: encoder.layer2.0.bn3.running_mean -> current param: encoder.layer2.0.bn3.running_mean
	pretrained param: encoder.layer2.0.bn3.running_var -> current param: encoder.layer2.0.bn3.running_var
	pretrained param: encoder.layer2.0.bn3.num_batches_tracked -> current param: encoder.layer2.0.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.downsample.0.weight -> current param: encoder.layer2.0.downsample.0.weight
	pretrained param: encoder.layer2.0.downsample.1.weight -> current param: encoder.layer2.0.downsample.1.weight
	pretrained param: encoder.layer2.0.downsample.1.bias -> current param: encoder.layer2.0.downsample.1.bias
	pretrained param: encoder.layer2.0.downsample.1.running_mean -> current param: encoder.layer2.0.downsample.1.running_mean
	pretrained param: encoder.layer2.0.downsample.1.running_var -> current param: encoder.layer2.0.downsample.1.running_var
	pretrained param: encoder.layer2.0.downsample.1.num_batches_tracked -> current param: encoder.layer2.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv1.weight -> current param: encoder.layer2.1.conv1.weight
	pretrained param: encoder.layer2.1.bn1.weight -> current param: encoder.layer2.1.bn1.weight
	pretrained param: encoder.layer2.1.bn1.bias -> current param: encoder.layer2.1.bn1.bias
	pretrained param: encoder.layer2.1.bn1.running_mean -> current param: encoder.layer2.1.bn1.running_mean
	pretrained param: encoder.layer2.1.bn1.running_var -> current param: encoder.layer2.1.bn1.running_var
	pretrained param: encoder.layer2.1.bn1.num_batches_tracked -> current param: encoder.layer2.1.bn1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv2.weight -> current param: encoder.layer2.1.conv2.weight
	pretrained param: encoder.layer2.1.bn2.weight -> current param: encoder.layer2.1.bn2.weight
	pretrained param: encoder.layer2.1.bn2.bias -> current param: encoder.layer2.1.bn2.bias
	pretrained param: encoder.layer2.1.bn2.running_mean -> current param: encoder.layer2.1.bn2.running_mean
	pretrained param: encoder.layer2.1.bn2.running_var -> current param: encoder.layer2.1.bn2.running_var
	pretrained param: encoder.layer2.1.bn2.num_batches_tracked -> current param: encoder.layer2.1.bn2.num_batches_tracked
	pretrained param: encoder.layer2.1.conv3.weight -> current param: encoder.layer2.1.conv3.weight
	pretrained param: encoder.layer2.1.bn3.weight -> current param: encoder.layer2.1.bn3.weight
	pretrained param: encoder.layer2.1.bn3.bias -> current param: encoder.layer2.1.bn3.bias
	pretrained param: encoder.layer2.1.bn3.running_mean -> current param: encoder.layer2.1.bn3.running_mean
	pretrained param: encoder.layer2.1.bn3.running_var -> current param: encoder.layer2.1.bn3.running_var
	pretrained param: encoder.layer2.1.bn3.num_batches_tracked -> current param: encoder.layer2.1.bn3.num_batches_tracked
	pretrained param: encoder.layer2.2.conv1.weight -> current param: encoder.layer2.2.conv1.weight
	pretrained param: encoder.layer2.2.bn1.weight -> current param: encoder.layer2.2.bn1.weight
	pretrained param: encoder.layer2.2.bn1.bias -> current param: encoder.layer2.2.bn1.bias
	pretrained param: encoder.layer2.2.bn1.running_mean -> current param: encoder.layer2.2.bn1.running_mean
	pretrained param: encoder.layer2.2.bn1.running_var -> current param: encoder.layer2.2.bn1.running_var
	pretrained param: encoder.layer2.2.bn1.num_batches_tracked -> current param: encoder.layer2.2.bn1.num_batches_tracked
	pretrained param: encoder.layer2.2.conv2.weight -> current param: encoder.layer2.2.conv2.weight
	pretrained param: encoder.layer2.2.bn2.weight -> current param: encoder.layer2.2.bn2.weight
	pretrained param: encoder.layer2.2.bn2.bias -> current param: encoder.layer2.2.bn2.bias
	pretrained param: encoder.layer2.2.bn2.running_mean -> current param: encoder.layer2.2.bn2.running_mean
	pretrained param: encoder.layer2.2.bn2.running_var -> current param: encoder.layer2.2.bn2.running_var
	pretrained param: encoder.layer2.2.bn2.num_batches_tracked -> current param: encoder.layer2.2.bn2.num_batches_tracked
	pretrained param: encoder.layer2.2.conv3.weight -> current param: encoder.layer2.2.conv3.weight
	pretrained param: encoder.layer2.2.bn3.weight -> current param: encoder.layer2.2.bn3.weight
	pretrained param: encoder.layer2.2.bn3.bias -> current param: encoder.layer2.2.bn3.bias
	pretrained param: encoder.layer2.2.bn3.running_mean -> current param: encoder.layer2.2.bn3.running_mean
	pretrained param: encoder.layer2.2.bn3.running_var -> current param: encoder.layer2.2.bn3.running_var
	pretrained param: encoder.layer2.2.bn3.num_batches_tracked -> current param: encoder.layer2.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.3.conv1.weight -> current param: encoder.layer2.3.conv1.weight
	pretrained param: encoder.layer2.3.bn1.weight -> current param: encoder.layer2.3.bn1.weight
	pretrained param: encoder.layer2.3.bn1.bias -> current param: encoder.layer2.3.bn1.bias
	pretrained param: encoder.layer2.3.bn1.running_mean -> current param: encoder.layer2.3.bn1.running_mean
	pretrained param: encoder.layer2.3.bn1.running_var -> current param: encoder.layer2.3.bn1.running_var
	pretrained param: encoder.layer2.3.bn1.num_batches_tracked -> current param: encoder.layer2.3.bn1.num_batches_tracked
	pretrained param: encoder.layer2.3.conv2.weight -> current param: encoder.layer2.3.conv2.weight
	pretrained param: encoder.layer2.3.bn2.weight -> current param: encoder.layer2.3.bn2.weight
	pretrained param: encoder.layer2.3.bn2.bias -> current param: encoder.layer2.3.bn2.bias
	pretrained param: encoder.layer2.3.bn2.running_mean -> current param: encoder.layer2.3.bn2.running_mean
	pretrained param: encoder.layer2.3.bn2.running_var -> current param: encoder.layer2.3.bn2.running_var
	pretrained param: encoder.layer2.3.bn2.num_batches_tracked -> current param: encoder.layer2.3.bn2.num_batches_tracked
	pretrained param: encoder.layer2.3.conv3.weight -> current param: encoder.layer2.3.conv3.weight
	pretrained param: encoder.layer2.3.bn3.weight -> current param: encoder.layer2.3.bn3.weight
	pretrained param: encoder.layer2.3.bn3.bias -> current param: encoder.layer2.3.bn3.bias
	pretrained param: encoder.layer2.3.bn3.running_mean -> current param: encoder.layer2.3.bn3.running_mean
	pretrained param: encoder.layer2.3.bn3.running_var -> current param: encoder.layer2.3.bn3.running_var
	pretrained param: encoder.layer2.3.bn3.num_batches_tracked -> current param: encoder.layer2.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.conv1.weight -> current param: encoder.layer3.0.conv1.weight
	pretrained param: encoder.layer3.0.bn1.weight -> current param: encoder.layer3.0.bn1.weight
	pretrained param: encoder.layer3.0.bn1.bias -> current param: encoder.layer3.0.bn1.bias
	pretrained param: encoder.layer3.0.bn1.running_mean -> current param: encoder.layer3.0.bn1.running_mean
	pretrained param: encoder.layer3.0.bn1.running_var -> current param: encoder.layer3.0.bn1.running_var
	pretrained param: encoder.layer3.0.bn1.num_batches_tracked -> current param: encoder.layer3.0.bn1.num_batches_tracked
	pretrained param: encoder.layer3.0.conv2.weight -> current param: encoder.layer3.0.conv2.weight
	pretrained param: encoder.layer3.0.bn2.weight -> current param: encoder.layer3.0.bn2.weight
	pretrained param: encoder.layer3.0.bn2.bias -> current param: encoder.layer3.0.bn2.bias
	pretrained param: encoder.layer3.0.bn2.running_mean -> current param: encoder.layer3.0.bn2.running_mean
	pretrained param: encoder.layer3.0.bn2.running_var -> current param: encoder.layer3.0.bn2.running_var
	pretrained param: encoder.layer3.0.bn2.num_batches_tracked -> current param: encoder.layer3.0.bn2.num_batches_tracked
	pretrained param: encoder.layer3.0.conv3.weight -> current param: encoder.layer3.0.conv3.weight
	pretrained param: encoder.layer3.0.bn3.weight -> current param: encoder.layer3.0.bn3.weight
	pretrained param: encoder.layer3.0.bn3.bias -> current param: encoder.layer3.0.bn3.bias
	pretrained param: encoder.layer3.0.bn3.running_mean -> current param: encoder.layer3.0.bn3.running_mean
	pretrained param: encoder.layer3.0.bn3.running_var -> current param: encoder.layer3.0.bn3.running_var
	pretrained param: encoder.layer3.0.bn3.num_batches_tracked -> current param: encoder.layer3.0.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.downsample.0.weight -> current param: encoder.layer3.0.downsample.0.weight
	pretrained param: encoder.layer3.0.downsample.1.weight -> current param: encoder.layer3.0.downsample.1.weight
	pretrained param: encoder.layer3.0.downsample.1.bias -> current param: encoder.layer3.0.downsample.1.bias
	pretrained param: encoder.layer3.0.downsample.1.running_mean -> current param: encoder.layer3.0.downsample.1.running_mean
	pretrained param: encoder.layer3.0.downsample.1.running_var -> current param: encoder.layer3.0.downsample.1.running_var
	pretrained param: encoder.layer3.0.downsample.1.num_batches_tracked -> current param: encoder.layer3.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv1.weight -> current param: encoder.layer3.1.conv1.weight
	pretrained param: encoder.layer3.1.bn1.weight -> current param: encoder.layer3.1.bn1.weight
	pretrained param: encoder.layer3.1.bn1.bias -> current param: encoder.layer3.1.bn1.bias
	pretrained param: encoder.layer3.1.bn1.running_mean -> current param: encoder.layer3.1.bn1.running_mean
	pretrained param: encoder.layer3.1.bn1.running_var -> current param: encoder.layer3.1.bn1.running_var
	pretrained param: encoder.layer3.1.bn1.num_batches_tracked -> current param: encoder.layer3.1.bn1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv2.weight -> current param: encoder.layer3.1.conv2.weight
	pretrained param: encoder.layer3.1.bn2.weight -> current param: encoder.layer3.1.bn2.weight
	pretrained param: encoder.layer3.1.bn2.bias -> current param: encoder.layer3.1.bn2.bias
	pretrained param: encoder.layer3.1.bn2.running_mean -> current param: encoder.layer3.1.bn2.running_mean
	pretrained param: encoder.layer3.1.bn2.running_var -> current param: encoder.layer3.1.bn2.running_var
	pretrained param: encoder.layer3.1.bn2.num_batches_tracked -> current param: encoder.layer3.1.bn2.num_batches_tracked
	pretrained param: encoder.layer3.1.conv3.weight -> current param: encoder.layer3.1.conv3.weight
	pretrained param: encoder.layer3.1.bn3.weight -> current param: encoder.layer3.1.bn3.weight
	pretrained param: encoder.layer3.1.bn3.bias -> current param: encoder.layer3.1.bn3.bias
	pretrained param: encoder.layer3.1.bn3.running_mean -> current param: encoder.layer3.1.bn3.running_mean
	pretrained param: encoder.layer3.1.bn3.running_var -> current param: encoder.layer3.1.bn3.running_var
	pretrained param: encoder.layer3.1.bn3.num_batches_tracked -> current param: encoder.layer3.1.bn3.num_batches_tracked
	pretrained param: encoder.layer3.2.conv1.weight -> current param: encoder.layer3.2.conv1.weight
	pretrained param: encoder.layer3.2.bn1.weight -> current param: encoder.layer3.2.bn1.weight
	pretrained param: encoder.layer3.2.bn1.bias -> current param: encoder.layer3.2.bn1.bias
	pretrained param: encoder.layer3.2.bn1.running_mean -> current param: encoder.layer3.2.bn1.running_mean
	pretrained param: encoder.layer3.2.bn1.running_var -> current param: encoder.layer3.2.bn1.running_var
	pretrained param: encoder.layer3.2.bn1.num_batches_tracked -> current param: encoder.layer3.2.bn1.num_batches_tracked
	pretrained param: encoder.layer3.2.conv2.weight -> current param: encoder.layer3.2.conv2.weight
	pretrained param: encoder.layer3.2.bn2.weight -> current param: encoder.layer3.2.bn2.weight
	pretrained param: encoder.layer3.2.bn2.bias -> current param: encoder.layer3.2.bn2.bias
	pretrained param: encoder.layer3.2.bn2.running_mean -> current param: encoder.layer3.2.bn2.running_mean
	pretrained param: encoder.layer3.2.bn2.running_var -> current param: encoder.layer3.2.bn2.running_var
	pretrained param: encoder.layer3.2.bn2.num_batches_tracked -> current param: encoder.layer3.2.bn2.num_batches_tracked
	pretrained param: encoder.layer3.2.conv3.weight -> current param: encoder.layer3.2.conv3.weight
	pretrained param: encoder.layer3.2.bn3.weight -> current param: encoder.layer3.2.bn3.weight
	pretrained param: encoder.layer3.2.bn3.bias -> current param: encoder.layer3.2.bn3.bias
	pretrained param: encoder.layer3.2.bn3.running_mean -> current param: encoder.layer3.2.bn3.running_mean
	pretrained param: encoder.layer3.2.bn3.running_var -> current param: encoder.layer3.2.bn3.running_var
	pretrained param: encoder.layer3.2.bn3.num_batches_tracked -> current param: encoder.layer3.2.bn3.num_batches_tracked
	pretrained param: encoder.layer3.3.conv1.weight -> current param: encoder.layer3.3.conv1.weight
	pretrained param: encoder.layer3.3.bn1.weight -> current param: encoder.layer3.3.bn1.weight
	pretrained param: encoder.layer3.3.bn1.bias -> current param: encoder.layer3.3.bn1.bias
	pretrained param: encoder.layer3.3.bn1.running_mean -> current param: encoder.layer3.3.bn1.running_mean
	pretrained param: encoder.layer3.3.bn1.running_var -> current param: encoder.layer3.3.bn1.running_var
	pretrained param: encoder.layer3.3.bn1.num_batches_tracked -> current param: encoder.layer3.3.bn1.num_batches_tracked
	pretrained param: encoder.layer3.3.conv2.weight -> current param: encoder.layer3.3.conv2.weight
	pretrained param: encoder.layer3.3.bn2.weight -> current param: encoder.layer3.3.bn2.weight
	pretrained param: encoder.layer3.3.bn2.bias -> current param: encoder.layer3.3.bn2.bias
	pretrained param: encoder.layer3.3.bn2.running_mean -> current param: encoder.layer3.3.bn2.running_mean
	pretrained param: encoder.layer3.3.bn2.running_var -> current param: encoder.layer3.3.bn2.running_var
	pretrained param: encoder.layer3.3.bn2.num_batches_tracked -> current param: encoder.layer3.3.bn2.num_batches_tracked
	pretrained param: encoder.layer3.3.conv3.weight -> current param: encoder.layer3.3.conv3.weight
	pretrained param: encoder.layer3.3.bn3.weight -> current param: encoder.layer3.3.bn3.weight
	pretrained param: encoder.layer3.3.bn3.bias -> current param: encoder.layer3.3.bn3.bias
	pretrained param: encoder.layer3.3.bn3.running_mean -> current param: encoder.layer3.3.bn3.running_mean
	pretrained param: encoder.layer3.3.bn3.running_var -> current param: encoder.layer3.3.bn3.running_var
	pretrained param: encoder.layer3.3.bn3.num_batches_tracked -> current param: encoder.layer3.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.4.conv1.weight -> current param: encoder.layer3.4.conv1.weight
	pretrained param: encoder.layer3.4.bn1.weight -> current param: encoder.layer3.4.bn1.weight
	pretrained param: encoder.layer3.4.bn1.bias -> current param: encoder.layer3.4.bn1.bias
	pretrained param: encoder.layer3.4.bn1.running_mean -> current param: encoder.layer3.4.bn1.running_mean
	pretrained param: encoder.layer3.4.bn1.running_var -> current param: encoder.layer3.4.bn1.running_var
	pretrained param: encoder.layer3.4.bn1.num_batches_tracked -> current param: encoder.layer3.4.bn1.num_batches_tracked
	pretrained param: encoder.layer3.4.conv2.weight -> current param: encoder.layer3.4.conv2.weight
	pretrained param: encoder.layer3.4.bn2.weight -> current param: encoder.layer3.4.bn2.weight
	pretrained param: encoder.layer3.4.bn2.bias -> current param: encoder.layer3.4.bn2.bias
	pretrained param: encoder.layer3.4.bn2.running_mean -> current param: encoder.layer3.4.bn2.running_mean
	pretrained param: encoder.layer3.4.bn2.running_var -> current param: encoder.layer3.4.bn2.running_var
	pretrained param: encoder.layer3.4.bn2.num_batches_tracked -> current param: encoder.layer3.4.bn2.num_batches_tracked
	pretrained param: encoder.layer3.4.conv3.weight -> current param: encoder.layer3.4.conv3.weight
	pretrained param: encoder.layer3.4.bn3.weight -> current param: encoder.layer3.4.bn3.weight
	pretrained param: encoder.layer3.4.bn3.bias -> current param: encoder.layer3.4.bn3.bias
	pretrained param: encoder.layer3.4.bn3.running_mean -> current param: encoder.layer3.4.bn3.running_mean
	pretrained param: encoder.layer3.4.bn3.running_var -> current param: encoder.layer3.4.bn3.running_var
	pretrained param: encoder.layer3.4.bn3.num_batches_tracked -> current param: encoder.layer3.4.bn3.num_batches_tracked
	pretrained param: encoder.layer3.5.conv1.weight -> current param: encoder.layer3.5.conv1.weight
	pretrained param: encoder.layer3.5.bn1.weight -> current param: encoder.layer3.5.bn1.weight
	pretrained param: encoder.layer3.5.bn1.bias -> current param: encoder.layer3.5.bn1.bias
	pretrained param: encoder.layer3.5.bn1.running_mean -> current param: encoder.layer3.5.bn1.running_mean
	pretrained param: encoder.layer3.5.bn1.running_var -> current param: encoder.layer3.5.bn1.running_var
	pretrained param: encoder.layer3.5.bn1.num_batches_tracked -> current param: encoder.layer3.5.bn1.num_batches_tracked
	pretrained param: encoder.layer3.5.conv2.weight -> current param: encoder.layer3.5.conv2.weight
	pretrained param: encoder.layer3.5.bn2.weight -> current param: encoder.layer3.5.bn2.weight
	pretrained param: encoder.layer3.5.bn2.bias -> current param: encoder.layer3.5.bn2.bias
	pretrained param: encoder.layer3.5.bn2.running_mean -> current param: encoder.layer3.5.bn2.running_mean
	pretrained param: encoder.layer3.5.bn2.running_var -> current param: encoder.layer3.5.bn2.running_var
	pretrained param: encoder.layer3.5.bn2.num_batches_tracked -> current param: encoder.layer3.5.bn2.num_batches_tracked
	pretrained param: encoder.layer3.5.conv3.weight -> current param: encoder.layer3.5.conv3.weight
	pretrained param: encoder.layer3.5.bn3.weight -> current param: encoder.layer3.5.bn3.weight
	pretrained param: encoder.layer3.5.bn3.bias -> current param: encoder.layer3.5.bn3.bias
	pretrained param: encoder.layer3.5.bn3.running_mean -> current param: encoder.layer3.5.bn3.running_mean
	pretrained param: encoder.layer3.5.bn3.running_var -> current param: encoder.layer3.5.bn3.running_var
	pretrained param: encoder.layer3.5.bn3.num_batches_tracked -> current param: encoder.layer3.5.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.conv1.weight -> current param: encoder.layer4.0.conv1.weight
	pretrained param: encoder.layer4.0.bn1.weight -> current param: encoder.layer4.0.bn1.weight
	pretrained param: encoder.layer4.0.bn1.bias -> current param: encoder.layer4.0.bn1.bias
	pretrained param: encoder.layer4.0.bn1.running_mean -> current param: encoder.layer4.0.bn1.running_mean
	pretrained param: encoder.layer4.0.bn1.running_var -> current param: encoder.layer4.0.bn1.running_var
	pretrained param: encoder.layer4.0.bn1.num_batches_tracked -> current param: encoder.layer4.0.bn1.num_batches_tracked
	pretrained param: encoder.layer4.0.conv2.weight -> current param: encoder.layer4.0.conv2.weight
	pretrained param: encoder.layer4.0.bn2.weight -> current param: encoder.layer4.0.bn2.weight
	pretrained param: encoder.layer4.0.bn2.bias -> current param: encoder.layer4.0.bn2.bias
	pretrained param: encoder.layer4.0.bn2.running_mean -> current param: encoder.layer4.0.bn2.running_mean
	pretrained param: encoder.layer4.0.bn2.running_var -> current param: encoder.layer4.0.bn2.running_var
	pretrained param: encoder.layer4.0.bn2.num_batches_tracked -> current param: encoder.layer4.0.bn2.num_batches_tracked
	pretrained param: encoder.layer4.0.conv3.weight -> current param: encoder.layer4.0.conv3.weight
	pretrained param: encoder.layer4.0.bn3.weight -> current param: encoder.layer4.0.bn3.weight
	pretrained param: encoder.layer4.0.bn3.bias -> current param: encoder.layer4.0.bn3.bias
	pretrained param: encoder.layer4.0.bn3.running_mean -> current param: encoder.layer4.0.bn3.running_mean
	pretrained param: encoder.layer4.0.bn3.running_var -> current param: encoder.layer4.0.bn3.running_var
	pretrained param: encoder.layer4.0.bn3.num_batches_tracked -> current param: encoder.layer4.0.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.downsample.0.weight -> current param: encoder.layer4.0.downsample.0.weight
	pretrained param: encoder.layer4.0.downsample.1.weight -> current param: encoder.layer4.0.downsample.1.weight
	pretrained param: encoder.layer4.0.downsample.1.bias -> current param: encoder.layer4.0.downsample.1.bias
	pretrained param: encoder.layer4.0.downsample.1.running_mean -> current param: encoder.layer4.0.downsample.1.running_mean
	pretrained param: encoder.layer4.0.downsample.1.running_var -> current param: encoder.layer4.0.downsample.1.running_var
	pretrained param: encoder.layer4.0.downsample.1.num_batches_tracked -> current param: encoder.layer4.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv1.weight -> current param: encoder.layer4.1.conv1.weight
	pretrained param: encoder.layer4.1.bn1.weight -> current param: encoder.layer4.1.bn1.weight
	pretrained param: encoder.layer4.1.bn1.bias -> current param: encoder.layer4.1.bn1.bias
	pretrained param: encoder.layer4.1.bn1.running_mean -> current param: encoder.layer4.1.bn1.running_mean
	pretrained param: encoder.layer4.1.bn1.running_var -> current param: encoder.layer4.1.bn1.running_var
	pretrained param: encoder.layer4.1.bn1.num_batches_tracked -> current param: encoder.layer4.1.bn1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv2.weight -> current param: encoder.layer4.1.conv2.weight
	pretrained param: encoder.layer4.1.bn2.weight -> current param: encoder.layer4.1.bn2.weight
	pretrained param: encoder.layer4.1.bn2.bias -> current param: encoder.layer4.1.bn2.bias
	pretrained param: encoder.layer4.1.bn2.running_mean -> current param: encoder.layer4.1.bn2.running_mean
	pretrained param: encoder.layer4.1.bn2.running_var -> current param: encoder.layer4.1.bn2.running_var
	pretrained param: encoder.layer4.1.bn2.num_batches_tracked -> current param: encoder.layer4.1.bn2.num_batches_tracked
	pretrained param: encoder.layer4.1.conv3.weight -> current param: encoder.layer4.1.conv3.weight
	pretrained param: encoder.layer4.1.bn3.weight -> current param: encoder.layer4.1.bn3.weight
	pretrained param: encoder.layer4.1.bn3.bias -> current param: encoder.layer4.1.bn3.bias
	pretrained param: encoder.layer4.1.bn3.running_mean -> current param: encoder.layer4.1.bn3.running_mean
	pretrained param: encoder.layer4.1.bn3.running_var -> current param: encoder.layer4.1.bn3.running_var
	pretrained param: encoder.layer4.1.bn3.num_batches_tracked -> current param: encoder.layer4.1.bn3.num_batches_tracked
	pretrained param: encoder.layer4.2.conv1.weight -> current param: encoder.layer4.2.conv1.weight
	pretrained param: encoder.layer4.2.bn1.weight -> current param: encoder.layer4.2.bn1.weight
	pretrained param: encoder.layer4.2.bn1.bias -> current param: encoder.layer4.2.bn1.bias
	pretrained param: encoder.layer4.2.bn1.running_mean -> current param: encoder.layer4.2.bn1.running_mean
	pretrained param: encoder.layer4.2.bn1.running_var -> current param: encoder.layer4.2.bn1.running_var
	pretrained param: encoder.layer4.2.bn1.num_batches_tracked -> current param: encoder.layer4.2.bn1.num_batches_tracked
	pretrained param: encoder.layer4.2.conv2.weight -> current param: encoder.layer4.2.conv2.weight
	pretrained param: encoder.layer4.2.bn2.weight -> current param: encoder.layer4.2.bn2.weight
	pretrained param: encoder.layer4.2.bn2.bias -> current param: encoder.layer4.2.bn2.bias
	pretrained param: encoder.layer4.2.bn2.running_mean -> current param: encoder.layer4.2.bn2.running_mean
	pretrained param: encoder.layer4.2.bn2.running_var -> current param: encoder.layer4.2.bn2.running_var
	pretrained param: encoder.layer4.2.bn2.num_batches_tracked -> current param: encoder.layer4.2.bn2.num_batches_tracked
	pretrained param: encoder.layer4.2.conv3.weight -> current param: encoder.layer4.2.conv3.weight
	pretrained param: encoder.layer4.2.bn3.weight -> current param: encoder.layer4.2.bn3.weight
	pretrained param: encoder.layer4.2.bn3.bias -> current param: encoder.layer4.2.bn3.bias
	pretrained param: encoder.layer4.2.bn3.running_mean -> current param: encoder.layer4.2.bn3.running_mean
	pretrained param: encoder.layer4.2.bn3.running_var -> current param: encoder.layer4.2.bn3.running_var
	pretrained param: encoder.layer4.2.bn3.num_batches_tracked -> current param: encoder.layer4.2.bn3.num_batches_tracked
	pretrained param: decoder.classify.weight -> current param: decoder.classify.weight
		Ignoring: decoder.classify.weight->decoder.classify.weight (size mismatch)
	pretrained param: decoder.classify.bias -> current param: decoder.classify.bias
90.11% of the model loaded from the pretrained
Total params: 179.77M
Dataset catalyst_h2 is not supported, use default mean stats instead
Training model on the catalyst_h2 dataset
Dataset catalyst_h2 is not supported, use default mean stats instead
[train] Epoch: 0/80 xent: 1.354 softIoU: 8.285 IoU: 0.000 
Execution time: 283.95594336278737

[valid] Epoch: 0/80 xent: 0.376 softIoU: 8.013 IoU: 0.000 
Execution time: 67.92250222200528

[train] Epoch: 1/80 xent: 0.322 softIoU: 8.012 IoU: 0.000 
Execution time: 282.1872799741104

[valid] Epoch: 1/80 xent: 0.377 softIoU: 8.011 IoU: 0.000 
Execution time: 67.58831490995362

[train] Epoch: 2/80 xent: 0.326 softIoU: 8.011 IoU: 0.000 
Execution time: 284.3034431547858

[valid] Epoch: 2/80 xent: 0.376 softIoU: 8.011 IoU: 0.000 
Execution time: 67.73792753182352

[train] Epoch: 3/80 xent: 0.324 softIoU: 8.010 IoU: 0.000 
Execution time: 281.76838026894256

[valid] Epoch: 3/80 xent: 0.376 softIoU: 8.011 IoU: 0.000 
Execution time: 68.94213568186387

[train] Epoch: 4/80 xent: 0.320 softIoU: 8.011 IoU: 0.000 
Execution time: 283.3821167717688

[valid] Epoch: 4/80 xent: 0.375 softIoU: 8.011 IoU: 0.000 
Execution time: 68.02593343425542

[train] Epoch: 5/80 xent: 0.320 softIoU: 8.011 IoU: 0.000 
Execution time: 284.5581222269684

[valid] Epoch: 5/80 xent: 0.375 softIoU: 8.011 IoU: 0.000 
Execution time: 68.76234778901562

[train] Epoch: 6/80 xent: 0.315 softIoU: 8.010 IoU: 0.000 
Execution time: 283.17453909199685

[valid] Epoch: 6/80 xent: 0.374 softIoU: 8.011 IoU: 0.000 
Execution time: 69.27453083870932

[train] Epoch: 7/80 xent: 0.324 softIoU: 8.010 IoU: 0.000 
Execution time: 284.3524589231238

[valid] Epoch: 7/80 xent: 0.374 softIoU: 8.011 IoU: 0.000 
Execution time: 68.25902334786952

[train] Epoch: 8/80 xent: 0.316 softIoU: 8.010 IoU: 0.000 
Execution time: 281.8201845237054

[valid] Epoch: 8/80 xent: 0.373 softIoU: 8.011 IoU: 0.000 
Execution time: 68.19875696767122

[train] Epoch: 9/80 xent: 0.323 softIoU: 8.011 IoU: 0.000 
Execution time: 283.1511684888974

[valid] Epoch: 9/80 xent: 0.372 softIoU: 8.011 IoU: 0.000 
Execution time: 67.68714704737067

[train] Epoch: 10/80 xent: 0.316 softIoU: 8.010 IoU: 0.000 
Execution time: 281.5538159972057

[valid] Epoch: 10/80 xent: 0.372 softIoU: 8.011 IoU: 0.000 
Execution time: 67.48548197001219

[train] Epoch: 11/80 xent: 0.321 softIoU: 8.011 IoU: 0.000 
Execution time: 282.2015313603915

[valid] Epoch: 11/80 xent: 0.371 softIoU: 8.010 IoU: 0.000 
Execution time: 67.48342046607286

[train] Epoch: 12/80 xent: 0.316 softIoU: 8.010 IoU: 0.000 
Execution time: 287.4134331718087

[valid] Epoch: 12/80 xent: 0.370 softIoU: 8.010 IoU: 0.000 
Execution time: 68.22665977384895

[train] Epoch: 13/80 xent: 0.320 softIoU: 8.010 IoU: 0.000 
Execution time: 282.0406578211114

[valid] Epoch: 13/80 xent: 0.370 softIoU: 8.010 IoU: 0.000 
Execution time: 68.17327160201967

[train] Epoch: 14/80 xent: 0.318 softIoU: 8.010 IoU: 0.000 
Execution time: 282.75940952496603

[valid] Epoch: 14/80 xent: 0.368 softIoU: 8.010 IoU: 0.000 
Execution time: 68.07704710774124

[train] Epoch: 15/80 xent: 0.318 softIoU: 8.010 IoU: 0.000 
Execution time: 282.6426855591126

[valid] Epoch: 15/80 xent: 0.367 softIoU: 8.010 IoU: 0.000 
Execution time: 70.39755742019042

[train] Epoch: 16/80 xent: 0.316 softIoU: 8.011 IoU: 0.000 
Execution time: 284.9609975214116

[valid] Epoch: 16/80 xent: 0.365 softIoU: 8.010 IoU: 0.000 
Execution time: 67.96379595063627

[train] Epoch: 17/80 xent: 0.316 softIoU: 8.009 IoU: 0.000 
Execution time: 289.0622165170498

[valid] Epoch: 17/80 xent: 0.362 softIoU: 8.010 IoU: 0.000 
Execution time: 71.03945789532736

[train] Epoch: 18/80 xent: 0.313 softIoU: 8.010 IoU: 0.000 
Execution time: 295.2348363841884

[valid] Epoch: 18/80 xent: 0.361 softIoU: 8.010 IoU: 0.000 
Execution time: 70.96121897315606

[train] Epoch: 19/80 xent: 0.311 softIoU: 8.010 IoU: 0.000 
Execution time: 294.8835913478397

[valid] Epoch: 19/80 xent: 0.358 softIoU: 8.010 IoU: 0.000 
Execution time: 70.30213598767295

[train] Epoch: 20/80 xent: 0.305 softIoU: 8.009 IoU: 0.000 
Execution time: 292.0533044231124

[valid] Epoch: 20/80 xent: 0.354 softIoU: 8.009 IoU: 0.000 
Execution time: 70.02779244771227

Saved model at /scratch/sr365/models/catalysth2_mb_3/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-20.pth.tar
[train] Epoch: 21/80 xent: 0.304 softIoU: 8.008 IoU: 0.000 
Execution time: 291.90789302717894

[valid] Epoch: 21/80 xent: 0.347 softIoU: 8.010 IoU: 0.000 
Execution time: 71.27581291086972

[train] Epoch: 22/80 xent: 0.298 softIoU: 8.009 IoU: 0.000 
Execution time: 291.8218205529265

[valid] Epoch: 22/80 xent: 0.341 softIoU: 8.008 IoU: 0.000 
Execution time: 70.95674455119297

[train] Epoch: 23/80 xent: 0.290 softIoU: 8.008 IoU: 0.000 
Execution time: 293.71462777256966

[valid] Epoch: 23/80 xent: 0.330 softIoU: 8.007 IoU: 0.000 
Execution time: 73.13357013789937

[train] Epoch: 24/80 xent: 0.278 softIoU: 8.006 IoU: 0.000 
Execution time: 302.6696820850484

[valid] Epoch: 24/80 xent: 0.308 softIoU: 8.005 IoU: 0.000 
Execution time: 75.4586084280163

[train] Epoch: 25/80 xent: 0.253 softIoU: 8.001 IoU: 0.000 
Execution time: 308.69888666877523

[valid] Epoch: 25/80 xent: 0.271 softIoU: 7.998 IoU: 0.000 
Execution time: 73.95373249286786

[train] Epoch: 26/80 xent: 0.198 softIoU: 7.966 IoU: 0.015 
Execution time: 307.85109868785366

[valid] Epoch: 26/80 xent: 0.171 softIoU: 7.899 IoU: 0.062 
Execution time: 79.63552781613544

[train] Epoch: 27/80 xent: 0.099 softIoU: 7.719 IoU: 0.326 
Execution time: 309.94883828796446

[valid] Epoch: 27/80 xent: 0.121 softIoU: 7.617 IoU: 0.137 
Execution time: 78.0230385940522

[train] Epoch: 28/80 xent: 0.061 softIoU: 7.573 IoU: 0.468 
Execution time: 314.0018790140748

[valid] Epoch: 28/80 xent: 0.105 softIoU: 7.558 IoU: 0.148 
Execution time: 78.94724984373897

[train] Epoch: 29/80 xent: 0.053 softIoU: 7.464 IoU: 0.428 
Execution time: 309.06777447089553

[valid] Epoch: 29/80 xent: 0.112 softIoU: 7.544 IoU: 0.140 
Execution time: 77.79291306668893

[train] Epoch: 30/80 xent: 0.056 softIoU: 7.454 IoU: 0.406 
Execution time: 313.2009695437737

[valid] Epoch: 30/80 xent: 0.131 softIoU: 7.527 IoU: 0.119 
Execution time: 73.83390374435112

[train] Epoch: 31/80 xent: 0.051 softIoU: 7.432 IoU: 0.446 
Execution time: 305.09589913859963

[valid] Epoch: 31/80 xent: 0.084 softIoU: 7.505 IoU: 0.217 
Execution time: 77.90843478683382

[train] Epoch: 32/80 xent: 0.057 softIoU: 7.449 IoU: 0.387 
Execution time: 308.5041773398407

[valid] Epoch: 32/80 xent: 0.074 softIoU: 7.489 IoU: 0.287 
Execution time: 82.90772550320253

[train] Epoch: 33/80 xent: 0.048 softIoU: 7.430 IoU: 0.463 
Execution time: 307.8068427252583

[valid] Epoch: 33/80 xent: 0.086 softIoU: 7.501 IoU: 0.214 
Execution time: 72.8273443528451

[train] Epoch: 34/80 xent: 0.047 softIoU: 7.399 IoU: 0.470 
Execution time: 300.80745305120945

[valid] Epoch: 34/80 xent: 0.075 softIoU: 7.488 IoU: 0.263 
Execution time: 73.14560810476542

[train] Epoch: 35/80 xent: 0.047 softIoU: 7.395 IoU: 0.471 
Execution time: 323.47108932817355

[valid] Epoch: 35/80 xent: 0.078 softIoU: 7.490 IoU: 0.250 
Execution time: 73.08304311614484

[train] Epoch: 36/80 xent: 0.046 softIoU: 7.407 IoU: 0.510 
Execution time: 319.83358622388914

[valid] Epoch: 36/80 xent: 0.114 softIoU: 7.514 IoU: 0.144 
Execution time: 74.88935643341392

[train] Epoch: 37/80 xent: 0.054 softIoU: 7.413 IoU: 0.425 
Execution time: 314.59338826779276

[valid] Epoch: 37/80 xent: 0.073 softIoU: 7.480 IoU: 0.271 
Execution time: 75.83173339208588

[train] Epoch: 38/80 xent: 0.048 softIoU: 7.401 IoU: 0.475 
Execution time: 310.53176042996347

[valid] Epoch: 38/80 xent: 0.080 softIoU: 7.486 IoU: 0.238 
Execution time: 75.64354866463691

[train] Epoch: 39/80 xent: 0.041 softIoU: 7.384 IoU: 0.506 
Execution time: 319.5286415927112

[valid] Epoch: 39/80 xent: 0.065 softIoU: 7.472 IoU: 0.314 
Execution time: 72.98704686714336

[train] Epoch: 40/80 xent: 0.040 softIoU: 7.366 IoU: 0.534 
Execution time: 312.7139751999639

[valid] Epoch: 40/80 xent: 0.071 softIoU: 7.473 IoU: 0.278 
Execution time: 74.66551425866783

Saved model at /scratch/sr365/models/catalysth2_mb_3/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-40.pth.tar
[train] Epoch: 41/80 xent: 0.041 softIoU: 7.377 IoU: 0.539 
Execution time: 310.0132603258826

[valid] Epoch: 41/80 xent: 0.079 softIoU: 7.473 IoU: 0.232 
Execution time: 79.32804069994017

[train] Epoch: 42/80 xent: 0.040 softIoU: 7.391 IoU: 0.548 
Execution time: 314.3138994341716

[valid] Epoch: 42/80 xent: 0.076 softIoU: 7.474 IoU: 0.241 
Execution time: 79.04246262600645

[train] Epoch: 43/80 xent: 0.043 softIoU: 7.395 IoU: 0.519 
Execution time: 305.84701041318476

[valid] Epoch: 43/80 xent: 0.066 softIoU: 7.476 IoU: 0.311 
Execution time: 74.08611834980547

[train] Epoch: 44/80 xent: 0.040 softIoU: 7.370 IoU: 0.523 
Execution time: 307.6877883579582

[valid] Epoch: 44/80 xent: 0.075 softIoU: 7.471 IoU: 0.257 
Execution time: 81.15378478774801

[train] Epoch: 45/80 xent: 0.041 softIoU: 7.377 IoU: 0.527 
Execution time: 310.27915694518015

[valid] Epoch: 45/80 xent: 0.082 softIoU: 7.475 IoU: 0.222 
Execution time: 77.67380272923037

[train] Epoch: 46/80 xent: 0.039 softIoU: 7.380 IoU: 0.550 
Execution time: 309.9349226797931

[valid] Epoch: 46/80 xent: 0.062 softIoU: 7.469 IoU: 0.325 
Execution time: 78.8512010439299

[train] Epoch: 47/80 xent: 0.039 softIoU: 7.393 IoU: 0.530 
Execution time: 303.89079126995057

[valid] Epoch: 47/80 xent: 0.067 softIoU: 7.478 IoU: 0.301 
Execution time: 75.51865439908579

[train] Epoch: 48/80 xent: 0.043 softIoU: 7.367 IoU: 0.516 
Execution time: 308.6759034511633

[valid] Epoch: 48/80 xent: 0.064 softIoU: 7.478 IoU: 0.319 
Execution time: 76.32279310328886

[train] Epoch: 49/80 xent: 0.041 softIoU: 7.364 IoU: 0.505 
Execution time: 306.5860104258172

[valid] Epoch: 49/80 xent: 0.063 softIoU: 7.469 IoU: 0.324 
Execution time: 79.85072323912755

[train] Epoch: 50/80 xent: 0.043 softIoU: 7.387 IoU: 0.501 
Execution time: 306.6548779429868

[valid] Epoch: 50/80 xent: 0.068 softIoU: 7.470 IoU: 0.286 
Execution time: 74.94276793394238

[train] Epoch: 51/80 xent: 0.040 softIoU: 7.377 IoU: 0.520 
Execution time: 308.8358278069645

[valid] Epoch: 51/80 xent: 0.071 softIoU: 7.470 IoU: 0.269 
Execution time: 77.32584859710187

[train] Epoch: 52/80 xent: 0.043 softIoU: 7.379 IoU: 0.510 
Execution time: 310.55461626313627

[valid] Epoch: 52/80 xent: 0.072 softIoU: 7.468 IoU: 0.261 
Execution time: 77.9304717942141

[train] Epoch: 53/80 xent: 0.042 softIoU: 7.387 IoU: 0.495 
Execution time: 312.76219740416855

[valid] Epoch: 53/80 xent: 0.066 softIoU: 7.466 IoU: 0.295 
Execution time: 73.10619959887117

[train] Epoch: 54/80 xent: 0.039 softIoU: 7.382 IoU: 0.523 
Execution time: 312.9627165910788

[valid] Epoch: 54/80 xent: 0.061 softIoU: 7.475 IoU: 0.343 
Execution time: 74.52124444302171

[train] Epoch: 55/80 xent: 0.041 softIoU: 7.379 IoU: 0.523 
Execution time: 313.90203786594793

[valid] Epoch: 55/80 xent: 0.059 softIoU: 7.470 IoU: 0.346 
Execution time: 76.23433799715713

[train] Epoch: 56/80 xent: 0.038 softIoU: 7.366 IoU: 0.550 
Execution time: 310.85049763321877

[valid] Epoch: 56/80 xent: 0.069 softIoU: 7.473 IoU: 0.280 
Execution time: 77.1428806912154

[train] Epoch: 57/80 xent: 0.040 softIoU: 7.384 IoU: 0.514 
Execution time: 313.7799061210826

[valid] Epoch: 57/80 xent: 0.062 softIoU: 7.470 IoU: 0.318 
Execution time: 80.51913034636527

[train] Epoch: 58/80 xent: 0.042 softIoU: 7.379 IoU: 0.517 
Execution time: 324.0742209767923

[valid] Epoch: 58/80 xent: 0.072 softIoU: 7.469 IoU: 0.261 
Execution time: 78.80411920463666

[train] Epoch: 59/80 xent: 0.044 softIoU: 7.401 IoU: 0.502 
Execution time: 306.2387921670452

[valid] Epoch: 59/80 xent: 0.072 softIoU: 7.470 IoU: 0.259 
Execution time: 73.25277663068846

[train] Epoch: 60/80 xent: 0.041 softIoU: 7.389 IoU: 0.493 
Execution time: 330.3976135891862

[valid] Epoch: 60/80 xent: 0.061 softIoU: 7.467 IoU: 0.334 
Execution time: 82.01848572213203

Saved model at /scratch/sr365/models/catalysth2_mb_3/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-60.pth.tar
[train] Epoch: 61/80 xent: 0.041 softIoU: 7.376 IoU: 0.519 
Execution time: 303.1681807991117

[valid] Epoch: 61/80 xent: 0.056 softIoU: 7.476 IoU: 0.398 
Execution time: 75.2959525291808

[train] Epoch: 62/80 xent: 0.041 softIoU: 7.371 IoU: 0.496 
Execution time: 308.3361929077655

[valid] Epoch: 62/80 xent: 0.098 softIoU: 7.472 IoU: 0.182 
Execution time: 73.03374272212386

[train] Epoch: 63/80 xent: 0.038 softIoU: 7.367 IoU: 0.541 
Execution time: 303.1184358680621

[valid] Epoch: 63/80 xent: 0.081 softIoU: 7.469 IoU: 0.222 
Execution time: 72.93195321317762

[train] Epoch: 64/80 xent: 0.039 softIoU: 7.381 IoU: 0.535 
Execution time: 312.72448242781684

[valid] Epoch: 64/80 xent: 0.060 softIoU: 7.470 IoU: 0.348 
Execution time: 78.34098718920723

[train] Epoch: 65/80 xent: 0.038 softIoU: 7.355 IoU: 0.548 
Execution time: 311.81134424591437

[valid] Epoch: 65/80 xent: 0.063 softIoU: 7.471 IoU: 0.318 
Execution time: 73.00393227301538

[train] Epoch: 66/80 xent: 0.041 softIoU: 7.363 IoU: 0.506 
Execution time: 300.01184249157086

[valid] Epoch: 66/80 xent: 0.065 softIoU: 7.470 IoU: 0.308 
Execution time: 72.65004631597549

[train] Epoch: 67/80 xent: 0.039 softIoU: 7.378 IoU: 0.520 
Execution time: 315.22746887104586

[valid] Epoch: 67/80 xent: 0.068 softIoU: 7.471 IoU: 0.281 
Execution time: 72.6195317641832

[train] Epoch: 68/80 xent: 0.039 softIoU: 7.364 IoU: 0.531 
Execution time: 335.4328751848079

[valid] Epoch: 68/80 xent: 0.067 softIoU: 7.468 IoU: 0.293 
Execution time: 72.83531277440488

[train] Epoch: 69/80 xent: 0.038 softIoU: 7.346 IoU: 0.549 
Execution time: 299.8881100961007

[valid] Epoch: 69/80 xent: 0.061 softIoU: 7.466 IoU: 0.329 
Execution time: 72.4924747729674

[train] Epoch: 70/80 xent: 0.041 softIoU: 7.418 IoU: 0.494 
Execution time: 299.53623610083014

[valid] Epoch: 70/80 xent: 0.071 softIoU: 7.469 IoU: 0.264 
Execution time: 81.91979899303988

[train] Epoch: 71/80 xent: 0.039 softIoU: 7.367 IoU: 0.523 
Execution time: 304.5000553512946

[valid] Epoch: 71/80 xent: 0.067 softIoU: 7.470 IoU: 0.293 
Execution time: 72.76834422489628

[train] Epoch: 72/80 xent: 0.039 softIoU: 7.373 IoU: 0.538 
Execution time: 313.21046928176656

[valid] Epoch: 72/80 xent: 0.058 softIoU: 7.469 IoU: 0.374 
Execution time: 72.7666425309144

[train] Epoch: 73/80 xent: 0.038 softIoU: 7.399 IoU: 0.558 
Execution time: 303.0152260051109

[valid] Epoch: 73/80 xent: 0.069 softIoU: 7.469 IoU: 0.276 
Execution time: 77.28312589786947

[train] Epoch: 74/80 xent: 0.039 softIoU: 7.350 IoU: 0.541 
Execution time: 312.77164249913767

[valid] Epoch: 74/80 xent: 0.064 softIoU: 7.466 IoU: 0.313 
Execution time: 73.38924402883276

[train] Epoch: 75/80 xent: 0.038 softIoU: 7.379 IoU: 0.528 
Execution time: 322.7695085047744

[valid] Epoch: 75/80 xent: 0.063 softIoU: 7.471 IoU: 0.319 
Execution time: 72.6395627357997

[train] Epoch: 76/80 xent: 0.039 softIoU: 7.370 IoU: 0.518 
Execution time: 334.68554092012346

[valid] Epoch: 76/80 xent: 0.054 softIoU: 7.471 IoU: 0.412 
Execution time: 73.22020066482946

[train] Epoch: 77/80 xent: 0.040 softIoU: 7.359 IoU: 0.540 
Execution time: 299.4159098020755

[valid] Epoch: 77/80 xent: 0.058 softIoU: 7.477 IoU: 0.380 
Execution time: 82.92798544559628

[train] Epoch: 78/80 xent: 0.040 softIoU: 7.360 IoU: 0.515 
Execution time: 300.13199778227136

[valid] Epoch: 78/80 xent: 0.068 softIoU: 7.467 IoU: 0.282 
Execution time: 72.36490511288866

[train] Epoch: 79/80 xent: 0.037 softIoU: 7.373 IoU: 0.563 
Execution time: 302.32966046687216

[valid] Epoch: 79/80 xent: 0.062 softIoU: 7.474 IoU: 0.342 
Execution time: 72.6999481790699

Saved model at /scratch/sr365/models/catalysth2_mb_3/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-80.pth.tar
Device being used: cuda:1
Finetuning model from /scratch/wh145/models/solarmapper_final/ct/epoch-80.pth.tar
Warning: The following parameters in the pretrained model does not exist in the current model
	 decoder.uc.0.up_conv.weight
	 decoder.uc.0.up_conv.bias
	 decoder.uc.0.conv_1.weight
	 decoder.uc.0.conv_1.bias
	 decoder.uc.0.conv_2.weight
	 decoder.uc.0.conv_2.bias
	 decoder.uc.0.bn_1.weight
	 decoder.uc.0.bn_1.bias
	 decoder.uc.0.bn_1.running_mean
	 decoder.uc.0.bn_1.running_var
	 decoder.uc.0.bn_1.num_batches_tracked
	 decoder.uc.0.bn_2.weight
	 decoder.uc.0.bn_2.bias
	 decoder.uc.0.bn_2.running_mean
	 decoder.uc.0.bn_2.running_var
	 decoder.uc.0.bn_2.num_batches_tracked
	 decoder.uc.0.act.weight
	 decoder.uc.1.up_conv.weight
	 decoder.uc.1.up_conv.bias
	 decoder.uc.1.conv_1.weight
	 decoder.uc.1.conv_1.bias
	 decoder.uc.1.conv_2.weight
	 decoder.uc.1.conv_2.bias
	 decoder.uc.1.bn_1.weight
	 decoder.uc.1.bn_1.bias
	 decoder.uc.1.bn_1.running_mean
	 decoder.uc.1.bn_1.running_var
	 decoder.uc.1.bn_1.num_batches_tracked
	 decoder.uc.1.bn_2.weight
	 decoder.uc.1.bn_2.bias
	 decoder.uc.1.bn_2.running_mean
	 decoder.uc.1.bn_2.running_var
	 decoder.uc.1.bn_2.num_batches_tracked
	 decoder.uc.1.act.weight
	 decoder.uc.2.up_conv.weight
	 decoder.uc.2.up_conv.bias
	 decoder.uc.2.conv_1.weight
	 decoder.uc.2.conv_1.bias
	 decoder.uc.2.conv_2.weight
	 decoder.uc.2.conv_2.bias
	 decoder.uc.2.bn_1.weight
	 decoder.uc.2.bn_1.bias
	 decoder.uc.2.bn_1.running_mean
	 decoder.uc.2.bn_1.running_var
	 decoder.uc.2.bn_1.num_batches_tracked
	 decoder.uc.2.bn_2.weight
	 decoder.uc.2.bn_2.bias
	 decoder.uc.2.bn_2.running_mean
	 decoder.uc.2.bn_2.running_var
	 decoder.uc.2.bn_2.num_batches_tracked
	 decoder.uc.2.act.weight
	 decoder.uc.3.up_conv.weight
	 decoder.uc.3.up_conv.bias
	 decoder.uc.3.conv_1.weight
	 decoder.uc.3.conv_1.bias
	 decoder.uc.3.conv_2.weight
	 decoder.uc.3.conv_2.bias
	 decoder.uc.3.bn_1.weight
	 decoder.uc.3.bn_1.bias
	 decoder.uc.3.bn_1.running_mean
	 decoder.uc.3.bn_1.running_var
	 decoder.uc.3.bn_1.num_batches_tracked
	 decoder.uc.3.bn_2.weight
	 decoder.uc.3.bn_2.bias
	 decoder.uc.3.bn_2.running_mean
	 decoder.uc.3.bn_2.running_var
	 decoder.uc.3.bn_2.num_batches_tracked
	 decoder.uc.3.act.weight
Warning: The following parameters in the current model does not exist in the pretrained model
	 decoder.center_dilation.dconv_1.weight
	 decoder.center_dilation.dconv_1.bias
	 decoder.center_dilation.dconv_2.weight
	 decoder.center_dilation.dconv_2.bias
	 decoder.center_dilation.dconv_3.weight
	 decoder.center_dilation.dconv_3.bias
	 decoder.center_dilation.dconv_4.weight
	 decoder.center_dilation.dconv_4.bias
	 decoder.upsample_1.conv1.weight
	 decoder.upsample_1.conv1.bias
	 decoder.upsample_1.tconv.weight
	 decoder.upsample_1.tconv.bias
	 decoder.upsample_1.conv2.weight
	 decoder.upsample_1.conv2.bias
	 decoder.upsample_2.conv1.weight
	 decoder.upsample_2.conv1.bias
	 decoder.upsample_2.tconv.weight
	 decoder.upsample_2.tconv.bias
	 decoder.upsample_2.conv2.weight
	 decoder.upsample_2.conv2.bias
	 decoder.upsample_3.conv1.weight
	 decoder.upsample_3.conv1.bias
	 decoder.upsample_3.tconv.weight
	 decoder.upsample_3.tconv.bias
	 decoder.upsample_3.conv2.weight
	 decoder.upsample_3.conv2.bias
	 decoder.upsample_4.conv1.weight
	 decoder.upsample_4.conv1.bias
	 decoder.upsample_4.tconv.weight
	 decoder.upsample_4.tconv.bias
	 decoder.upsample_4.conv2.weight
	 decoder.upsample_4.conv2.bias
	 decoder.tconv.weight
	 decoder.tconv.bias
Warning: The size of the following parameters in the current model does not match the ones in the pretrained model
	 decoder.classify.weight
Try loading with relaxed naming rule:
Prefix in pretrained model 
	pretrained param: encoder.conv1.weight -> current param: encoder.conv1.weight
	pretrained param: encoder.bn1.weight -> current param: encoder.bn1.weight
	pretrained param: encoder.bn1.bias -> current param: encoder.bn1.bias
	pretrained param: encoder.bn1.running_mean -> current param: encoder.bn1.running_mean
	pretrained param: encoder.bn1.running_var -> current param: encoder.bn1.running_var
	pretrained param: encoder.bn1.num_batches_tracked -> current param: encoder.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv1.weight -> current param: encoder.layer1.0.conv1.weight
	pretrained param: encoder.layer1.0.bn1.weight -> current param: encoder.layer1.0.bn1.weight
	pretrained param: encoder.layer1.0.bn1.bias -> current param: encoder.layer1.0.bn1.bias
	pretrained param: encoder.layer1.0.bn1.running_mean -> current param: encoder.layer1.0.bn1.running_mean
	pretrained param: encoder.layer1.0.bn1.running_var -> current param: encoder.layer1.0.bn1.running_var
	pretrained param: encoder.layer1.0.bn1.num_batches_tracked -> current param: encoder.layer1.0.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv2.weight -> current param: encoder.layer1.0.conv2.weight
	pretrained param: encoder.layer1.0.bn2.weight -> current param: encoder.layer1.0.bn2.weight
	pretrained param: encoder.layer1.0.bn2.bias -> current param: encoder.layer1.0.bn2.bias
	pretrained param: encoder.layer1.0.bn2.running_mean -> current param: encoder.layer1.0.bn2.running_mean
	pretrained param: encoder.layer1.0.bn2.running_var -> current param: encoder.layer1.0.bn2.running_var
	pretrained param: encoder.layer1.0.bn2.num_batches_tracked -> current param: encoder.layer1.0.bn2.num_batches_tracked
	pretrained param: encoder.layer1.0.conv3.weight -> current param: encoder.layer1.0.conv3.weight
	pretrained param: encoder.layer1.0.bn3.weight -> current param: encoder.layer1.0.bn3.weight
	pretrained param: encoder.layer1.0.bn3.bias -> current param: encoder.layer1.0.bn3.bias
	pretrained param: encoder.layer1.0.bn3.running_mean -> current param: encoder.layer1.0.bn3.running_mean
	pretrained param: encoder.layer1.0.bn3.running_var -> current param: encoder.layer1.0.bn3.running_var
	pretrained param: encoder.layer1.0.bn3.num_batches_tracked -> current param: encoder.layer1.0.bn3.num_batches_tracked
	pretrained param: encoder.layer1.0.downsample.0.weight -> current param: encoder.layer1.0.downsample.0.weight
	pretrained param: encoder.layer1.0.downsample.1.weight -> current param: encoder.layer1.0.downsample.1.weight
	pretrained param: encoder.layer1.0.downsample.1.bias -> current param: encoder.layer1.0.downsample.1.bias
	pretrained param: encoder.layer1.0.downsample.1.running_mean -> current param: encoder.layer1.0.downsample.1.running_mean
	pretrained param: encoder.layer1.0.downsample.1.running_var -> current param: encoder.layer1.0.downsample.1.running_var
	pretrained param: encoder.layer1.0.downsample.1.num_batches_tracked -> current param: encoder.layer1.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv1.weight -> current param: encoder.layer1.1.conv1.weight
	pretrained param: encoder.layer1.1.bn1.weight -> current param: encoder.layer1.1.bn1.weight
	pretrained param: encoder.layer1.1.bn1.bias -> current param: encoder.layer1.1.bn1.bias
	pretrained param: encoder.layer1.1.bn1.running_mean -> current param: encoder.layer1.1.bn1.running_mean
	pretrained param: encoder.layer1.1.bn1.running_var -> current param: encoder.layer1.1.bn1.running_var
	pretrained param: encoder.layer1.1.bn1.num_batches_tracked -> current param: encoder.layer1.1.bn1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv2.weight -> current param: encoder.layer1.1.conv2.weight
	pretrained param: encoder.layer1.1.bn2.weight -> current param: encoder.layer1.1.bn2.weight
	pretrained param: encoder.layer1.1.bn2.bias -> current param: encoder.layer1.1.bn2.bias
	pretrained param: encoder.layer1.1.bn2.running_mean -> current param: encoder.layer1.1.bn2.running_mean
	pretrained param: encoder.layer1.1.bn2.running_var -> current param: encoder.layer1.1.bn2.running_var
	pretrained param: encoder.layer1.1.bn2.num_batches_tracked -> current param: encoder.layer1.1.bn2.num_batches_tracked
	pretrained param: encoder.layer1.1.conv3.weight -> current param: encoder.layer1.1.conv3.weight
	pretrained param: encoder.layer1.1.bn3.weight -> current param: encoder.layer1.1.bn3.weight
	pretrained param: encoder.layer1.1.bn3.bias -> current param: encoder.layer1.1.bn3.bias
	pretrained param: encoder.layer1.1.bn3.running_mean -> current param: encoder.layer1.1.bn3.running_mean
	pretrained param: encoder.layer1.1.bn3.running_var -> current param: encoder.layer1.1.bn3.running_var
	pretrained param: encoder.layer1.1.bn3.num_batches_tracked -> current param: encoder.layer1.1.bn3.num_batches_tracked
	pretrained param: encoder.layer1.2.conv1.weight -> current param: encoder.layer1.2.conv1.weight
	pretrained param: encoder.layer1.2.bn1.weight -> current param: encoder.layer1.2.bn1.weight
	pretrained param: encoder.layer1.2.bn1.bias -> current param: encoder.layer1.2.bn1.bias
	pretrained param: encoder.layer1.2.bn1.running_mean -> current param: encoder.layer1.2.bn1.running_mean
	pretrained param: encoder.layer1.2.bn1.running_var -> current param: encoder.layer1.2.bn1.running_var
	pretrained param: encoder.layer1.2.bn1.num_batches_tracked -> current param: encoder.layer1.2.bn1.num_batches_tracked
	pretrained param: encoder.layer1.2.conv2.weight -> current param: encoder.layer1.2.conv2.weight
	pretrained param: encoder.layer1.2.bn2.weight -> current param: encoder.layer1.2.bn2.weight
	pretrained param: encoder.layer1.2.bn2.bias -> current param: encoder.layer1.2.bn2.bias
	pretrained param: encoder.layer1.2.bn2.running_mean -> current param: encoder.layer1.2.bn2.running_mean
	pretrained param: encoder.layer1.2.bn2.running_var -> current param: encoder.layer1.2.bn2.running_var
	pretrained param: encoder.layer1.2.bn2.num_batches_tracked -> current param: encoder.layer1.2.bn2.num_batches_tracked
	pretrained param: encoder.layer1.2.conv3.weight -> current param: encoder.layer1.2.conv3.weight
	pretrained param: encoder.layer1.2.bn3.weight -> current param: encoder.layer1.2.bn3.weight
	pretrained param: encoder.layer1.2.bn3.bias -> current param: encoder.layer1.2.bn3.bias
	pretrained param: encoder.layer1.2.bn3.running_mean -> current param: encoder.layer1.2.bn3.running_mean
	pretrained param: encoder.layer1.2.bn3.running_var -> current param: encoder.layer1.2.bn3.running_var
	pretrained param: encoder.layer1.2.bn3.num_batches_tracked -> current param: encoder.layer1.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.conv1.weight -> current param: encoder.layer2.0.conv1.weight
	pretrained param: encoder.layer2.0.bn1.weight -> current param: encoder.layer2.0.bn1.weight
	pretrained param: encoder.layer2.0.bn1.bias -> current param: encoder.layer2.0.bn1.bias
	pretrained param: encoder.layer2.0.bn1.running_mean -> current param: encoder.layer2.0.bn1.running_mean
	pretrained param: encoder.layer2.0.bn1.running_var -> current param: encoder.layer2.0.bn1.running_var
	pretrained param: encoder.layer2.0.bn1.num_batches_tracked -> current param: encoder.layer2.0.bn1.num_batches_tracked
	pretrained param: encoder.layer2.0.conv2.weight -> current param: encoder.layer2.0.conv2.weight
	pretrained param: encoder.layer2.0.bn2.weight -> current param: encoder.layer2.0.bn2.weight
	pretrained param: encoder.layer2.0.bn2.bias -> current param: encoder.layer2.0.bn2.bias
	pretrained param: encoder.layer2.0.bn2.running_mean -> current param: encoder.layer2.0.bn2.running_mean
	pretrained param: encoder.layer2.0.bn2.running_var -> current param: encoder.layer2.0.bn2.running_var
	pretrained param: encoder.layer2.0.bn2.num_batches_tracked -> current param: encoder.layer2.0.bn2.num_batches_tracked
	pretrained param: encoder.layer2.0.conv3.weight -> current param: encoder.layer2.0.conv3.weight
	pretrained param: encoder.layer2.0.bn3.weight -> current param: encoder.layer2.0.bn3.weight
	pretrained param: encoder.layer2.0.bn3.bias -> current param: encoder.layer2.0.bn3.bias
	pretrained param: encoder.layer2.0.bn3.running_mean -> current param: encoder.layer2.0.bn3.running_mean
	pretrained param: encoder.layer2.0.bn3.running_var -> current param: encoder.layer2.0.bn3.running_var
	pretrained param: encoder.layer2.0.bn3.num_batches_tracked -> current param: encoder.layer2.0.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.downsample.0.weight -> current param: encoder.layer2.0.downsample.0.weight
	pretrained param: encoder.layer2.0.downsample.1.weight -> current param: encoder.layer2.0.downsample.1.weight
	pretrained param: encoder.layer2.0.downsample.1.bias -> current param: encoder.layer2.0.downsample.1.bias
	pretrained param: encoder.layer2.0.downsample.1.running_mean -> current param: encoder.layer2.0.downsample.1.running_mean
	pretrained param: encoder.layer2.0.downsample.1.running_var -> current param: encoder.layer2.0.downsample.1.running_var
	pretrained param: encoder.layer2.0.downsample.1.num_batches_tracked -> current param: encoder.layer2.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv1.weight -> current param: encoder.layer2.1.conv1.weight
	pretrained param: encoder.layer2.1.bn1.weight -> current param: encoder.layer2.1.bn1.weight
	pretrained param: encoder.layer2.1.bn1.bias -> current param: encoder.layer2.1.bn1.bias
	pretrained param: encoder.layer2.1.bn1.running_mean -> current param: encoder.layer2.1.bn1.running_mean
	pretrained param: encoder.layer2.1.bn1.running_var -> current param: encoder.layer2.1.bn1.running_var
	pretrained param: encoder.layer2.1.bn1.num_batches_tracked -> current param: encoder.layer2.1.bn1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv2.weight -> current param: encoder.layer2.1.conv2.weight
	pretrained param: encoder.layer2.1.bn2.weight -> current param: encoder.layer2.1.bn2.weight
	pretrained param: encoder.layer2.1.bn2.bias -> current param: encoder.layer2.1.bn2.bias
	pretrained param: encoder.layer2.1.bn2.running_mean -> current param: encoder.layer2.1.bn2.running_mean
	pretrained param: encoder.layer2.1.bn2.running_var -> current param: encoder.layer2.1.bn2.running_var
	pretrained param: encoder.layer2.1.bn2.num_batches_tracked -> current param: encoder.layer2.1.bn2.num_batches_tracked
	pretrained param: encoder.layer2.1.conv3.weight -> current param: encoder.layer2.1.conv3.weight
	pretrained param: encoder.layer2.1.bn3.weight -> current param: encoder.layer2.1.bn3.weight
	pretrained param: encoder.layer2.1.bn3.bias -> current param: encoder.layer2.1.bn3.bias
	pretrained param: encoder.layer2.1.bn3.running_mean -> current param: encoder.layer2.1.bn3.running_mean
	pretrained param: encoder.layer2.1.bn3.running_var -> current param: encoder.layer2.1.bn3.running_var
	pretrained param: encoder.layer2.1.bn3.num_batches_tracked -> current param: encoder.layer2.1.bn3.num_batches_tracked
	pretrained param: encoder.layer2.2.conv1.weight -> current param: encoder.layer2.2.conv1.weight
	pretrained param: encoder.layer2.2.bn1.weight -> current param: encoder.layer2.2.bn1.weight
	pretrained param: encoder.layer2.2.bn1.bias -> current param: encoder.layer2.2.bn1.bias
	pretrained param: encoder.layer2.2.bn1.running_mean -> current param: encoder.layer2.2.bn1.running_mean
	pretrained param: encoder.layer2.2.bn1.running_var -> current param: encoder.layer2.2.bn1.running_var
	pretrained param: encoder.layer2.2.bn1.num_batches_tracked -> current param: encoder.layer2.2.bn1.num_batches_tracked
	pretrained param: encoder.layer2.2.conv2.weight -> current param: encoder.layer2.2.conv2.weight
	pretrained param: encoder.layer2.2.bn2.weight -> current param: encoder.layer2.2.bn2.weight
	pretrained param: encoder.layer2.2.bn2.bias -> current param: encoder.layer2.2.bn2.bias
	pretrained param: encoder.layer2.2.bn2.running_mean -> current param: encoder.layer2.2.bn2.running_mean
	pretrained param: encoder.layer2.2.bn2.running_var -> current param: encoder.layer2.2.bn2.running_var
	pretrained param: encoder.layer2.2.bn2.num_batches_tracked -> current param: encoder.layer2.2.bn2.num_batches_tracked
	pretrained param: encoder.layer2.2.conv3.weight -> current param: encoder.layer2.2.conv3.weight
	pretrained param: encoder.layer2.2.bn3.weight -> current param: encoder.layer2.2.bn3.weight
	pretrained param: encoder.layer2.2.bn3.bias -> current param: encoder.layer2.2.bn3.bias
	pretrained param: encoder.layer2.2.bn3.running_mean -> current param: encoder.layer2.2.bn3.running_mean
	pretrained param: encoder.layer2.2.bn3.running_var -> current param: encoder.layer2.2.bn3.running_var
	pretrained param: encoder.layer2.2.bn3.num_batches_tracked -> current param: encoder.layer2.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.3.conv1.weight -> current param: encoder.layer2.3.conv1.weight
	pretrained param: encoder.layer2.3.bn1.weight -> current param: encoder.layer2.3.bn1.weight
	pretrained param: encoder.layer2.3.bn1.bias -> current param: encoder.layer2.3.bn1.bias
	pretrained param: encoder.layer2.3.bn1.running_mean -> current param: encoder.layer2.3.bn1.running_mean
	pretrained param: encoder.layer2.3.bn1.running_var -> current param: encoder.layer2.3.bn1.running_var
	pretrained param: encoder.layer2.3.bn1.num_batches_tracked -> current param: encoder.layer2.3.bn1.num_batches_tracked
	pretrained param: encoder.layer2.3.conv2.weight -> current param: encoder.layer2.3.conv2.weight
	pretrained param: encoder.layer2.3.bn2.weight -> current param: encoder.layer2.3.bn2.weight
	pretrained param: encoder.layer2.3.bn2.bias -> current param: encoder.layer2.3.bn2.bias
	pretrained param: encoder.layer2.3.bn2.running_mean -> current param: encoder.layer2.3.bn2.running_mean
	pretrained param: encoder.layer2.3.bn2.running_var -> current param: encoder.layer2.3.bn2.running_var
	pretrained param: encoder.layer2.3.bn2.num_batches_tracked -> current param: encoder.layer2.3.bn2.num_batches_tracked
	pretrained param: encoder.layer2.3.conv3.weight -> current param: encoder.layer2.3.conv3.weight
	pretrained param: encoder.layer2.3.bn3.weight -> current param: encoder.layer2.3.bn3.weight
	pretrained param: encoder.layer2.3.bn3.bias -> current param: encoder.layer2.3.bn3.bias
	pretrained param: encoder.layer2.3.bn3.running_mean -> current param: encoder.layer2.3.bn3.running_mean
	pretrained param: encoder.layer2.3.bn3.running_var -> current param: encoder.layer2.3.bn3.running_var
	pretrained param: encoder.layer2.3.bn3.num_batches_tracked -> current param: encoder.layer2.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.conv1.weight -> current param: encoder.layer3.0.conv1.weight
	pretrained param: encoder.layer3.0.bn1.weight -> current param: encoder.layer3.0.bn1.weight
	pretrained param: encoder.layer3.0.bn1.bias -> current param: encoder.layer3.0.bn1.bias
	pretrained param: encoder.layer3.0.bn1.running_mean -> current param: encoder.layer3.0.bn1.running_mean
	pretrained param: encoder.layer3.0.bn1.running_var -> current param: encoder.layer3.0.bn1.running_var
	pretrained param: encoder.layer3.0.bn1.num_batches_tracked -> current param: encoder.layer3.0.bn1.num_batches_tracked
	pretrained param: encoder.layer3.0.conv2.weight -> current param: encoder.layer3.0.conv2.weight
	pretrained param: encoder.layer3.0.bn2.weight -> current param: encoder.layer3.0.bn2.weight
	pretrained param: encoder.layer3.0.bn2.bias -> current param: encoder.layer3.0.bn2.bias
	pretrained param: encoder.layer3.0.bn2.running_mean -> current param: encoder.layer3.0.bn2.running_mean
	pretrained param: encoder.layer3.0.bn2.running_var -> current param: encoder.layer3.0.bn2.running_var
	pretrained param: encoder.layer3.0.bn2.num_batches_tracked -> current param: encoder.layer3.0.bn2.num_batches_tracked
	pretrained param: encoder.layer3.0.conv3.weight -> current param: encoder.layer3.0.conv3.weight
	pretrained param: encoder.layer3.0.bn3.weight -> current param: encoder.layer3.0.bn3.weight
	pretrained param: encoder.layer3.0.bn3.bias -> current param: encoder.layer3.0.bn3.bias
	pretrained param: encoder.layer3.0.bn3.running_mean -> current param: encoder.layer3.0.bn3.running_mean
	pretrained param: encoder.layer3.0.bn3.running_var -> current param: encoder.layer3.0.bn3.running_var
	pretrained param: encoder.layer3.0.bn3.num_batches_tracked -> current param: encoder.layer3.0.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.downsample.0.weight -> current param: encoder.layer3.0.downsample.0.weight
	pretrained param: encoder.layer3.0.downsample.1.weight -> current param: encoder.layer3.0.downsample.1.weight
	pretrained param: encoder.layer3.0.downsample.1.bias -> current param: encoder.layer3.0.downsample.1.bias
	pretrained param: encoder.layer3.0.downsample.1.running_mean -> current param: encoder.layer3.0.downsample.1.running_mean
	pretrained param: encoder.layer3.0.downsample.1.running_var -> current param: encoder.layer3.0.downsample.1.running_var
	pretrained param: encoder.layer3.0.downsample.1.num_batches_tracked -> current param: encoder.layer3.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv1.weight -> current param: encoder.layer3.1.conv1.weight
	pretrained param: encoder.layer3.1.bn1.weight -> current param: encoder.layer3.1.bn1.weight
	pretrained param: encoder.layer3.1.bn1.bias -> current param: encoder.layer3.1.bn1.bias
	pretrained param: encoder.layer3.1.bn1.running_mean -> current param: encoder.layer3.1.bn1.running_mean
	pretrained param: encoder.layer3.1.bn1.running_var -> current param: encoder.layer3.1.bn1.running_var
	pretrained param: encoder.layer3.1.bn1.num_batches_tracked -> current param: encoder.layer3.1.bn1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv2.weight -> current param: encoder.layer3.1.conv2.weight
	pretrained param: encoder.layer3.1.bn2.weight -> current param: encoder.layer3.1.bn2.weight
	pretrained param: encoder.layer3.1.bn2.bias -> current param: encoder.layer3.1.bn2.bias
	pretrained param: encoder.layer3.1.bn2.running_mean -> current param: encoder.layer3.1.bn2.running_mean
	pretrained param: encoder.layer3.1.bn2.running_var -> current param: encoder.layer3.1.bn2.running_var
	pretrained param: encoder.layer3.1.bn2.num_batches_tracked -> current param: encoder.layer3.1.bn2.num_batches_tracked
	pretrained param: encoder.layer3.1.conv3.weight -> current param: encoder.layer3.1.conv3.weight
	pretrained param: encoder.layer3.1.bn3.weight -> current param: encoder.layer3.1.bn3.weight
	pretrained param: encoder.layer3.1.bn3.bias -> current param: encoder.layer3.1.bn3.bias
	pretrained param: encoder.layer3.1.bn3.running_mean -> current param: encoder.layer3.1.bn3.running_mean
	pretrained param: encoder.layer3.1.bn3.running_var -> current param: encoder.layer3.1.bn3.running_var
	pretrained param: encoder.layer3.1.bn3.num_batches_tracked -> current param: encoder.layer3.1.bn3.num_batches_tracked
	pretrained param: encoder.layer3.2.conv1.weight -> current param: encoder.layer3.2.conv1.weight
	pretrained param: encoder.layer3.2.bn1.weight -> current param: encoder.layer3.2.bn1.weight
	pretrained param: encoder.layer3.2.bn1.bias -> current param: encoder.layer3.2.bn1.bias
	pretrained param: encoder.layer3.2.bn1.running_mean -> current param: encoder.layer3.2.bn1.running_mean
	pretrained param: encoder.layer3.2.bn1.running_var -> current param: encoder.layer3.2.bn1.running_var
	pretrained param: encoder.layer3.2.bn1.num_batches_tracked -> current param: encoder.layer3.2.bn1.num_batches_tracked
	pretrained param: encoder.layer3.2.conv2.weight -> current param: encoder.layer3.2.conv2.weight
	pretrained param: encoder.layer3.2.bn2.weight -> current param: encoder.layer3.2.bn2.weight
	pretrained param: encoder.layer3.2.bn2.bias -> current param: encoder.layer3.2.bn2.bias
	pretrained param: encoder.layer3.2.bn2.running_mean -> current param: encoder.layer3.2.bn2.running_mean
	pretrained param: encoder.layer3.2.bn2.running_var -> current param: encoder.layer3.2.bn2.running_var
	pretrained param: encoder.layer3.2.bn2.num_batches_tracked -> current param: encoder.layer3.2.bn2.num_batches_tracked
	pretrained param: encoder.layer3.2.conv3.weight -> current param: encoder.layer3.2.conv3.weight
	pretrained param: encoder.layer3.2.bn3.weight -> current param: encoder.layer3.2.bn3.weight
	pretrained param: encoder.layer3.2.bn3.bias -> current param: encoder.layer3.2.bn3.bias
	pretrained param: encoder.layer3.2.bn3.running_mean -> current param: encoder.layer3.2.bn3.running_mean
	pretrained param: encoder.layer3.2.bn3.running_var -> current param: encoder.layer3.2.bn3.running_var
	pretrained param: encoder.layer3.2.bn3.num_batches_tracked -> current param: encoder.layer3.2.bn3.num_batches_tracked
	pretrained param: encoder.layer3.3.conv1.weight -> current param: encoder.layer3.3.conv1.weight
	pretrained param: encoder.layer3.3.bn1.weight -> current param: encoder.layer3.3.bn1.weight
	pretrained param: encoder.layer3.3.bn1.bias -> current param: encoder.layer3.3.bn1.bias
	pretrained param: encoder.layer3.3.bn1.running_mean -> current param: encoder.layer3.3.bn1.running_mean
	pretrained param: encoder.layer3.3.bn1.running_var -> current param: encoder.layer3.3.bn1.running_var
	pretrained param: encoder.layer3.3.bn1.num_batches_tracked -> current param: encoder.layer3.3.bn1.num_batches_tracked
	pretrained param: encoder.layer3.3.conv2.weight -> current param: encoder.layer3.3.conv2.weight
	pretrained param: encoder.layer3.3.bn2.weight -> current param: encoder.layer3.3.bn2.weight
	pretrained param: encoder.layer3.3.bn2.bias -> current param: encoder.layer3.3.bn2.bias
	pretrained param: encoder.layer3.3.bn2.running_mean -> current param: encoder.layer3.3.bn2.running_mean
	pretrained param: encoder.layer3.3.bn2.running_var -> current param: encoder.layer3.3.bn2.running_var
	pretrained param: encoder.layer3.3.bn2.num_batches_tracked -> current param: encoder.layer3.3.bn2.num_batches_tracked
	pretrained param: encoder.layer3.3.conv3.weight -> current param: encoder.layer3.3.conv3.weight
	pretrained param: encoder.layer3.3.bn3.weight -> current param: encoder.layer3.3.bn3.weight
	pretrained param: encoder.layer3.3.bn3.bias -> current param: encoder.layer3.3.bn3.bias
	pretrained param: encoder.layer3.3.bn3.running_mean -> current param: encoder.layer3.3.bn3.running_mean
	pretrained param: encoder.layer3.3.bn3.running_var -> current param: encoder.layer3.3.bn3.running_var
	pretrained param: encoder.layer3.3.bn3.num_batches_tracked -> current param: encoder.layer3.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.4.conv1.weight -> current param: encoder.layer3.4.conv1.weight
	pretrained param: encoder.layer3.4.bn1.weight -> current param: encoder.layer3.4.bn1.weight
	pretrained param: encoder.layer3.4.bn1.bias -> current param: encoder.layer3.4.bn1.bias
	pretrained param: encoder.layer3.4.bn1.running_mean -> current param: encoder.layer3.4.bn1.running_mean
	pretrained param: encoder.layer3.4.bn1.running_var -> current param: encoder.layer3.4.bn1.running_var
	pretrained param: encoder.layer3.4.bn1.num_batches_tracked -> current param: encoder.layer3.4.bn1.num_batches_tracked
	pretrained param: encoder.layer3.4.conv2.weight -> current param: encoder.layer3.4.conv2.weight
	pretrained param: encoder.layer3.4.bn2.weight -> current param: encoder.layer3.4.bn2.weight
	pretrained param: encoder.layer3.4.bn2.bias -> current param: encoder.layer3.4.bn2.bias
	pretrained param: encoder.layer3.4.bn2.running_mean -> current param: encoder.layer3.4.bn2.running_mean
	pretrained param: encoder.layer3.4.bn2.running_var -> current param: encoder.layer3.4.bn2.running_var
	pretrained param: encoder.layer3.4.bn2.num_batches_tracked -> current param: encoder.layer3.4.bn2.num_batches_tracked
	pretrained param: encoder.layer3.4.conv3.weight -> current param: encoder.layer3.4.conv3.weight
	pretrained param: encoder.layer3.4.bn3.weight -> current param: encoder.layer3.4.bn3.weight
	pretrained param: encoder.layer3.4.bn3.bias -> current param: encoder.layer3.4.bn3.bias
	pretrained param: encoder.layer3.4.bn3.running_mean -> current param: encoder.layer3.4.bn3.running_mean
	pretrained param: encoder.layer3.4.bn3.running_var -> current param: encoder.layer3.4.bn3.running_var
	pretrained param: encoder.layer3.4.bn3.num_batches_tracked -> current param: encoder.layer3.4.bn3.num_batches_tracked
	pretrained param: encoder.layer3.5.conv1.weight -> current param: encoder.layer3.5.conv1.weight
	pretrained param: encoder.layer3.5.bn1.weight -> current param: encoder.layer3.5.bn1.weight
	pretrained param: encoder.layer3.5.bn1.bias -> current param: encoder.layer3.5.bn1.bias
	pretrained param: encoder.layer3.5.bn1.running_mean -> current param: encoder.layer3.5.bn1.running_mean
	pretrained param: encoder.layer3.5.bn1.running_var -> current param: encoder.layer3.5.bn1.running_var
	pretrained param: encoder.layer3.5.bn1.num_batches_tracked -> current param: encoder.layer3.5.bn1.num_batches_tracked
	pretrained param: encoder.layer3.5.conv2.weight -> current param: encoder.layer3.5.conv2.weight
	pretrained param: encoder.layer3.5.bn2.weight -> current param: encoder.layer3.5.bn2.weight
	pretrained param: encoder.layer3.5.bn2.bias -> current param: encoder.layer3.5.bn2.bias
	pretrained param: encoder.layer3.5.bn2.running_mean -> current param: encoder.layer3.5.bn2.running_mean
	pretrained param: encoder.layer3.5.bn2.running_var -> current param: encoder.layer3.5.bn2.running_var
	pretrained param: encoder.layer3.5.bn2.num_batches_tracked -> current param: encoder.layer3.5.bn2.num_batches_tracked
	pretrained param: encoder.layer3.5.conv3.weight -> current param: encoder.layer3.5.conv3.weight
	pretrained param: encoder.layer3.5.bn3.weight -> current param: encoder.layer3.5.bn3.weight
	pretrained param: encoder.layer3.5.bn3.bias -> current param: encoder.layer3.5.bn3.bias
	pretrained param: encoder.layer3.5.bn3.running_mean -> current param: encoder.layer3.5.bn3.running_mean
	pretrained param: encoder.layer3.5.bn3.running_var -> current param: encoder.layer3.5.bn3.running_var
	pretrained param: encoder.layer3.5.bn3.num_batches_tracked -> current param: encoder.layer3.5.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.conv1.weight -> current param: encoder.layer4.0.conv1.weight
	pretrained param: encoder.layer4.0.bn1.weight -> current param: encoder.layer4.0.bn1.weight
	pretrained param: encoder.layer4.0.bn1.bias -> current param: encoder.layer4.0.bn1.bias
	pretrained param: encoder.layer4.0.bn1.running_mean -> current param: encoder.layer4.0.bn1.running_mean
	pretrained param: encoder.layer4.0.bn1.running_var -> current param: encoder.layer4.0.bn1.running_var
	pretrained param: encoder.layer4.0.bn1.num_batches_tracked -> current param: encoder.layer4.0.bn1.num_batches_tracked
	pretrained param: encoder.layer4.0.conv2.weight -> current param: encoder.layer4.0.conv2.weight
	pretrained param: encoder.layer4.0.bn2.weight -> current param: encoder.layer4.0.bn2.weight
	pretrained param: encoder.layer4.0.bn2.bias -> current param: encoder.layer4.0.bn2.bias
	pretrained param: encoder.layer4.0.bn2.running_mean -> current param: encoder.layer4.0.bn2.running_mean
	pretrained param: encoder.layer4.0.bn2.running_var -> current param: encoder.layer4.0.bn2.running_var
	pretrained param: encoder.layer4.0.bn2.num_batches_tracked -> current param: encoder.layer4.0.bn2.num_batches_tracked
	pretrained param: encoder.layer4.0.conv3.weight -> current param: encoder.layer4.0.conv3.weight
	pretrained param: encoder.layer4.0.bn3.weight -> current param: encoder.layer4.0.bn3.weight
	pretrained param: encoder.layer4.0.bn3.bias -> current param: encoder.layer4.0.bn3.bias
	pretrained param: encoder.layer4.0.bn3.running_mean -> current param: encoder.layer4.0.bn3.running_mean
	pretrained param: encoder.layer4.0.bn3.running_var -> current param: encoder.layer4.0.bn3.running_var
	pretrained param: encoder.layer4.0.bn3.num_batches_tracked -> current param: encoder.layer4.0.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.downsample.0.weight -> current param: encoder.layer4.0.downsample.0.weight
	pretrained param: encoder.layer4.0.downsample.1.weight -> current param: encoder.layer4.0.downsample.1.weight
	pretrained param: encoder.layer4.0.downsample.1.bias -> current param: encoder.layer4.0.downsample.1.bias
	pretrained param: encoder.layer4.0.downsample.1.running_mean -> current param: encoder.layer4.0.downsample.1.running_mean
	pretrained param: encoder.layer4.0.downsample.1.running_var -> current param: encoder.layer4.0.downsample.1.running_var
	pretrained param: encoder.layer4.0.downsample.1.num_batches_tracked -> current param: encoder.layer4.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv1.weight -> current param: encoder.layer4.1.conv1.weight
	pretrained param: encoder.layer4.1.bn1.weight -> current param: encoder.layer4.1.bn1.weight
	pretrained param: encoder.layer4.1.bn1.bias -> current param: encoder.layer4.1.bn1.bias
	pretrained param: encoder.layer4.1.bn1.running_mean -> current param: encoder.layer4.1.bn1.running_mean
	pretrained param: encoder.layer4.1.bn1.running_var -> current param: encoder.layer4.1.bn1.running_var
	pretrained param: encoder.layer4.1.bn1.num_batches_tracked -> current param: encoder.layer4.1.bn1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv2.weight -> current param: encoder.layer4.1.conv2.weight
	pretrained param: encoder.layer4.1.bn2.weight -> current param: encoder.layer4.1.bn2.weight
	pretrained param: encoder.layer4.1.bn2.bias -> current param: encoder.layer4.1.bn2.bias
	pretrained param: encoder.layer4.1.bn2.running_mean -> current param: encoder.layer4.1.bn2.running_mean
	pretrained param: encoder.layer4.1.bn2.running_var -> current param: encoder.layer4.1.bn2.running_var
	pretrained param: encoder.layer4.1.bn2.num_batches_tracked -> current param: encoder.layer4.1.bn2.num_batches_tracked
	pretrained param: encoder.layer4.1.conv3.weight -> current param: encoder.layer4.1.conv3.weight
	pretrained param: encoder.layer4.1.bn3.weight -> current param: encoder.layer4.1.bn3.weight
	pretrained param: encoder.layer4.1.bn3.bias -> current param: encoder.layer4.1.bn3.bias
	pretrained param: encoder.layer4.1.bn3.running_mean -> current param: encoder.layer4.1.bn3.running_mean
	pretrained param: encoder.layer4.1.bn3.running_var -> current param: encoder.layer4.1.bn3.running_var
	pretrained param: encoder.layer4.1.bn3.num_batches_tracked -> current param: encoder.layer4.1.bn3.num_batches_tracked
	pretrained param: encoder.layer4.2.conv1.weight -> current param: encoder.layer4.2.conv1.weight
	pretrained param: encoder.layer4.2.bn1.weight -> current param: encoder.layer4.2.bn1.weight
	pretrained param: encoder.layer4.2.bn1.bias -> current param: encoder.layer4.2.bn1.bias
	pretrained param: encoder.layer4.2.bn1.running_mean -> current param: encoder.layer4.2.bn1.running_mean
	pretrained param: encoder.layer4.2.bn1.running_var -> current param: encoder.layer4.2.bn1.running_var
	pretrained param: encoder.layer4.2.bn1.num_batches_tracked -> current param: encoder.layer4.2.bn1.num_batches_tracked
	pretrained param: encoder.layer4.2.conv2.weight -> current param: encoder.layer4.2.conv2.weight
	pretrained param: encoder.layer4.2.bn2.weight -> current param: encoder.layer4.2.bn2.weight
	pretrained param: encoder.layer4.2.bn2.bias -> current param: encoder.layer4.2.bn2.bias
	pretrained param: encoder.layer4.2.bn2.running_mean -> current param: encoder.layer4.2.bn2.running_mean
	pretrained param: encoder.layer4.2.bn2.running_var -> current param: encoder.layer4.2.bn2.running_var
	pretrained param: encoder.layer4.2.bn2.num_batches_tracked -> current param: encoder.layer4.2.bn2.num_batches_tracked
	pretrained param: encoder.layer4.2.conv3.weight -> current param: encoder.layer4.2.conv3.weight
	pretrained param: encoder.layer4.2.bn3.weight -> current param: encoder.layer4.2.bn3.weight
	pretrained param: encoder.layer4.2.bn3.bias -> current param: encoder.layer4.2.bn3.bias
	pretrained param: encoder.layer4.2.bn3.running_mean -> current param: encoder.layer4.2.bn3.running_mean
	pretrained param: encoder.layer4.2.bn3.running_var -> current param: encoder.layer4.2.bn3.running_var
	pretrained param: encoder.layer4.2.bn3.num_batches_tracked -> current param: encoder.layer4.2.bn3.num_batches_tracked
	pretrained param: decoder.classify.weight -> current param: decoder.classify.weight
		Ignoring: decoder.classify.weight->decoder.classify.weight (size mismatch)
	pretrained param: decoder.classify.bias -> current param: decoder.classify.bias
90.11% of the model loaded from the pretrained
Total params: 179.77M
Dataset catalyst_h2 is not supported, use default mean stats instead
Training model on the catalyst_h2 dataset
Dataset catalyst_h2 is not supported, use default mean stats instead
[train] Epoch: 0/80 xent: 1.346 softIoU: 8.283 IoU: 0.000 
Execution time: 325.9131148373708

[valid] Epoch: 0/80 xent: 0.373 softIoU: 8.013 IoU: 0.000 
Execution time: 76.59120361600071

[train] Epoch: 1/80 xent: 0.327 softIoU: 8.012 IoU: 0.000 
Execution time: 312.2327777482569

[valid] Epoch: 1/80 xent: 0.373 softIoU: 8.011 IoU: 0.000 
Execution time: 71.92387763690203

[train] Epoch: 2/80 xent: 0.324 softIoU: 8.011 IoU: 0.000 
Execution time: 312.42403873521835

[valid] Epoch: 2/80 xent: 0.373 softIoU: 8.011 IoU: 0.000 
Execution time: 74.3168625952676

[train] Epoch: 3/80 xent: 0.327 softIoU: 8.011 IoU: 0.000 
Execution time: 308.5106318453327

[valid] Epoch: 3/80 xent: 0.374 softIoU: 8.010 IoU: 0.000 
Execution time: 78.70679030008614

[train] Epoch: 4/80 xent: 0.327 softIoU: 8.010 IoU: 0.000 
Execution time: 309.09294363483787

[valid] Epoch: 4/80 xent: 0.372 softIoU: 8.011 IoU: 0.000 
Execution time: 72.02263578400016

[train] Epoch: 5/80 xent: 0.326 softIoU: 8.010 IoU: 0.000 
Execution time: 307.55718280235305

[valid] Epoch: 5/80 xent: 0.372 softIoU: 8.011 IoU: 0.000 
Execution time: 79.55766025092453

[train] Epoch: 6/80 xent: 0.325 softIoU: 8.011 IoU: 0.000 
Execution time: 307.42178169218823

[valid] Epoch: 6/80 xent: 0.371 softIoU: 8.011 IoU: 0.000 
Execution time: 71.20214853296056

[train] Epoch: 7/80 xent: 0.325 softIoU: 8.010 IoU: 0.000 
Execution time: 335.7500264206901

[valid] Epoch: 7/80 xent: 0.371 softIoU: 8.010 IoU: 0.000 
Execution time: 81.00187525711954

[train] Epoch: 8/80 xent: 0.324 softIoU: 8.011 IoU: 0.000 
Execution time: 303.2655281010084

[valid] Epoch: 8/80 xent: 0.371 softIoU: 8.010 IoU: 0.000 
Execution time: 70.91526448260993

[train] Epoch: 9/80 xent: 0.320 softIoU: 8.010 IoU: 0.000 
Execution time: 309.4715362386778

[valid] Epoch: 9/80 xent: 0.370 softIoU: 8.010 IoU: 0.000 
Execution time: 71.0853146170266

[train] Epoch: 10/80 xent: 0.324 softIoU: 8.011 IoU: 0.000 
Execution time: 302.79974890407175

[valid] Epoch: 10/80 xent: 0.369 softIoU: 8.011 IoU: 0.000 
Execution time: 79.82132151443511

[train] Epoch: 11/80 xent: 0.321 softIoU: 8.010 IoU: 0.000 
Execution time: 303.993703159038

[valid] Epoch: 11/80 xent: 0.368 softIoU: 8.010 IoU: 0.000 
Execution time: 79.15705651417375

[train] Epoch: 12/80 xent: 0.319 softIoU: 8.010 IoU: 0.000 
Execution time: 302.1004200000316

[valid] Epoch: 12/80 xent: 0.367 softIoU: 8.010 IoU: 0.000 
Execution time: 80.96704914001748

[train] Epoch: 13/80 xent: 0.321 softIoU: 8.010 IoU: 0.000 
Execution time: 302.28026067791507

[valid] Epoch: 13/80 xent: 0.366 softIoU: 8.010 IoU: 0.000 
Execution time: 71.33117495197803

[train] Epoch: 14/80 xent: 0.320 softIoU: 8.011 IoU: 0.000 
Execution time: 304.61291584791616

[valid] Epoch: 14/80 xent: 0.365 softIoU: 8.010 IoU: 0.000 
Execution time: 71.78225599136204

[train] Epoch: 15/80 xent: 0.320 softIoU: 8.009 IoU: 0.000 
Execution time: 303.4386062519625

[valid] Epoch: 15/80 xent: 0.363 softIoU: 8.010 IoU: 0.000 
Execution time: 70.52851369278505

[train] Epoch: 16/80 xent: 0.318 softIoU: 8.011 IoU: 0.000 
Execution time: 302.97060249419883

[valid] Epoch: 16/80 xent: 0.361 softIoU: 8.010 IoU: 0.000 
Execution time: 79.12763238605112

[train] Epoch: 17/80 xent: 0.311 softIoU: 8.010 IoU: 0.000 
Execution time: 301.9063094551675

[valid] Epoch: 17/80 xent: 0.360 softIoU: 8.009 IoU: 0.000 
Execution time: 72.79256546264514

[train] Epoch: 18/80 xent: 0.314 softIoU: 8.010 IoU: 0.000 
Execution time: 314.73369792476296

[valid] Epoch: 18/80 xent: 0.357 softIoU: 8.009 IoU: 0.000 
Execution time: 71.28266894211993

[train] Epoch: 19/80 xent: 0.312 softIoU: 8.009 IoU: 0.000 
Execution time: 303.11227475712076

[valid] Epoch: 19/80 xent: 0.354 softIoU: 8.009 IoU: 0.000 
Execution time: 71.31212851032615

[train] Epoch: 20/80 xent: 0.308 softIoU: 8.009 IoU: 0.000 
Execution time: 302.91250242991373

[valid] Epoch: 20/80 xent: 0.350 softIoU: 8.009 IoU: 0.000 
Execution time: 70.93180126603693

Saved model at /scratch/sr365/models/catalysth2_mb_4/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-20.pth.tar
[train] Epoch: 21/80 xent: 0.303 softIoU: 8.009 IoU: 0.000 
Execution time: 304.6555417557247

[valid] Epoch: 21/80 xent: 0.346 softIoU: 8.007 IoU: 0.000 
Execution time: 70.43749720184132

[train] Epoch: 22/80 xent: 0.294 softIoU: 8.007 IoU: 0.000 
Execution time: 313.6427098386921

[valid] Epoch: 22/80 xent: 0.336 softIoU: 8.008 IoU: 0.000 
Execution time: 71.84177698520944

[train] Epoch: 23/80 xent: 0.289 softIoU: 8.007 IoU: 0.000 
Execution time: 333.3809577948414

[valid] Epoch: 23/80 xent: 0.324 softIoU: 8.007 IoU: 0.000 
Execution time: 70.40981956990436

[train] Epoch: 24/80 xent: 0.273 softIoU: 8.005 IoU: 0.000 
Execution time: 317.9970775600523

[valid] Epoch: 24/80 xent: 0.301 softIoU: 8.003 IoU: 0.000 
Execution time: 82.04880401492119

[train] Epoch: 25/80 xent: 0.243 softIoU: 7.998 IoU: 0.000 
Execution time: 304.55023221159354

[valid] Epoch: 25/80 xent: 0.246 softIoU: 7.984 IoU: 0.000 
Execution time: 71.07774104597047

[train] Epoch: 26/80 xent: 0.162 softIoU: 7.900 IoU: 0.120 
Execution time: 306.0785078131594

[valid] Epoch: 26/80 xent: 0.136 softIoU: 7.757 IoU: 0.266 
Execution time: 82.38514178618789

[train] Epoch: 27/80 xent: 0.085 softIoU: 7.674 IoU: 0.328 
Execution time: 305.7769516929984

[valid] Epoch: 27/80 xent: 0.082 softIoU: 7.549 IoU: 0.420 
Execution time: 77.77841171808541

[train] Epoch: 28/80 xent: 0.067 softIoU: 7.550 IoU: 0.333 
Execution time: 308.18677076278254

[valid] Epoch: 28/80 xent: 0.066 softIoU: 7.473 IoU: 0.475 
Execution time: 75.09097816981375

[train] Epoch: 29/80 xent: 0.060 softIoU: 7.497 IoU: 0.359 
Execution time: 312.25793084921315

[valid] Epoch: 29/80 xent: 0.064 softIoU: 7.460 IoU: 0.514 
Execution time: 73.24759599426761

[train] Epoch: 30/80 xent: 0.057 softIoU: 7.466 IoU: 0.380 
Execution time: 307.3772810357623

[valid] Epoch: 30/80 xent: 0.055 softIoU: 7.434 IoU: 0.545 
Execution time: 68.60656937211752

[train] Epoch: 31/80 xent: 0.057 softIoU: 7.454 IoU: 0.391 
Execution time: 297.53512520715594

[valid] Epoch: 31/80 xent: 0.058 softIoU: 7.454 IoU: 0.516 
Execution time: 72.11220284365118

[train] Epoch: 32/80 xent: 0.057 softIoU: 7.448 IoU: 0.384 
Execution time: 295.48723620781675

[valid] Epoch: 32/80 xent: 0.057 softIoU: 7.443 IoU: 0.528 
Execution time: 70.70399269508198

[train] Epoch: 33/80 xent: 0.049 softIoU: 7.416 IoU: 0.465 
Execution time: 295.78891572216526

[valid] Epoch: 33/80 xent: 0.051 softIoU: 7.388 IoU: 0.547 
Execution time: 69.12580366432667

[train] Epoch: 34/80 xent: 0.051 softIoU: 7.425 IoU: 0.442 
Execution time: 304.3259316738695

[valid] Epoch: 34/80 xent: 0.049 softIoU: 7.392 IoU: 0.570 
Execution time: 68.46311736898497

[train] Epoch: 35/80 xent: 0.051 softIoU: 7.417 IoU: 0.466 
Execution time: 299.8227522117086

[valid] Epoch: 35/80 xent: 0.048 softIoU: 7.384 IoU: 0.569 
Execution time: 68.35569250164554

[train] Epoch: 36/80 xent: 0.044 softIoU: 7.380 IoU: 0.518 
Execution time: 305.2737058349885

[valid] Epoch: 36/80 xent: 0.048 softIoU: 7.386 IoU: 0.576 
Execution time: 69.59875658201054

[train] Epoch: 37/80 xent: 0.046 softIoU: 7.376 IoU: 0.467 
Execution time: 286.3339735730551

[valid] Epoch: 37/80 xent: 0.049 softIoU: 7.367 IoU: 0.526 
Execution time: 67.1332131261006

[train] Epoch: 38/80 xent: 0.045 softIoU: 7.377 IoU: 0.483 
Execution time: 292.4131328118965

[valid] Epoch: 38/80 xent: 0.062 softIoU: 7.437 IoU: 0.537 
Execution time: 66.60973002808169

[train] Epoch: 39/80 xent: 0.047 softIoU: 7.393 IoU: 0.479 
Execution time: 287.6806983961724

[valid] Epoch: 39/80 xent: 0.044 softIoU: 7.381 IoU: 0.590 
Execution time: 65.83563143294305

[train] Epoch: 40/80 xent: 0.041 softIoU: 7.381 IoU: 0.506 
Execution time: 287.4467833880335

[valid] Epoch: 40/80 xent: 0.044 softIoU: 7.381 IoU: 0.587 
Execution time: 66.85018922993913

Saved model at /scratch/sr365/models/catalysth2_mb_4/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-40.pth.tar
[train] Epoch: 41/80 xent: 0.040 softIoU: 7.397 IoU: 0.546 
Execution time: 286.15111128007993

[valid] Epoch: 41/80 xent: 0.045 softIoU: 7.382 IoU: 0.590 
Execution time: 66.43063965905458

[train] Epoch: 42/80 xent: 0.045 softIoU: 7.388 IoU: 0.503 
Execution time: 288.0691228671931

[valid] Epoch: 42/80 xent: 0.045 softIoU: 7.375 IoU: 0.585 
Execution time: 66.21451863832772

[train] Epoch: 43/80 xent: 0.040 softIoU: 7.386 IoU: 0.542 
Execution time: 288.0538123338483

[valid] Epoch: 43/80 xent: 0.044 softIoU: 7.376 IoU: 0.589 
Execution time: 66.14147078199312

[train] Epoch: 44/80 xent: 0.041 softIoU: 7.381 IoU: 0.525 
Execution time: 289.3902120469138

[valid] Epoch: 44/80 xent: 0.044 softIoU: 7.376 IoU: 0.587 
Execution time: 67.31296231411397

[train] Epoch: 45/80 xent: 0.041 softIoU: 7.389 IoU: 0.531 
Execution time: 287.83944532321766

[valid] Epoch: 45/80 xent: 0.045 softIoU: 7.373 IoU: 0.584 
Execution time: 66.92770165530965

[train] Epoch: 46/80 xent: 0.043 softIoU: 7.384 IoU: 0.523 
Execution time: 287.36080021597445

[valid] Epoch: 46/80 xent: 0.044 softIoU: 7.376 IoU: 0.587 
Execution time: 66.51646433118731

[train] Epoch: 47/80 xent: 0.042 softIoU: 7.393 IoU: 0.503 
Execution time: 286.6736450227909

[valid] Epoch: 47/80 xent: 0.044 softIoU: 7.377 IoU: 0.588 
Execution time: 66.71986168203875

[train] Epoch: 48/80 xent: 0.042 softIoU: 7.411 IoU: 0.527 
Execution time: 288.5192805249244

[valid] Epoch: 48/80 xent: 0.044 softIoU: 7.372 IoU: 0.586 
Execution time: 66.75392556097358

[train] Epoch: 49/80 xent: 0.041 softIoU: 7.392 IoU: 0.534 
Execution time: 287.6451923260465

[valid] Epoch: 49/80 xent: 0.044 softIoU: 7.372 IoU: 0.587 
Execution time: 67.55259510036558

[train] Epoch: 50/80 xent: 0.038 softIoU: 7.368 IoU: 0.552 
Execution time: 287.0001991800964

[valid] Epoch: 50/80 xent: 0.044 softIoU: 7.377 IoU: 0.584 
Execution time: 67.14016083301976

[train] Epoch: 51/80 xent: 0.042 softIoU: 7.375 IoU: 0.520 
Execution time: 287.8259062161669

[valid] Epoch: 51/80 xent: 0.042 softIoU: 7.368 IoU: 0.592 
Execution time: 66.79563222592697

[train] Epoch: 52/80 xent: 0.037 softIoU: 7.389 IoU: 0.558 
Execution time: 288.42851171595976

[valid] Epoch: 52/80 xent: 0.043 softIoU: 7.376 IoU: 0.589 
Execution time: 66.73661627434194

[train] Epoch: 53/80 xent: 0.040 softIoU: 7.388 IoU: 0.516 
Execution time: 285.4037403143011

[valid] Epoch: 53/80 xent: 0.045 softIoU: 7.387 IoU: 0.586 
Execution time: 66.4168079230003

[train] Epoch: 54/80 xent: 0.042 softIoU: 7.378 IoU: 0.498 
Execution time: 288.03778087114915

[valid] Epoch: 54/80 xent: 0.043 softIoU: 7.370 IoU: 0.591 
Execution time: 66.40626609604806

[train] Epoch: 55/80 xent: 0.040 softIoU: 7.381 IoU: 0.528 
Execution time: 286.982043127995

[valid] Epoch: 55/80 xent: 0.044 softIoU: 7.382 IoU: 0.590 
Execution time: 66.70584703888744

[train] Epoch: 56/80 xent: 0.042 softIoU: 7.376 IoU: 0.517 
Execution time: 287.11958134081215

[valid] Epoch: 56/80 xent: 0.044 softIoU: 7.379 IoU: 0.586 
Execution time: 70.93230552319437

[train] Epoch: 57/80 xent: 0.040 softIoU: 7.380 IoU: 0.531 
Execution time: 298.692763350904

[valid] Epoch: 57/80 xent: 0.043 softIoU: 7.380 IoU: 0.590 
Execution time: 69.28943539690226

[train] Epoch: 58/80 xent: 0.037 softIoU: 7.372 IoU: 0.563 
Execution time: 297.4758098931052

[valid] Epoch: 58/80 xent: 0.042 softIoU: 7.375 IoU: 0.594 
Execution time: 70.64672097936273

[train] Epoch: 59/80 xent: 0.039 softIoU: 7.369 IoU: 0.525 
Execution time: 300.57295262115076

[valid] Epoch: 59/80 xent: 0.043 softIoU: 7.378 IoU: 0.594 
Execution time: 71.02041424578056

[train] Epoch: 60/80 xent: 0.041 softIoU: 7.385 IoU: 0.538 
Execution time: 290.0787654221058

[valid] Epoch: 60/80 xent: 0.043 softIoU: 7.377 IoU: 0.595 
Execution time: 68.24578763870522

Saved model at /scratch/sr365/models/catalysth2_mb_4/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-60.pth.tar
[train] Epoch: 61/80 xent: 0.040 softIoU: 7.376 IoU: 0.499 
Execution time: 287.4216987118125

[valid] Epoch: 61/80 xent: 0.042 softIoU: 7.374 IoU: 0.596 
Execution time: 66.79884033091366

[train] Epoch: 62/80 xent: 0.039 softIoU: 7.388 IoU: 0.528 
Execution time: 285.8828691090457

[valid] Epoch: 62/80 xent: 0.043 softIoU: 7.378 IoU: 0.594 
Execution time: 67.4671204010956

[train] Epoch: 63/80 xent: 0.041 softIoU: 7.387 IoU: 0.548 
Execution time: 289.6734816050157

[valid] Epoch: 63/80 xent: 0.044 softIoU: 7.380 IoU: 0.594 
Execution time: 66.03379391785711

[train] Epoch: 64/80 xent: 0.038 softIoU: 7.378 IoU: 0.535 
Execution time: 286.83052577404305

[valid] Epoch: 64/80 xent: 0.042 softIoU: 7.377 IoU: 0.594 
Execution time: 66.78068475611508

[train] Epoch: 65/80 xent: 0.040 softIoU: 7.406 IoU: 0.518 
Execution time: 285.62123225582764

[valid] Epoch: 65/80 xent: 0.044 softIoU: 7.379 IoU: 0.587 
Execution time: 66.70316699985415

[train] Epoch: 66/80 xent: 0.041 softIoU: 7.389 IoU: 0.513 
Execution time: 284.95579619612545

[valid] Epoch: 66/80 xent: 0.042 softIoU: 7.369 IoU: 0.592 
Execution time: 66.69258608389646

[train] Epoch: 67/80 xent: 0.038 softIoU: 7.369 IoU: 0.535 
Execution time: 285.11181596899405

[valid] Epoch: 67/80 xent: 0.043 softIoU: 7.376 IoU: 0.591 
Execution time: 66.98519445490092

[train] Epoch: 68/80 xent: 0.038 softIoU: 7.392 IoU: 0.544 
Execution time: 288.1524461838417

[valid] Epoch: 68/80 xent: 0.043 softIoU: 7.372 IoU: 0.595 
Execution time: 66.0081704990007

[train] Epoch: 69/80 xent: 0.040 softIoU: 7.393 IoU: 0.529 
Execution time: 287.379453569185

[valid] Epoch: 69/80 xent: 0.042 softIoU: 7.366 IoU: 0.591 
Execution time: 67.7183654140681

[train] Epoch: 70/80 xent: 0.038 softIoU: 7.389 IoU: 0.549 
Execution time: 287.2511354559101

[valid] Epoch: 70/80 xent: 0.043 softIoU: 7.379 IoU: 0.590 
Execution time: 66.87870901590213

[train] Epoch: 71/80 xent: 0.039 softIoU: 7.391 IoU: 0.531 
Execution time: 286.73861339781433

[valid] Epoch: 71/80 xent: 0.042 softIoU: 7.374 IoU: 0.595 
Execution time: 66.39188435813412

[train] Epoch: 72/80 xent: 0.037 softIoU: 7.375 IoU: 0.505 
Execution time: 287.2269647549838

[valid] Epoch: 72/80 xent: 0.044 softIoU: 7.375 IoU: 0.589 
Execution time: 66.58702003676444

[train] Epoch: 73/80 xent: 0.036 softIoU: 7.375 IoU: 0.538 
Execution time: 293.0491320453584

[valid] Epoch: 73/80 xent: 0.045 softIoU: 7.389 IoU: 0.590 
Execution time: 79.27766080060974

[train] Epoch: 74/80 xent: 0.040 softIoU: 7.384 IoU: 0.540 
Execution time: 323.101626500953

[valid] Epoch: 74/80 xent: 0.044 softIoU: 7.383 IoU: 0.590 
Execution time: 80.78517167363316

[train] Epoch: 75/80 xent: 0.038 softIoU: 7.341 IoU: 0.537 
Execution time: 319.343283619266

[valid] Epoch: 75/80 xent: 0.042 softIoU: 7.372 IoU: 0.593 
Execution time: 73.00591349508613

[train] Epoch: 76/80 xent: 0.040 softIoU: 7.363 IoU: 0.538 
Execution time: 315.83389760321006

[valid] Epoch: 76/80 xent: 0.042 softIoU: 7.371 IoU: 0.591 
Execution time: 77.58026960259303

[train] Epoch: 77/80 xent: 0.039 softIoU: 7.380 IoU: 0.542 
Execution time: 307.8828147300519

[valid] Epoch: 77/80 xent: 0.044 softIoU: 7.378 IoU: 0.587 
Execution time: 70.92993591632694

[train] Epoch: 78/80 xent: 0.038 softIoU: 7.378 IoU: 0.547 
Execution time: 310.888435007073

[valid] Epoch: 78/80 xent: 0.043 softIoU: 7.378 IoU: 0.593 
Execution time: 66.87924194708467

[train] Epoch: 79/80 xent: 0.041 softIoU: 7.353 IoU: 0.528 
Execution time: 288.347922203131

[valid] Epoch: 79/80 xent: 0.042 softIoU: 7.371 IoU: 0.595 
Execution time: 68.32832904811949

Saved model at /scratch/sr365/models/catalysth2_mb_4/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-80.pth.tar
Device being used: cuda:1
Finetuning model from /scratch/wh145/models/solarmapper_final/ct/epoch-80.pth.tar
Warning: The following parameters in the pretrained model does not exist in the current model
	 decoder.uc.0.up_conv.weight
	 decoder.uc.0.up_conv.bias
	 decoder.uc.0.conv_1.weight
	 decoder.uc.0.conv_1.bias
	 decoder.uc.0.conv_2.weight
	 decoder.uc.0.conv_2.bias
	 decoder.uc.0.bn_1.weight
	 decoder.uc.0.bn_1.bias
	 decoder.uc.0.bn_1.running_mean
	 decoder.uc.0.bn_1.running_var
	 decoder.uc.0.bn_1.num_batches_tracked
	 decoder.uc.0.bn_2.weight
	 decoder.uc.0.bn_2.bias
	 decoder.uc.0.bn_2.running_mean
	 decoder.uc.0.bn_2.running_var
	 decoder.uc.0.bn_2.num_batches_tracked
	 decoder.uc.0.act.weight
	 decoder.uc.1.up_conv.weight
	 decoder.uc.1.up_conv.bias
	 decoder.uc.1.conv_1.weight
	 decoder.uc.1.conv_1.bias
	 decoder.uc.1.conv_2.weight
	 decoder.uc.1.conv_2.bias
	 decoder.uc.1.bn_1.weight
	 decoder.uc.1.bn_1.bias
	 decoder.uc.1.bn_1.running_mean
	 decoder.uc.1.bn_1.running_var
	 decoder.uc.1.bn_1.num_batches_tracked
	 decoder.uc.1.bn_2.weight
	 decoder.uc.1.bn_2.bias
	 decoder.uc.1.bn_2.running_mean
	 decoder.uc.1.bn_2.running_var
	 decoder.uc.1.bn_2.num_batches_tracked
	 decoder.uc.1.act.weight
	 decoder.uc.2.up_conv.weight
	 decoder.uc.2.up_conv.bias
	 decoder.uc.2.conv_1.weight
	 decoder.uc.2.conv_1.bias
	 decoder.uc.2.conv_2.weight
	 decoder.uc.2.conv_2.bias
	 decoder.uc.2.bn_1.weight
	 decoder.uc.2.bn_1.bias
	 decoder.uc.2.bn_1.running_mean
	 decoder.uc.2.bn_1.running_var
	 decoder.uc.2.bn_1.num_batches_tracked
	 decoder.uc.2.bn_2.weight
	 decoder.uc.2.bn_2.bias
	 decoder.uc.2.bn_2.running_mean
	 decoder.uc.2.bn_2.running_var
	 decoder.uc.2.bn_2.num_batches_tracked
	 decoder.uc.2.act.weight
	 decoder.uc.3.up_conv.weight
	 decoder.uc.3.up_conv.bias
	 decoder.uc.3.conv_1.weight
	 decoder.uc.3.conv_1.bias
	 decoder.uc.3.conv_2.weight
	 decoder.uc.3.conv_2.bias
	 decoder.uc.3.bn_1.weight
	 decoder.uc.3.bn_1.bias
	 decoder.uc.3.bn_1.running_mean
	 decoder.uc.3.bn_1.running_var
	 decoder.uc.3.bn_1.num_batches_tracked
	 decoder.uc.3.bn_2.weight
	 decoder.uc.3.bn_2.bias
	 decoder.uc.3.bn_2.running_mean
	 decoder.uc.3.bn_2.running_var
	 decoder.uc.3.bn_2.num_batches_tracked
	 decoder.uc.3.act.weight
Warning: The following parameters in the current model does not exist in the pretrained model
	 decoder.center_dilation.dconv_1.weight
	 decoder.center_dilation.dconv_1.bias
	 decoder.center_dilation.dconv_2.weight
	 decoder.center_dilation.dconv_2.bias
	 decoder.center_dilation.dconv_3.weight
	 decoder.center_dilation.dconv_3.bias
	 decoder.center_dilation.dconv_4.weight
	 decoder.center_dilation.dconv_4.bias
	 decoder.upsample_1.conv1.weight
	 decoder.upsample_1.conv1.bias
	 decoder.upsample_1.tconv.weight
	 decoder.upsample_1.tconv.bias
	 decoder.upsample_1.conv2.weight
	 decoder.upsample_1.conv2.bias
	 decoder.upsample_2.conv1.weight
	 decoder.upsample_2.conv1.bias
	 decoder.upsample_2.tconv.weight
	 decoder.upsample_2.tconv.bias
	 decoder.upsample_2.conv2.weight
	 decoder.upsample_2.conv2.bias
	 decoder.upsample_3.conv1.weight
	 decoder.upsample_3.conv1.bias
	 decoder.upsample_3.tconv.weight
	 decoder.upsample_3.tconv.bias
	 decoder.upsample_3.conv2.weight
	 decoder.upsample_3.conv2.bias
	 decoder.upsample_4.conv1.weight
	 decoder.upsample_4.conv1.bias
	 decoder.upsample_4.tconv.weight
	 decoder.upsample_4.tconv.bias
	 decoder.upsample_4.conv2.weight
	 decoder.upsample_4.conv2.bias
	 decoder.tconv.weight
	 decoder.tconv.bias
Warning: The size of the following parameters in the current model does not match the ones in the pretrained model
	 decoder.classify.weight
Try loading with relaxed naming rule:
Prefix in pretrained model 
	pretrained param: encoder.conv1.weight -> current param: encoder.conv1.weight
	pretrained param: encoder.bn1.weight -> current param: encoder.bn1.weight
	pretrained param: encoder.bn1.bias -> current param: encoder.bn1.bias
	pretrained param: encoder.bn1.running_mean -> current param: encoder.bn1.running_mean
	pretrained param: encoder.bn1.running_var -> current param: encoder.bn1.running_var
	pretrained param: encoder.bn1.num_batches_tracked -> current param: encoder.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv1.weight -> current param: encoder.layer1.0.conv1.weight
	pretrained param: encoder.layer1.0.bn1.weight -> current param: encoder.layer1.0.bn1.weight
	pretrained param: encoder.layer1.0.bn1.bias -> current param: encoder.layer1.0.bn1.bias
	pretrained param: encoder.layer1.0.bn1.running_mean -> current param: encoder.layer1.0.bn1.running_mean
	pretrained param: encoder.layer1.0.bn1.running_var -> current param: encoder.layer1.0.bn1.running_var
	pretrained param: encoder.layer1.0.bn1.num_batches_tracked -> current param: encoder.layer1.0.bn1.num_batches_tracked
	pretrained param: encoder.layer1.0.conv2.weight -> current param: encoder.layer1.0.conv2.weight
	pretrained param: encoder.layer1.0.bn2.weight -> current param: encoder.layer1.0.bn2.weight
	pretrained param: encoder.layer1.0.bn2.bias -> current param: encoder.layer1.0.bn2.bias
	pretrained param: encoder.layer1.0.bn2.running_mean -> current param: encoder.layer1.0.bn2.running_mean
	pretrained param: encoder.layer1.0.bn2.running_var -> current param: encoder.layer1.0.bn2.running_var
	pretrained param: encoder.layer1.0.bn2.num_batches_tracked -> current param: encoder.layer1.0.bn2.num_batches_tracked
	pretrained param: encoder.layer1.0.conv3.weight -> current param: encoder.layer1.0.conv3.weight
	pretrained param: encoder.layer1.0.bn3.weight -> current param: encoder.layer1.0.bn3.weight
	pretrained param: encoder.layer1.0.bn3.bias -> current param: encoder.layer1.0.bn3.bias
	pretrained param: encoder.layer1.0.bn3.running_mean -> current param: encoder.layer1.0.bn3.running_mean
	pretrained param: encoder.layer1.0.bn3.running_var -> current param: encoder.layer1.0.bn3.running_var
	pretrained param: encoder.layer1.0.bn3.num_batches_tracked -> current param: encoder.layer1.0.bn3.num_batches_tracked
	pretrained param: encoder.layer1.0.downsample.0.weight -> current param: encoder.layer1.0.downsample.0.weight
	pretrained param: encoder.layer1.0.downsample.1.weight -> current param: encoder.layer1.0.downsample.1.weight
	pretrained param: encoder.layer1.0.downsample.1.bias -> current param: encoder.layer1.0.downsample.1.bias
	pretrained param: encoder.layer1.0.downsample.1.running_mean -> current param: encoder.layer1.0.downsample.1.running_mean
	pretrained param: encoder.layer1.0.downsample.1.running_var -> current param: encoder.layer1.0.downsample.1.running_var
	pretrained param: encoder.layer1.0.downsample.1.num_batches_tracked -> current param: encoder.layer1.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv1.weight -> current param: encoder.layer1.1.conv1.weight
	pretrained param: encoder.layer1.1.bn1.weight -> current param: encoder.layer1.1.bn1.weight
	pretrained param: encoder.layer1.1.bn1.bias -> current param: encoder.layer1.1.bn1.bias
	pretrained param: encoder.layer1.1.bn1.running_mean -> current param: encoder.layer1.1.bn1.running_mean
	pretrained param: encoder.layer1.1.bn1.running_var -> current param: encoder.layer1.1.bn1.running_var
	pretrained param: encoder.layer1.1.bn1.num_batches_tracked -> current param: encoder.layer1.1.bn1.num_batches_tracked
	pretrained param: encoder.layer1.1.conv2.weight -> current param: encoder.layer1.1.conv2.weight
	pretrained param: encoder.layer1.1.bn2.weight -> current param: encoder.layer1.1.bn2.weight
	pretrained param: encoder.layer1.1.bn2.bias -> current param: encoder.layer1.1.bn2.bias
	pretrained param: encoder.layer1.1.bn2.running_mean -> current param: encoder.layer1.1.bn2.running_mean
	pretrained param: encoder.layer1.1.bn2.running_var -> current param: encoder.layer1.1.bn2.running_var
	pretrained param: encoder.layer1.1.bn2.num_batches_tracked -> current param: encoder.layer1.1.bn2.num_batches_tracked
	pretrained param: encoder.layer1.1.conv3.weight -> current param: encoder.layer1.1.conv3.weight
	pretrained param: encoder.layer1.1.bn3.weight -> current param: encoder.layer1.1.bn3.weight
	pretrained param: encoder.layer1.1.bn3.bias -> current param: encoder.layer1.1.bn3.bias
	pretrained param: encoder.layer1.1.bn3.running_mean -> current param: encoder.layer1.1.bn3.running_mean
	pretrained param: encoder.layer1.1.bn3.running_var -> current param: encoder.layer1.1.bn3.running_var
	pretrained param: encoder.layer1.1.bn3.num_batches_tracked -> current param: encoder.layer1.1.bn3.num_batches_tracked
	pretrained param: encoder.layer1.2.conv1.weight -> current param: encoder.layer1.2.conv1.weight
	pretrained param: encoder.layer1.2.bn1.weight -> current param: encoder.layer1.2.bn1.weight
	pretrained param: encoder.layer1.2.bn1.bias -> current param: encoder.layer1.2.bn1.bias
	pretrained param: encoder.layer1.2.bn1.running_mean -> current param: encoder.layer1.2.bn1.running_mean
	pretrained param: encoder.layer1.2.bn1.running_var -> current param: encoder.layer1.2.bn1.running_var
	pretrained param: encoder.layer1.2.bn1.num_batches_tracked -> current param: encoder.layer1.2.bn1.num_batches_tracked
	pretrained param: encoder.layer1.2.conv2.weight -> current param: encoder.layer1.2.conv2.weight
	pretrained param: encoder.layer1.2.bn2.weight -> current param: encoder.layer1.2.bn2.weight
	pretrained param: encoder.layer1.2.bn2.bias -> current param: encoder.layer1.2.bn2.bias
	pretrained param: encoder.layer1.2.bn2.running_mean -> current param: encoder.layer1.2.bn2.running_mean
	pretrained param: encoder.layer1.2.bn2.running_var -> current param: encoder.layer1.2.bn2.running_var
	pretrained param: encoder.layer1.2.bn2.num_batches_tracked -> current param: encoder.layer1.2.bn2.num_batches_tracked
	pretrained param: encoder.layer1.2.conv3.weight -> current param: encoder.layer1.2.conv3.weight
	pretrained param: encoder.layer1.2.bn3.weight -> current param: encoder.layer1.2.bn3.weight
	pretrained param: encoder.layer1.2.bn3.bias -> current param: encoder.layer1.2.bn3.bias
	pretrained param: encoder.layer1.2.bn3.running_mean -> current param: encoder.layer1.2.bn3.running_mean
	pretrained param: encoder.layer1.2.bn3.running_var -> current param: encoder.layer1.2.bn3.running_var
	pretrained param: encoder.layer1.2.bn3.num_batches_tracked -> current param: encoder.layer1.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.conv1.weight -> current param: encoder.layer2.0.conv1.weight
	pretrained param: encoder.layer2.0.bn1.weight -> current param: encoder.layer2.0.bn1.weight
	pretrained param: encoder.layer2.0.bn1.bias -> current param: encoder.layer2.0.bn1.bias
	pretrained param: encoder.layer2.0.bn1.running_mean -> current param: encoder.layer2.0.bn1.running_mean
	pretrained param: encoder.layer2.0.bn1.running_var -> current param: encoder.layer2.0.bn1.running_var
	pretrained param: encoder.layer2.0.bn1.num_batches_tracked -> current param: encoder.layer2.0.bn1.num_batches_tracked
	pretrained param: encoder.layer2.0.conv2.weight -> current param: encoder.layer2.0.conv2.weight
	pretrained param: encoder.layer2.0.bn2.weight -> current param: encoder.layer2.0.bn2.weight
	pretrained param: encoder.layer2.0.bn2.bias -> current param: encoder.layer2.0.bn2.bias
	pretrained param: encoder.layer2.0.bn2.running_mean -> current param: encoder.layer2.0.bn2.running_mean
	pretrained param: encoder.layer2.0.bn2.running_var -> current param: encoder.layer2.0.bn2.running_var
	pretrained param: encoder.layer2.0.bn2.num_batches_tracked -> current param: encoder.layer2.0.bn2.num_batches_tracked
	pretrained param: encoder.layer2.0.conv3.weight -> current param: encoder.layer2.0.conv3.weight
	pretrained param: encoder.layer2.0.bn3.weight -> current param: encoder.layer2.0.bn3.weight
	pretrained param: encoder.layer2.0.bn3.bias -> current param: encoder.layer2.0.bn3.bias
	pretrained param: encoder.layer2.0.bn3.running_mean -> current param: encoder.layer2.0.bn3.running_mean
	pretrained param: encoder.layer2.0.bn3.running_var -> current param: encoder.layer2.0.bn3.running_var
	pretrained param: encoder.layer2.0.bn3.num_batches_tracked -> current param: encoder.layer2.0.bn3.num_batches_tracked
	pretrained param: encoder.layer2.0.downsample.0.weight -> current param: encoder.layer2.0.downsample.0.weight
	pretrained param: encoder.layer2.0.downsample.1.weight -> current param: encoder.layer2.0.downsample.1.weight
	pretrained param: encoder.layer2.0.downsample.1.bias -> current param: encoder.layer2.0.downsample.1.bias
	pretrained param: encoder.layer2.0.downsample.1.running_mean -> current param: encoder.layer2.0.downsample.1.running_mean
	pretrained param: encoder.layer2.0.downsample.1.running_var -> current param: encoder.layer2.0.downsample.1.running_var
	pretrained param: encoder.layer2.0.downsample.1.num_batches_tracked -> current param: encoder.layer2.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv1.weight -> current param: encoder.layer2.1.conv1.weight
	pretrained param: encoder.layer2.1.bn1.weight -> current param: encoder.layer2.1.bn1.weight
	pretrained param: encoder.layer2.1.bn1.bias -> current param: encoder.layer2.1.bn1.bias
	pretrained param: encoder.layer2.1.bn1.running_mean -> current param: encoder.layer2.1.bn1.running_mean
	pretrained param: encoder.layer2.1.bn1.running_var -> current param: encoder.layer2.1.bn1.running_var
	pretrained param: encoder.layer2.1.bn1.num_batches_tracked -> current param: encoder.layer2.1.bn1.num_batches_tracked
	pretrained param: encoder.layer2.1.conv2.weight -> current param: encoder.layer2.1.conv2.weight
	pretrained param: encoder.layer2.1.bn2.weight -> current param: encoder.layer2.1.bn2.weight
	pretrained param: encoder.layer2.1.bn2.bias -> current param: encoder.layer2.1.bn2.bias
	pretrained param: encoder.layer2.1.bn2.running_mean -> current param: encoder.layer2.1.bn2.running_mean
	pretrained param: encoder.layer2.1.bn2.running_var -> current param: encoder.layer2.1.bn2.running_var
	pretrained param: encoder.layer2.1.bn2.num_batches_tracked -> current param: encoder.layer2.1.bn2.num_batches_tracked
	pretrained param: encoder.layer2.1.conv3.weight -> current param: encoder.layer2.1.conv3.weight
	pretrained param: encoder.layer2.1.bn3.weight -> current param: encoder.layer2.1.bn3.weight
	pretrained param: encoder.layer2.1.bn3.bias -> current param: encoder.layer2.1.bn3.bias
	pretrained param: encoder.layer2.1.bn3.running_mean -> current param: encoder.layer2.1.bn3.running_mean
	pretrained param: encoder.layer2.1.bn3.running_var -> current param: encoder.layer2.1.bn3.running_var
	pretrained param: encoder.layer2.1.bn3.num_batches_tracked -> current param: encoder.layer2.1.bn3.num_batches_tracked
	pretrained param: encoder.layer2.2.conv1.weight -> current param: encoder.layer2.2.conv1.weight
	pretrained param: encoder.layer2.2.bn1.weight -> current param: encoder.layer2.2.bn1.weight
	pretrained param: encoder.layer2.2.bn1.bias -> current param: encoder.layer2.2.bn1.bias
	pretrained param: encoder.layer2.2.bn1.running_mean -> current param: encoder.layer2.2.bn1.running_mean
	pretrained param: encoder.layer2.2.bn1.running_var -> current param: encoder.layer2.2.bn1.running_var
	pretrained param: encoder.layer2.2.bn1.num_batches_tracked -> current param: encoder.layer2.2.bn1.num_batches_tracked
	pretrained param: encoder.layer2.2.conv2.weight -> current param: encoder.layer2.2.conv2.weight
	pretrained param: encoder.layer2.2.bn2.weight -> current param: encoder.layer2.2.bn2.weight
	pretrained param: encoder.layer2.2.bn2.bias -> current param: encoder.layer2.2.bn2.bias
	pretrained param: encoder.layer2.2.bn2.running_mean -> current param: encoder.layer2.2.bn2.running_mean
	pretrained param: encoder.layer2.2.bn2.running_var -> current param: encoder.layer2.2.bn2.running_var
	pretrained param: encoder.layer2.2.bn2.num_batches_tracked -> current param: encoder.layer2.2.bn2.num_batches_tracked
	pretrained param: encoder.layer2.2.conv3.weight -> current param: encoder.layer2.2.conv3.weight
	pretrained param: encoder.layer2.2.bn3.weight -> current param: encoder.layer2.2.bn3.weight
	pretrained param: encoder.layer2.2.bn3.bias -> current param: encoder.layer2.2.bn3.bias
	pretrained param: encoder.layer2.2.bn3.running_mean -> current param: encoder.layer2.2.bn3.running_mean
	pretrained param: encoder.layer2.2.bn3.running_var -> current param: encoder.layer2.2.bn3.running_var
	pretrained param: encoder.layer2.2.bn3.num_batches_tracked -> current param: encoder.layer2.2.bn3.num_batches_tracked
	pretrained param: encoder.layer2.3.conv1.weight -> current param: encoder.layer2.3.conv1.weight
	pretrained param: encoder.layer2.3.bn1.weight -> current param: encoder.layer2.3.bn1.weight
	pretrained param: encoder.layer2.3.bn1.bias -> current param: encoder.layer2.3.bn1.bias
	pretrained param: encoder.layer2.3.bn1.running_mean -> current param: encoder.layer2.3.bn1.running_mean
	pretrained param: encoder.layer2.3.bn1.running_var -> current param: encoder.layer2.3.bn1.running_var
	pretrained param: encoder.layer2.3.bn1.num_batches_tracked -> current param: encoder.layer2.3.bn1.num_batches_tracked
	pretrained param: encoder.layer2.3.conv2.weight -> current param: encoder.layer2.3.conv2.weight
	pretrained param: encoder.layer2.3.bn2.weight -> current param: encoder.layer2.3.bn2.weight
	pretrained param: encoder.layer2.3.bn2.bias -> current param: encoder.layer2.3.bn2.bias
	pretrained param: encoder.layer2.3.bn2.running_mean -> current param: encoder.layer2.3.bn2.running_mean
	pretrained param: encoder.layer2.3.bn2.running_var -> current param: encoder.layer2.3.bn2.running_var
	pretrained param: encoder.layer2.3.bn2.num_batches_tracked -> current param: encoder.layer2.3.bn2.num_batches_tracked
	pretrained param: encoder.layer2.3.conv3.weight -> current param: encoder.layer2.3.conv3.weight
	pretrained param: encoder.layer2.3.bn3.weight -> current param: encoder.layer2.3.bn3.weight
	pretrained param: encoder.layer2.3.bn3.bias -> current param: encoder.layer2.3.bn3.bias
	pretrained param: encoder.layer2.3.bn3.running_mean -> current param: encoder.layer2.3.bn3.running_mean
	pretrained param: encoder.layer2.3.bn3.running_var -> current param: encoder.layer2.3.bn3.running_var
	pretrained param: encoder.layer2.3.bn3.num_batches_tracked -> current param: encoder.layer2.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.conv1.weight -> current param: encoder.layer3.0.conv1.weight
	pretrained param: encoder.layer3.0.bn1.weight -> current param: encoder.layer3.0.bn1.weight
	pretrained param: encoder.layer3.0.bn1.bias -> current param: encoder.layer3.0.bn1.bias
	pretrained param: encoder.layer3.0.bn1.running_mean -> current param: encoder.layer3.0.bn1.running_mean
	pretrained param: encoder.layer3.0.bn1.running_var -> current param: encoder.layer3.0.bn1.running_var
	pretrained param: encoder.layer3.0.bn1.num_batches_tracked -> current param: encoder.layer3.0.bn1.num_batches_tracked
	pretrained param: encoder.layer3.0.conv2.weight -> current param: encoder.layer3.0.conv2.weight
	pretrained param: encoder.layer3.0.bn2.weight -> current param: encoder.layer3.0.bn2.weight
	pretrained param: encoder.layer3.0.bn2.bias -> current param: encoder.layer3.0.bn2.bias
	pretrained param: encoder.layer3.0.bn2.running_mean -> current param: encoder.layer3.0.bn2.running_mean
	pretrained param: encoder.layer3.0.bn2.running_var -> current param: encoder.layer3.0.bn2.running_var
	pretrained param: encoder.layer3.0.bn2.num_batches_tracked -> current param: encoder.layer3.0.bn2.num_batches_tracked
	pretrained param: encoder.layer3.0.conv3.weight -> current param: encoder.layer3.0.conv3.weight
	pretrained param: encoder.layer3.0.bn3.weight -> current param: encoder.layer3.0.bn3.weight
	pretrained param: encoder.layer3.0.bn3.bias -> current param: encoder.layer3.0.bn3.bias
	pretrained param: encoder.layer3.0.bn3.running_mean -> current param: encoder.layer3.0.bn3.running_mean
	pretrained param: encoder.layer3.0.bn3.running_var -> current param: encoder.layer3.0.bn3.running_var
	pretrained param: encoder.layer3.0.bn3.num_batches_tracked -> current param: encoder.layer3.0.bn3.num_batches_tracked
	pretrained param: encoder.layer3.0.downsample.0.weight -> current param: encoder.layer3.0.downsample.0.weight
	pretrained param: encoder.layer3.0.downsample.1.weight -> current param: encoder.layer3.0.downsample.1.weight
	pretrained param: encoder.layer3.0.downsample.1.bias -> current param: encoder.layer3.0.downsample.1.bias
	pretrained param: encoder.layer3.0.downsample.1.running_mean -> current param: encoder.layer3.0.downsample.1.running_mean
	pretrained param: encoder.layer3.0.downsample.1.running_var -> current param: encoder.layer3.0.downsample.1.running_var
	pretrained param: encoder.layer3.0.downsample.1.num_batches_tracked -> current param: encoder.layer3.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv1.weight -> current param: encoder.layer3.1.conv1.weight
	pretrained param: encoder.layer3.1.bn1.weight -> current param: encoder.layer3.1.bn1.weight
	pretrained param: encoder.layer3.1.bn1.bias -> current param: encoder.layer3.1.bn1.bias
	pretrained param: encoder.layer3.1.bn1.running_mean -> current param: encoder.layer3.1.bn1.running_mean
	pretrained param: encoder.layer3.1.bn1.running_var -> current param: encoder.layer3.1.bn1.running_var
	pretrained param: encoder.layer3.1.bn1.num_batches_tracked -> current param: encoder.layer3.1.bn1.num_batches_tracked
	pretrained param: encoder.layer3.1.conv2.weight -> current param: encoder.layer3.1.conv2.weight
	pretrained param: encoder.layer3.1.bn2.weight -> current param: encoder.layer3.1.bn2.weight
	pretrained param: encoder.layer3.1.bn2.bias -> current param: encoder.layer3.1.bn2.bias
	pretrained param: encoder.layer3.1.bn2.running_mean -> current param: encoder.layer3.1.bn2.running_mean
	pretrained param: encoder.layer3.1.bn2.running_var -> current param: encoder.layer3.1.bn2.running_var
	pretrained param: encoder.layer3.1.bn2.num_batches_tracked -> current param: encoder.layer3.1.bn2.num_batches_tracked
	pretrained param: encoder.layer3.1.conv3.weight -> current param: encoder.layer3.1.conv3.weight
	pretrained param: encoder.layer3.1.bn3.weight -> current param: encoder.layer3.1.bn3.weight
	pretrained param: encoder.layer3.1.bn3.bias -> current param: encoder.layer3.1.bn3.bias
	pretrained param: encoder.layer3.1.bn3.running_mean -> current param: encoder.layer3.1.bn3.running_mean
	pretrained param: encoder.layer3.1.bn3.running_var -> current param: encoder.layer3.1.bn3.running_var
	pretrained param: encoder.layer3.1.bn3.num_batches_tracked -> current param: encoder.layer3.1.bn3.num_batches_tracked
	pretrained param: encoder.layer3.2.conv1.weight -> current param: encoder.layer3.2.conv1.weight
	pretrained param: encoder.layer3.2.bn1.weight -> current param: encoder.layer3.2.bn1.weight
	pretrained param: encoder.layer3.2.bn1.bias -> current param: encoder.layer3.2.bn1.bias
	pretrained param: encoder.layer3.2.bn1.running_mean -> current param: encoder.layer3.2.bn1.running_mean
	pretrained param: encoder.layer3.2.bn1.running_var -> current param: encoder.layer3.2.bn1.running_var
	pretrained param: encoder.layer3.2.bn1.num_batches_tracked -> current param: encoder.layer3.2.bn1.num_batches_tracked
	pretrained param: encoder.layer3.2.conv2.weight -> current param: encoder.layer3.2.conv2.weight
	pretrained param: encoder.layer3.2.bn2.weight -> current param: encoder.layer3.2.bn2.weight
	pretrained param: encoder.layer3.2.bn2.bias -> current param: encoder.layer3.2.bn2.bias
	pretrained param: encoder.layer3.2.bn2.running_mean -> current param: encoder.layer3.2.bn2.running_mean
	pretrained param: encoder.layer3.2.bn2.running_var -> current param: encoder.layer3.2.bn2.running_var
	pretrained param: encoder.layer3.2.bn2.num_batches_tracked -> current param: encoder.layer3.2.bn2.num_batches_tracked
	pretrained param: encoder.layer3.2.conv3.weight -> current param: encoder.layer3.2.conv3.weight
	pretrained param: encoder.layer3.2.bn3.weight -> current param: encoder.layer3.2.bn3.weight
	pretrained param: encoder.layer3.2.bn3.bias -> current param: encoder.layer3.2.bn3.bias
	pretrained param: encoder.layer3.2.bn3.running_mean -> current param: encoder.layer3.2.bn3.running_mean
	pretrained param: encoder.layer3.2.bn3.running_var -> current param: encoder.layer3.2.bn3.running_var
	pretrained param: encoder.layer3.2.bn3.num_batches_tracked -> current param: encoder.layer3.2.bn3.num_batches_tracked
	pretrained param: encoder.layer3.3.conv1.weight -> current param: encoder.layer3.3.conv1.weight
	pretrained param: encoder.layer3.3.bn1.weight -> current param: encoder.layer3.3.bn1.weight
	pretrained param: encoder.layer3.3.bn1.bias -> current param: encoder.layer3.3.bn1.bias
	pretrained param: encoder.layer3.3.bn1.running_mean -> current param: encoder.layer3.3.bn1.running_mean
	pretrained param: encoder.layer3.3.bn1.running_var -> current param: encoder.layer3.3.bn1.running_var
	pretrained param: encoder.layer3.3.bn1.num_batches_tracked -> current param: encoder.layer3.3.bn1.num_batches_tracked
	pretrained param: encoder.layer3.3.conv2.weight -> current param: encoder.layer3.3.conv2.weight
	pretrained param: encoder.layer3.3.bn2.weight -> current param: encoder.layer3.3.bn2.weight
	pretrained param: encoder.layer3.3.bn2.bias -> current param: encoder.layer3.3.bn2.bias
	pretrained param: encoder.layer3.3.bn2.running_mean -> current param: encoder.layer3.3.bn2.running_mean
	pretrained param: encoder.layer3.3.bn2.running_var -> current param: encoder.layer3.3.bn2.running_var
	pretrained param: encoder.layer3.3.bn2.num_batches_tracked -> current param: encoder.layer3.3.bn2.num_batches_tracked
	pretrained param: encoder.layer3.3.conv3.weight -> current param: encoder.layer3.3.conv3.weight
	pretrained param: encoder.layer3.3.bn3.weight -> current param: encoder.layer3.3.bn3.weight
	pretrained param: encoder.layer3.3.bn3.bias -> current param: encoder.layer3.3.bn3.bias
	pretrained param: encoder.layer3.3.bn3.running_mean -> current param: encoder.layer3.3.bn3.running_mean
	pretrained param: encoder.layer3.3.bn3.running_var -> current param: encoder.layer3.3.bn3.running_var
	pretrained param: encoder.layer3.3.bn3.num_batches_tracked -> current param: encoder.layer3.3.bn3.num_batches_tracked
	pretrained param: encoder.layer3.4.conv1.weight -> current param: encoder.layer3.4.conv1.weight
	pretrained param: encoder.layer3.4.bn1.weight -> current param: encoder.layer3.4.bn1.weight
	pretrained param: encoder.layer3.4.bn1.bias -> current param: encoder.layer3.4.bn1.bias
	pretrained param: encoder.layer3.4.bn1.running_mean -> current param: encoder.layer3.4.bn1.running_mean
	pretrained param: encoder.layer3.4.bn1.running_var -> current param: encoder.layer3.4.bn1.running_var
	pretrained param: encoder.layer3.4.bn1.num_batches_tracked -> current param: encoder.layer3.4.bn1.num_batches_tracked
	pretrained param: encoder.layer3.4.conv2.weight -> current param: encoder.layer3.4.conv2.weight
	pretrained param: encoder.layer3.4.bn2.weight -> current param: encoder.layer3.4.bn2.weight
	pretrained param: encoder.layer3.4.bn2.bias -> current param: encoder.layer3.4.bn2.bias
	pretrained param: encoder.layer3.4.bn2.running_mean -> current param: encoder.layer3.4.bn2.running_mean
	pretrained param: encoder.layer3.4.bn2.running_var -> current param: encoder.layer3.4.bn2.running_var
	pretrained param: encoder.layer3.4.bn2.num_batches_tracked -> current param: encoder.layer3.4.bn2.num_batches_tracked
	pretrained param: encoder.layer3.4.conv3.weight -> current param: encoder.layer3.4.conv3.weight
	pretrained param: encoder.layer3.4.bn3.weight -> current param: encoder.layer3.4.bn3.weight
	pretrained param: encoder.layer3.4.bn3.bias -> current param: encoder.layer3.4.bn3.bias
	pretrained param: encoder.layer3.4.bn3.running_mean -> current param: encoder.layer3.4.bn3.running_mean
	pretrained param: encoder.layer3.4.bn3.running_var -> current param: encoder.layer3.4.bn3.running_var
	pretrained param: encoder.layer3.4.bn3.num_batches_tracked -> current param: encoder.layer3.4.bn3.num_batches_tracked
	pretrained param: encoder.layer3.5.conv1.weight -> current param: encoder.layer3.5.conv1.weight
	pretrained param: encoder.layer3.5.bn1.weight -> current param: encoder.layer3.5.bn1.weight
	pretrained param: encoder.layer3.5.bn1.bias -> current param: encoder.layer3.5.bn1.bias
	pretrained param: encoder.layer3.5.bn1.running_mean -> current param: encoder.layer3.5.bn1.running_mean
	pretrained param: encoder.layer3.5.bn1.running_var -> current param: encoder.layer3.5.bn1.running_var
	pretrained param: encoder.layer3.5.bn1.num_batches_tracked -> current param: encoder.layer3.5.bn1.num_batches_tracked
	pretrained param: encoder.layer3.5.conv2.weight -> current param: encoder.layer3.5.conv2.weight
	pretrained param: encoder.layer3.5.bn2.weight -> current param: encoder.layer3.5.bn2.weight
	pretrained param: encoder.layer3.5.bn2.bias -> current param: encoder.layer3.5.bn2.bias
	pretrained param: encoder.layer3.5.bn2.running_mean -> current param: encoder.layer3.5.bn2.running_mean
	pretrained param: encoder.layer3.5.bn2.running_var -> current param: encoder.layer3.5.bn2.running_var
	pretrained param: encoder.layer3.5.bn2.num_batches_tracked -> current param: encoder.layer3.5.bn2.num_batches_tracked
	pretrained param: encoder.layer3.5.conv3.weight -> current param: encoder.layer3.5.conv3.weight
	pretrained param: encoder.layer3.5.bn3.weight -> current param: encoder.layer3.5.bn3.weight
	pretrained param: encoder.layer3.5.bn3.bias -> current param: encoder.layer3.5.bn3.bias
	pretrained param: encoder.layer3.5.bn3.running_mean -> current param: encoder.layer3.5.bn3.running_mean
	pretrained param: encoder.layer3.5.bn3.running_var -> current param: encoder.layer3.5.bn3.running_var
	pretrained param: encoder.layer3.5.bn3.num_batches_tracked -> current param: encoder.layer3.5.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.conv1.weight -> current param: encoder.layer4.0.conv1.weight
	pretrained param: encoder.layer4.0.bn1.weight -> current param: encoder.layer4.0.bn1.weight
	pretrained param: encoder.layer4.0.bn1.bias -> current param: encoder.layer4.0.bn1.bias
	pretrained param: encoder.layer4.0.bn1.running_mean -> current param: encoder.layer4.0.bn1.running_mean
	pretrained param: encoder.layer4.0.bn1.running_var -> current param: encoder.layer4.0.bn1.running_var
	pretrained param: encoder.layer4.0.bn1.num_batches_tracked -> current param: encoder.layer4.0.bn1.num_batches_tracked
	pretrained param: encoder.layer4.0.conv2.weight -> current param: encoder.layer4.0.conv2.weight
	pretrained param: encoder.layer4.0.bn2.weight -> current param: encoder.layer4.0.bn2.weight
	pretrained param: encoder.layer4.0.bn2.bias -> current param: encoder.layer4.0.bn2.bias
	pretrained param: encoder.layer4.0.bn2.running_mean -> current param: encoder.layer4.0.bn2.running_mean
	pretrained param: encoder.layer4.0.bn2.running_var -> current param: encoder.layer4.0.bn2.running_var
	pretrained param: encoder.layer4.0.bn2.num_batches_tracked -> current param: encoder.layer4.0.bn2.num_batches_tracked
	pretrained param: encoder.layer4.0.conv3.weight -> current param: encoder.layer4.0.conv3.weight
	pretrained param: encoder.layer4.0.bn3.weight -> current param: encoder.layer4.0.bn3.weight
	pretrained param: encoder.layer4.0.bn3.bias -> current param: encoder.layer4.0.bn3.bias
	pretrained param: encoder.layer4.0.bn3.running_mean -> current param: encoder.layer4.0.bn3.running_mean
	pretrained param: encoder.layer4.0.bn3.running_var -> current param: encoder.layer4.0.bn3.running_var
	pretrained param: encoder.layer4.0.bn3.num_batches_tracked -> current param: encoder.layer4.0.bn3.num_batches_tracked
	pretrained param: encoder.layer4.0.downsample.0.weight -> current param: encoder.layer4.0.downsample.0.weight
	pretrained param: encoder.layer4.0.downsample.1.weight -> current param: encoder.layer4.0.downsample.1.weight
	pretrained param: encoder.layer4.0.downsample.1.bias -> current param: encoder.layer4.0.downsample.1.bias
	pretrained param: encoder.layer4.0.downsample.1.running_mean -> current param: encoder.layer4.0.downsample.1.running_mean
	pretrained param: encoder.layer4.0.downsample.1.running_var -> current param: encoder.layer4.0.downsample.1.running_var
	pretrained param: encoder.layer4.0.downsample.1.num_batches_tracked -> current param: encoder.layer4.0.downsample.1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv1.weight -> current param: encoder.layer4.1.conv1.weight
	pretrained param: encoder.layer4.1.bn1.weight -> current param: encoder.layer4.1.bn1.weight
	pretrained param: encoder.layer4.1.bn1.bias -> current param: encoder.layer4.1.bn1.bias
	pretrained param: encoder.layer4.1.bn1.running_mean -> current param: encoder.layer4.1.bn1.running_mean
	pretrained param: encoder.layer4.1.bn1.running_var -> current param: encoder.layer4.1.bn1.running_var
	pretrained param: encoder.layer4.1.bn1.num_batches_tracked -> current param: encoder.layer4.1.bn1.num_batches_tracked
	pretrained param: encoder.layer4.1.conv2.weight -> current param: encoder.layer4.1.conv2.weight
	pretrained param: encoder.layer4.1.bn2.weight -> current param: encoder.layer4.1.bn2.weight
	pretrained param: encoder.layer4.1.bn2.bias -> current param: encoder.layer4.1.bn2.bias
	pretrained param: encoder.layer4.1.bn2.running_mean -> current param: encoder.layer4.1.bn2.running_mean
	pretrained param: encoder.layer4.1.bn2.running_var -> current param: encoder.layer4.1.bn2.running_var
	pretrained param: encoder.layer4.1.bn2.num_batches_tracked -> current param: encoder.layer4.1.bn2.num_batches_tracked
	pretrained param: encoder.layer4.1.conv3.weight -> current param: encoder.layer4.1.conv3.weight
	pretrained param: encoder.layer4.1.bn3.weight -> current param: encoder.layer4.1.bn3.weight
	pretrained param: encoder.layer4.1.bn3.bias -> current param: encoder.layer4.1.bn3.bias
	pretrained param: encoder.layer4.1.bn3.running_mean -> current param: encoder.layer4.1.bn3.running_mean
	pretrained param: encoder.layer4.1.bn3.running_var -> current param: encoder.layer4.1.bn3.running_var
	pretrained param: encoder.layer4.1.bn3.num_batches_tracked -> current param: encoder.layer4.1.bn3.num_batches_tracked
	pretrained param: encoder.layer4.2.conv1.weight -> current param: encoder.layer4.2.conv1.weight
	pretrained param: encoder.layer4.2.bn1.weight -> current param: encoder.layer4.2.bn1.weight
	pretrained param: encoder.layer4.2.bn1.bias -> current param: encoder.layer4.2.bn1.bias
	pretrained param: encoder.layer4.2.bn1.running_mean -> current param: encoder.layer4.2.bn1.running_mean
	pretrained param: encoder.layer4.2.bn1.running_var -> current param: encoder.layer4.2.bn1.running_var
	pretrained param: encoder.layer4.2.bn1.num_batches_tracked -> current param: encoder.layer4.2.bn1.num_batches_tracked
	pretrained param: encoder.layer4.2.conv2.weight -> current param: encoder.layer4.2.conv2.weight
	pretrained param: encoder.layer4.2.bn2.weight -> current param: encoder.layer4.2.bn2.weight
	pretrained param: encoder.layer4.2.bn2.bias -> current param: encoder.layer4.2.bn2.bias
	pretrained param: encoder.layer4.2.bn2.running_mean -> current param: encoder.layer4.2.bn2.running_mean
	pretrained param: encoder.layer4.2.bn2.running_var -> current param: encoder.layer4.2.bn2.running_var
	pretrained param: encoder.layer4.2.bn2.num_batches_tracked -> current param: encoder.layer4.2.bn2.num_batches_tracked
	pretrained param: encoder.layer4.2.conv3.weight -> current param: encoder.layer4.2.conv3.weight
	pretrained param: encoder.layer4.2.bn3.weight -> current param: encoder.layer4.2.bn3.weight
	pretrained param: encoder.layer4.2.bn3.bias -> current param: encoder.layer4.2.bn3.bias
	pretrained param: encoder.layer4.2.bn3.running_mean -> current param: encoder.layer4.2.bn3.running_mean
	pretrained param: encoder.layer4.2.bn3.running_var -> current param: encoder.layer4.2.bn3.running_var
	pretrained param: encoder.layer4.2.bn3.num_batches_tracked -> current param: encoder.layer4.2.bn3.num_batches_tracked
	pretrained param: decoder.classify.weight -> current param: decoder.classify.weight
		Ignoring: decoder.classify.weight->decoder.classify.weight (size mismatch)
	pretrained param: decoder.classify.bias -> current param: decoder.classify.bias
90.11% of the model loaded from the pretrained
Total params: 179.77M
Dataset catalyst_h2 is not supported, use default mean stats instead
Training model on the catalyst_h2 dataset
Dataset catalyst_h2 is not supported, use default mean stats instead
[train] Epoch: 0/80 xent: 1.365 softIoU: 8.285 IoU: 0.000 
Execution time: 284.4541186071001

[valid] Epoch: 0/80 xent: 0.336 softIoU: 8.013 IoU: 0.000 
Execution time: 69.5902439840138

[train] Epoch: 1/80 xent: 0.330 softIoU: 8.012 IoU: 0.000 
Execution time: 283.79386207368225

[valid] Epoch: 1/80 xent: 0.335 softIoU: 8.011 IoU: 0.000 
Execution time: 68.98160830466077

[train] Epoch: 2/80 xent: 0.338 softIoU: 8.011 IoU: 0.000 
Execution time: 284.2861239416525

[valid] Epoch: 2/80 xent: 0.335 softIoU: 8.012 IoU: 0.000 
Execution time: 70.05767904780805

[train] Epoch: 3/80 xent: 0.337 softIoU: 8.010 IoU: 0.000 
Execution time: 285.25580422673374

[valid] Epoch: 3/80 xent: 0.334 softIoU: 8.011 IoU: 0.000 
Execution time: 70.86012111697346

[train] Epoch: 4/80 xent: 0.331 softIoU: 8.011 IoU: 0.000 
Execution time: 283.19719135714695

[valid] Epoch: 4/80 xent: 0.334 softIoU: 8.012 IoU: 0.000 
Execution time: 68.21533704316244

[train] Epoch: 5/80 xent: 0.332 softIoU: 8.011 IoU: 0.000 
Execution time: 285.4673158326186

[valid] Epoch: 5/80 xent: 0.333 softIoU: 8.011 IoU: 0.000 
Execution time: 68.101336624939

[train] Epoch: 6/80 xent: 0.328 softIoU: 8.011 IoU: 0.000 
Execution time: 285.9860394289717

[valid] Epoch: 6/80 xent: 0.333 softIoU: 8.011 IoU: 0.000 
Execution time: 68.3649724679999

[train] Epoch: 7/80 xent: 0.335 softIoU: 8.011 IoU: 0.000 
Execution time: 282.08055596332997

[valid] Epoch: 7/80 xent: 0.333 softIoU: 8.011 IoU: 0.000 
Execution time: 68.04893241915852

[train] Epoch: 8/80 xent: 0.327 softIoU: 8.010 IoU: 0.000 
Execution time: 282.3363975188695

[valid] Epoch: 8/80 xent: 0.332 softIoU: 8.011 IoU: 0.000 
Execution time: 68.0388667229563

[train] Epoch: 9/80 xent: 0.334 softIoU: 8.011 IoU: 0.000 
Execution time: 281.89784478908405

[valid] Epoch: 9/80 xent: 0.331 softIoU: 8.011 IoU: 0.000 
Execution time: 68.0765584371984

[train] Epoch: 10/80 xent: 0.328 softIoU: 8.010 IoU: 0.000 
Execution time: 284.4068323690444

[valid] Epoch: 10/80 xent: 0.331 softIoU: 8.011 IoU: 0.000 
Execution time: 69.07068429980427

[train] Epoch: 11/80 xent: 0.332 softIoU: 8.011 IoU: 0.000 
Execution time: 284.33789002802223

[valid] Epoch: 11/80 xent: 0.330 softIoU: 8.011 IoU: 0.000 
Execution time: 68.67794383922592

[train] Epoch: 12/80 xent: 0.326 softIoU: 8.010 IoU: 0.000 
Execution time: 287.2647808790207

[valid] Epoch: 12/80 xent: 0.329 softIoU: 8.011 IoU: 0.000 
Execution time: 68.64785905880854

[train] Epoch: 13/80 xent: 0.332 softIoU: 8.011 IoU: 0.000 
Execution time: 283.8457068670541

[valid] Epoch: 13/80 xent: 0.329 softIoU: 8.010 IoU: 0.000 
Execution time: 68.47096226876602

[train] Epoch: 14/80 xent: 0.330 softIoU: 8.011 IoU: 0.000 
Execution time: 283.7611682470888

[valid] Epoch: 14/80 xent: 0.327 softIoU: 8.010 IoU: 0.000 
Execution time: 68.35388550208881

[train] Epoch: 15/80 xent: 0.330 softIoU: 8.010 IoU: 0.000 
Execution time: 293.61552597908303

[valid] Epoch: 15/80 xent: 0.326 softIoU: 8.011 IoU: 0.000 
Execution time: 68.90167143987492

[train] Epoch: 16/80 xent: 0.326 softIoU: 8.011 IoU: 0.000 
Execution time: 287.69166337978095

[valid] Epoch: 16/80 xent: 0.325 softIoU: 8.010 IoU: 0.000 
Execution time: 73.74495059624314

[train] Epoch: 17/80 xent: 0.326 softIoU: 8.009 IoU: 0.000 
Execution time: 298.98668766906485

[valid] Epoch: 17/80 xent: 0.323 softIoU: 8.011 IoU: 0.000 
Execution time: 70.44013222400099

[train] Epoch: 18/80 xent: 0.325 softIoU: 8.010 IoU: 0.000 
Execution time: 290.16715489095077

[valid] Epoch: 18/80 xent: 0.321 softIoU: 8.011 IoU: 0.000 
Execution time: 71.38649955904111

[train] Epoch: 19/80 xent: 0.322 softIoU: 8.010 IoU: 0.000 
Execution time: 286.5941014937125

[valid] Epoch: 19/80 xent: 0.318 softIoU: 8.010 IoU: 0.000 
Execution time: 69.27058472717181

[train] Epoch: 20/80 xent: 0.318 softIoU: 8.010 IoU: 0.000 
Execution time: 287.64612409239635

[valid] Epoch: 20/80 xent: 0.314 softIoU: 8.009 IoU: 0.000 
Execution time: 67.67494089202955

Saved model at /scratch/sr365/models/catalysth2_mb_5/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-20.pth.tar
[train] Epoch: 21/80 xent: 0.314 softIoU: 8.008 IoU: 0.000 
Execution time: 286.1417684229091

[valid] Epoch: 21/80 xent: 0.308 softIoU: 8.010 IoU: 0.000 
Execution time: 68.96422354178503

[train] Epoch: 22/80 xent: 0.308 softIoU: 8.009 IoU: 0.000 
Execution time: 286.1034135138616

[valid] Epoch: 22/80 xent: 0.302 softIoU: 8.008 IoU: 0.000 
Execution time: 70.31086165877059

[train] Epoch: 23/80 xent: 0.299 softIoU: 8.008 IoU: 0.000 
Execution time: 289.47846275102347

[valid] Epoch: 23/80 xent: 0.289 softIoU: 8.007 IoU: 0.000 
Execution time: 68.0228523449041

[train] Epoch: 24/80 xent: 0.285 softIoU: 8.005 IoU: 0.000 
Execution time: 288.7748928349465

[valid] Epoch: 24/80 xent: 0.268 softIoU: 8.005 IoU: 0.000 
Execution time: 71.95633431477472

[train] Epoch: 25/80 xent: 0.251 softIoU: 7.998 IoU: 0.000 
Execution time: 295.42896938417107

[valid] Epoch: 25/80 xent: 0.220 softIoU: 7.989 IoU: 0.000 
Execution time: 71.77896779309958

[train] Epoch: 26/80 xent: 0.171 softIoU: 7.908 IoU: 0.100 
Execution time: 296.4763679569587

[valid] Epoch: 26/80 xent: 0.108 softIoU: 7.776 IoU: 0.296 
Execution time: 75.2797190239653

[train] Epoch: 27/80 xent: 0.092 softIoU: 7.658 IoU: 0.307 
Execution time: 290.6913540698588

[valid] Epoch: 27/80 xent: 0.069 softIoU: 7.598 IoU: 0.283 
Execution time: 70.12794367596507

[train] Epoch: 28/80 xent: 0.068 softIoU: 7.525 IoU: 0.382 
Execution time: 297.1111705619842

[valid] Epoch: 28/80 xent: 0.052 softIoU: 7.560 IoU: 0.444 
Execution time: 71.86777103831992

[train] Epoch: 29/80 xent: 0.059 softIoU: 7.460 IoU: 0.407 
Execution time: 294.99819758487865

[valid] Epoch: 29/80 xent: 0.054 softIoU: 7.541 IoU: 0.439 
Execution time: 72.77817756542936

[train] Epoch: 30/80 xent: 0.059 softIoU: 7.449 IoU: 0.411 
Execution time: 285.41358349239454

[valid] Epoch: 30/80 xent: 0.053 softIoU: 7.521 IoU: 0.413 
Execution time: 68.05201176321134

[train] Epoch: 31/80 xent: 0.061 softIoU: 7.440 IoU: 0.366 
Execution time: 281.73557022819296

[valid] Epoch: 31/80 xent: 0.044 softIoU: 7.509 IoU: 0.528 
Execution time: 68.55583280790597

[train] Epoch: 32/80 xent: 0.055 softIoU: 7.414 IoU: 0.423 
Execution time: 287.08570047607645

[valid] Epoch: 32/80 xent: 0.041 softIoU: 7.512 IoU: 0.578 
Execution time: 71.76357861189172

[train] Epoch: 33/80 xent: 0.053 softIoU: 7.419 IoU: 0.417 
Execution time: 282.85241462662816

[valid] Epoch: 33/80 xent: 0.042 softIoU: 7.498 IoU: 0.558 
Execution time: 68.17536871414632

[train] Epoch: 34/80 xent: 0.052 softIoU: 7.375 IoU: 0.457 
Execution time: 288.3653920418583

[valid] Epoch: 34/80 xent: 0.040 softIoU: 7.501 IoU: 0.603 
Execution time: 72.53155436972156

[train] Epoch: 35/80 xent: 0.052 softIoU: 7.393 IoU: 0.457 
Execution time: 296.3070959369652

[valid] Epoch: 35/80 xent: 0.039 softIoU: 7.491 IoU: 0.604 
Execution time: 71.57090809661895

[train] Epoch: 36/80 xent: 0.051 softIoU: 7.398 IoU: 0.470 
Execution time: 291.2644651560113

[valid] Epoch: 36/80 xent: 0.042 softIoU: 7.492 IoU: 0.541 
Execution time: 73.69526199903339

[train] Epoch: 37/80 xent: 0.046 softIoU: 7.394 IoU: 0.486 
Execution time: 293.6453884560615

[valid] Epoch: 37/80 xent: 0.039 softIoU: 7.490 IoU: 0.601 
Execution time: 72.23897245991975

[train] Epoch: 38/80 xent: 0.052 softIoU: 7.390 IoU: 0.454 
Execution time: 297.7920848247595

[valid] Epoch: 38/80 xent: 0.039 softIoU: 7.488 IoU: 0.578 
Execution time: 71.14022560277954

[train] Epoch: 39/80 xent: 0.045 softIoU: 7.385 IoU: 0.515 
Execution time: 293.1955723599531

[valid] Epoch: 39/80 xent: 0.039 softIoU: 7.492 IoU: 0.587 
Execution time: 73.13408996816725

[train] Epoch: 40/80 xent: 0.047 softIoU: 7.343 IoU: 0.496 
Execution time: 292.7347294637002

[valid] Epoch: 40/80 xent: 0.039 softIoU: 7.484 IoU: 0.567 
Execution time: 72.59470416791737

Saved model at /scratch/sr365/models/catalysth2_mb_5/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-40.pth.tar
[train] Epoch: 41/80 xent: 0.042 softIoU: 7.348 IoU: 0.529 
Execution time: 294.9751081750728

[valid] Epoch: 41/80 xent: 0.037 softIoU: 7.480 IoU: 0.594 
Execution time: 72.04451467329636

[train] Epoch: 42/80 xent: 0.043 softIoU: 7.367 IoU: 0.539 
Execution time: 297.1388180661015

[valid] Epoch: 42/80 xent: 0.038 softIoU: 7.485 IoU: 0.570 
Execution time: 72.63940912811086

[train] Epoch: 43/80 xent: 0.041 softIoU: 7.368 IoU: 0.540 
Execution time: 296.4482593140565

[valid] Epoch: 43/80 xent: 0.037 softIoU: 7.484 IoU: 0.592 
Execution time: 70.19224475696683

[train] Epoch: 44/80 xent: 0.043 softIoU: 7.356 IoU: 0.516 
Execution time: 293.9337174058892

[valid] Epoch: 44/80 xent: 0.037 softIoU: 7.480 IoU: 0.595 
Execution time: 75.95576805109158

[train] Epoch: 45/80 xent: 0.042 softIoU: 7.343 IoU: 0.543 
Execution time: 296.0817489870824

[valid] Epoch: 45/80 xent: 0.038 softIoU: 7.484 IoU: 0.580 
Execution time: 72.49692758824676

[train] Epoch: 46/80 xent: 0.041 softIoU: 7.362 IoU: 0.529 
Execution time: 291.1502723279409

[valid] Epoch: 46/80 xent: 0.036 softIoU: 7.482 IoU: 0.594 
Execution time: 71.93889995617792

[train] Epoch: 47/80 xent: 0.043 softIoU: 7.346 IoU: 0.522 
Execution time: 292.03452199697495

[valid] Epoch: 47/80 xent: 0.036 softIoU: 7.482 IoU: 0.593 
Execution time: 74.05604915507138

[train] Epoch: 48/80 xent: 0.046 softIoU: 7.356 IoU: 0.526 
Execution time: 292.2233104961924

[valid] Epoch: 48/80 xent: 0.036 softIoU: 7.483 IoU: 0.608 
Execution time: 72.46270044194534

[train] Epoch: 49/80 xent: 0.044 softIoU: 7.360 IoU: 0.520 
Execution time: 292.57362976297736

[valid] Epoch: 49/80 xent: 0.035 softIoU: 7.479 IoU: 0.606 
Execution time: 70.99068269319832

[train] Epoch: 50/80 xent: 0.044 softIoU: 7.375 IoU: 0.515 
Execution time: 296.26323938695714

[valid] Epoch: 50/80 xent: 0.035 softIoU: 7.480 IoU: 0.609 
Execution time: 70.26220321003348

[train] Epoch: 51/80 xent: 0.042 softIoU: 7.354 IoU: 0.509 
Execution time: 290.39841309795156

[valid] Epoch: 51/80 xent: 0.035 softIoU: 7.478 IoU: 0.595 
Execution time: 68.84943111613393

[train] Epoch: 52/80 xent: 0.044 softIoU: 7.376 IoU: 0.513 
Execution time: 288.57823569187894

[valid] Epoch: 52/80 xent: 0.038 softIoU: 7.483 IoU: 0.552 
Execution time: 70.37898953724653

[train] Epoch: 53/80 xent: 0.040 softIoU: 7.359 IoU: 0.533 
Execution time: 286.21891306107864

[valid] Epoch: 53/80 xent: 0.036 softIoU: 7.480 IoU: 0.578 
Execution time: 69.16383770108223

[train] Epoch: 54/80 xent: 0.043 softIoU: 7.373 IoU: 0.523 
Execution time: 283.7052574586123

[valid] Epoch: 54/80 xent: 0.036 softIoU: 7.482 IoU: 0.593 
Execution time: 67.67363477079198

[train] Epoch: 55/80 xent: 0.040 softIoU: 7.353 IoU: 0.528 
Execution time: 287.306885890197

[valid] Epoch: 55/80 xent: 0.034 softIoU: 7.480 IoU: 0.610 
Execution time: 68.5769399208948

[train] Epoch: 56/80 xent: 0.041 softIoU: 7.359 IoU: 0.534 
Execution time: 290.9505543159321

[valid] Epoch: 56/80 xent: 0.035 softIoU: 7.479 IoU: 0.602 
Execution time: 68.63105450104922

[train] Epoch: 57/80 xent: 0.040 softIoU: 7.362 IoU: 0.514 
Execution time: 290.0899087227881

[valid] Epoch: 57/80 xent: 0.035 softIoU: 7.479 IoU: 0.604 
Execution time: 67.9734164220281

[train] Epoch: 58/80 xent: 0.042 softIoU: 7.357 IoU: 0.528 
Execution time: 289.791462588124

[valid] Epoch: 58/80 xent: 0.034 softIoU: 7.478 IoU: 0.604 
Execution time: 68.02083596913144

[train] Epoch: 59/80 xent: 0.040 softIoU: 7.390 IoU: 0.524 
Execution time: 284.94338520476595

[valid] Epoch: 59/80 xent: 0.035 softIoU: 7.478 IoU: 0.594 
Execution time: 68.51927872095257

[train] Epoch: 60/80 xent: 0.042 softIoU: 7.351 IoU: 0.514 
Execution time: 288.0832617720589

[valid] Epoch: 60/80 xent: 0.034 softIoU: 7.478 IoU: 0.604 
Execution time: 68.50178547203541

Saved model at /scratch/sr365/models/catalysth2_mb_5/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-60.pth.tar
[train] Epoch: 61/80 xent: 0.044 softIoU: 7.373 IoU: 0.502 
Execution time: 286.4824384059757

[valid] Epoch: 61/80 xent: 0.035 softIoU: 7.483 IoU: 0.628 
Execution time: 68.90442146500573

[train] Epoch: 62/80 xent: 0.042 softIoU: 7.353 IoU: 0.511 
Execution time: 283.2045121793635

[valid] Epoch: 62/80 xent: 0.035 softIoU: 7.479 IoU: 0.584 
Execution time: 68.94342600600794

[train] Epoch: 63/80 xent: 0.041 softIoU: 7.364 IoU: 0.531 
Execution time: 287.5333122704178

[valid] Epoch: 63/80 xent: 0.035 softIoU: 7.480 IoU: 0.580 
Execution time: 68.26037634676322

[train] Epoch: 64/80 xent: 0.041 softIoU: 7.362 IoU: 0.531 
Execution time: 289.3812531149015

[valid] Epoch: 64/80 xent: 0.034 softIoU: 7.479 IoU: 0.609 
Execution time: 68.19942496391013

[train] Epoch: 65/80 xent: 0.038 softIoU: 7.350 IoU: 0.540 
Execution time: 287.3704508407973

[valid] Epoch: 65/80 xent: 0.034 softIoU: 7.479 IoU: 0.611 
Execution time: 67.38244918407872

[train] Epoch: 66/80 xent: 0.042 softIoU: 7.349 IoU: 0.527 
Execution time: 288.8044316698797

[valid] Epoch: 66/80 xent: 0.035 softIoU: 7.479 IoU: 0.612 
Execution time: 68.72823216859251

[train] Epoch: 67/80 xent: 0.041 softIoU: 7.356 IoU: 0.532 
Execution time: 290.3492813142948

[valid] Epoch: 67/80 xent: 0.035 softIoU: 7.479 IoU: 0.595 
Execution time: 71.3166414219886

[train] Epoch: 68/80 xent: 0.043 softIoU: 7.354 IoU: 0.505 
Execution time: 287.882210529875

[valid] Epoch: 68/80 xent: 0.035 softIoU: 7.478 IoU: 0.597 
Execution time: 68.59024916309863

[train] Epoch: 69/80 xent: 0.039 softIoU: 7.352 IoU: 0.546 
Execution time: 285.03755707712844

[valid] Epoch: 69/80 xent: 0.034 softIoU: 7.478 IoU: 0.600 
Execution time: 67.4706518407911

[train] Epoch: 70/80 xent: 0.042 softIoU: 7.381 IoU: 0.509 
Execution time: 288.53283195523545

[valid] Epoch: 70/80 xent: 0.034 softIoU: 7.479 IoU: 0.614 
Execution time: 67.33127704495564

[train] Epoch: 71/80 xent: 0.039 softIoU: 7.351 IoU: 0.554 
Execution time: 286.3690440370701

[valid] Epoch: 71/80 xent: 0.035 softIoU: 7.479 IoU: 0.591 
Execution time: 68.32439030334353

[train] Epoch: 72/80 xent: 0.041 softIoU: 7.344 IoU: 0.538 
Execution time: 287.4561283797957

[valid] Epoch: 72/80 xent: 0.034 softIoU: 7.478 IoU: 0.619 
Execution time: 68.32582693500444

[train] Epoch: 73/80 xent: 0.041 softIoU: 7.396 IoU: 0.529 
Execution time: 287.40565095096827

[valid] Epoch: 73/80 xent: 0.034 softIoU: 7.479 IoU: 0.624 
Execution time: 69.83337889472023

[train] Epoch: 74/80 xent: 0.043 softIoU: 7.336 IoU: 0.531 
Execution time: 284.7696109027602

[valid] Epoch: 74/80 xent: 0.035 softIoU: 7.478 IoU: 0.595 
Execution time: 67.05988083966076

[train] Epoch: 75/80 xent: 0.039 softIoU: 7.358 IoU: 0.515 
Execution time: 285.7192017668858

[valid] Epoch: 75/80 xent: 0.035 softIoU: 7.479 IoU: 0.600 
Execution time: 68.33995284233242

[train] Epoch: 76/80 xent: 0.040 softIoU: 7.369 IoU: 0.531 
Execution time: 287.84939240990207

[valid] Epoch: 76/80 xent: 0.034 softIoU: 7.478 IoU: 0.617 
Execution time: 69.75209836894646

[train] Epoch: 77/80 xent: 0.041 softIoU: 7.359 IoU: 0.535 
Execution time: 287.3407282605767

[valid] Epoch: 77/80 xent: 0.034 softIoU: 7.482 IoU: 0.621 
Execution time: 68.68304805271327

[train] Epoch: 78/80 xent: 0.042 softIoU: 7.368 IoU: 0.537 
Execution time: 287.66628299700096

[valid] Epoch: 78/80 xent: 0.036 softIoU: 7.480 IoU: 0.576 
Execution time: 68.87993108388036

[train] Epoch: 79/80 xent: 0.039 softIoU: 7.358 IoU: 0.558 
Execution time: 283.79488787427545

[valid] Epoch: 79/80 xent: 0.035 softIoU: 7.479 IoU: 0.606 
Execution time: 69.18384136492386

Saved model at /scratch/sr365/models/catalysth2_mb_5/ecresnet50_dcdlinknet_dscatalyst_h2_lre1e-03_lrd1e-02_ep80_bs16_ds40_60_dr0p1_crxent7p0_softiou3p0/epoch-80.pth.tar
